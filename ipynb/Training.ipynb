{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import nibabel as nib\n",
    "from typing import List\n",
    "from collections import OrderedDict\n",
    "import SimpleITK as sitk\n",
    "from tqdm import notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://ftp.daumkakao.com/pypi/simple\n",
      "Collecting nibabel\n",
      "  Downloading http://mirror.kakao.com/pypi/packages/42/bf/ba089fec67237f6439c345b8977ca6dde67402ada6592bf84c2c78d557ff/nibabel-3.2.1-py3-none-any.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 12.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.8/dist-packages (from nibabel) (21.2)\n",
      "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.8/dist-packages (from nibabel) (1.21.3)\n",
      "Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=14.3->nibabel) (2.4.7)\n",
      "Installing collected packages: nibabel\n",
      "Successfully installed nibabel-3.2.1\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Looking in indexes: http://ftp.daumkakao.com/pypi/simple\n",
      "Collecting SimpleITK\n",
      "  Downloading http://mirror.kakao.com/pypi/packages/94/82/3d9993548359b031bdba679cab7562cdd7380e829924e6c6ce90237de700/SimpleITK-2.1.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (48.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 48.4 MB 9.3 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: SimpleITK\n",
      "Successfully installed SimpleITK-2.1.1\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install nibabel\n",
    "# !pip install SimpleITK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils ..\n",
    "def maybe_mkdir_p(directory: str) -> None:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    \n",
    "def subdirs(folder: str, join: bool = True, prefix: str = None, suffix: str = None, sort: bool = True) -> List[str]:\n",
    "    if join:\n",
    "        l = os.path.join\n",
    "    else:\n",
    "        l = lambda x, y: y\n",
    "    res = [l(folder, i) for i in os.listdir(folder) if os.path.isdir(os.path.join(folder, i))\n",
    "           and (prefix is None or i.startswith(prefix))\n",
    "           and (suffix is None or i.endswith(suffix))]\n",
    "    if sort:\n",
    "        res.sort()\n",
    "    return res\n",
    "\n",
    "def subfiles(folder: str, join: bool = True, prefix: str = None, suffix: str = None, sort: bool = True) -> List[str]:\n",
    "    if join:\n",
    "        l = os.path.join\n",
    "    else:\n",
    "        l = lambda x, y: y\n",
    "    res = [l(folder, i) for i in os.listdir(folder) if os.path.isfile(os.path.join(folder, i))\n",
    "           and (prefix is None or i.startswith(prefix))\n",
    "           and (suffix is None or i.endswith(suffix))]\n",
    "    if sort:\n",
    "        res.sort()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://ftp.daumkakao.com/pypi/simple\n",
      "Obtaining file:///tf/backup/nnUNet\n",
      "Requirement already satisfied: torch>=1.6.0a in /usr/local/lib/python3.8/dist-packages (from nnunet==1.7.0) (1.9.1+cu111)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nnunet==1.7.0) (4.62.3)\n",
      "Collecting dicom2nifti\n",
      "  Downloading http://mirror.kakao.com/pypi/packages/26/f1/22e4cb6704a5204b9ed731e74fac180b3659c0a1af65f6e2b149013bda21/dicom2nifti-2.3.0.tar.gz (33 kB)\n",
      "Requirement already satisfied: scikit-image>=0.14 in /usr/local/lib/python3.8/dist-packages (from nnunet==1.7.0) (0.18.3)\n",
      "Collecting medpy\n",
      "  Downloading http://mirror.kakao.com/pypi/packages/3b/70/c1fd5dd60242eee81774696ea7ba4caafac2bad8f028bba94b1af83777d7/MedPy-0.4.0.tar.gz (151 kB)\n",
      "\u001b[K     |████████████████████████████████| 151 kB 15.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from nnunet==1.7.0) (1.7.3)\n",
      "Collecting batchgenerators>=0.23\n",
      "  Downloading http://mirror.kakao.com/pypi/packages/02/6e/3353824a6d782dfad850f026c3020509b69abf21c5a503b1f76e63b8f48f/batchgenerators-0.23.tar.gz (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 35.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from nnunet==1.7.0) (1.21.3)\n",
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.8/dist-packages (from nnunet==1.7.0) (0.0)\n",
      "Requirement already satisfied: SimpleITK in /usr/local/lib/python3.8/dist-packages (from nnunet==1.7.0) (2.1.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from nnunet==1.7.0) (1.3.4)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from nnunet==1.7.0) (2.22.0)\n",
      "Requirement already satisfied: nibabel in /usr/local/lib/python3.8/dist-packages (from nnunet==1.7.0) (3.2.1)\n",
      "Requirement already satisfied: tifffile in /usr/local/lib/python3.8/dist-packages (from nnunet==1.7.0) (2021.11.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.6.0a->nnunet==1.7.0) (3.10.0.2)\n",
      "Collecting pydicom>=1.3.0\n",
      "  Downloading http://mirror.kakao.com/pypi/packages/53/9a/98df4fb41e7905b587be2ee9ce38bab8a092990bd174f46fd915a23ec0ea/pydicom-2.2.2-py3-none-any.whl (2.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.0 MB 20.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.14->nnunet==1.7.0) (3.4.3)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.14->nnunet==1.7.0) (8.4.0)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.14->nnunet==1.7.0) (2.13.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.14->nnunet==1.7.0) (1.2.0)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.14->nnunet==1.7.0) (2.6.3)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from batchgenerators>=0.23->nnunet==1.7.0) (1.0.1)\n",
      "Collecting future\n",
      "  Downloading http://mirror.kakao.com/pypi/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829 kB)\n",
      "\u001b[K     |████████████████████████████████| 829 kB 127.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting unittest2\n",
      "  Downloading http://mirror.kakao.com/pypi/packages/72/20/7f0f433060a962200b7272b8c12ba90ef5b903e218174301d0abfd523813/unittest2-1.1.0-py2.py3-none-any.whl (96 kB)\n",
      "\u001b[K     |████████████████████████████████| 96 kB 122.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: threadpoolctl in /usr/local/lib/python3.8/dist-packages (from batchgenerators>=0.23->nnunet==1.7.0) (3.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->nnunet==1.7.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->nnunet==1.7.0) (2021.3)\n",
      "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.8/dist-packages (from nibabel->nnunet==1.7.0) (21.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14->nnunet==1.7.0) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14->nnunet==1.7.0) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14->nnunet==1.7.0) (2.4.7)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->batchgenerators>=0.23->nnunet==1.7.0) (1.1.0)\n",
      "Collecting argparse\n",
      "  Downloading http://mirror.kakao.com/pypi/packages/f2/94/3af39d34be01a24a6e65433d19e107099374224905f1e0cc6bbe1fd22a2f/argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: six>=1.4 in /usr/lib/python3/dist-packages (from unittest2->batchgenerators>=0.23->nnunet==1.7.0) (1.14.0)\n",
      "Collecting traceback2\n",
      "  Downloading http://mirror.kakao.com/pypi/packages/17/0a/6ac05a3723017a967193456a2efa0aa9ac4b51456891af1e2353bb9de21e/traceback2-1.4.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting linecache2\n",
      "  Downloading http://mirror.kakao.com/pypi/packages/c7/a3/c5da2a44c85bfbb6eebcfc1dde24933f8704441b98fdde6528f4831757a6/linecache2-1.0.0-py2.py3-none-any.whl (12 kB)\n",
      "Building wheels for collected packages: dicom2nifti, medpy, batchgenerators, future\n",
      "  Building wheel for dicom2nifti (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dicom2nifti: filename=dicom2nifti-2.3.0-py3-none-any.whl size=42933 sha256=ca1de8bfe41beb690ff7814651a123d2d3e50358ae71f774f24c08c2eb941693\n",
      "  Stored in directory: /root/.cache/pip/wheels/6c/63/4b/bfdb925ebf1c6ee721258d7f8a69951cd76e6d178bb0d0395b\n",
      "  Building wheel for medpy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for medpy: filename=MedPy-0.4.0-py3-none-any.whl size=214963 sha256=62e2fe88725ed4d095536818b8b46ffa31b3d31e176110240e1c23b7afdbc428\n",
      "  Stored in directory: /root/.cache/pip/wheels/59/90/13/5b5a86494a571d07e6549b9910a7bdc9728aa15b4778dfddff\n",
      "  Building wheel for batchgenerators (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for batchgenerators: filename=batchgenerators-0.23-py3-none-any.whl size=84781 sha256=9c4204c67d68d9e997421c956a6cef547a2f0afed24a4f1a1b29942d70d2c1b2\n",
      "  Stored in directory: /root/.cache/pip/wheels/c1/2c/4d/038dd472e137fe2b32c595bd96a6cc346543b9c7141432e8be\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=ef95b1f629b988de98cf562f0fefbc71dc029ed9a54493a4504117408bf882b3\n",
      "  Stored in directory: /root/.cache/pip/wheels/18/06/47/bf4a03c24ff334fa02e8b45095b422a432b7c6bf9d72a40a99\n",
      "Successfully built dicom2nifti medpy batchgenerators future\n",
      "Installing collected packages: pydicom, dicom2nifti, medpy, future, argparse, linecache2, traceback2, unittest2, batchgenerators, nnunet\n",
      "  Running setup.py develop for nnunet\n",
      "Successfully installed argparse-1.4.0 batchgenerators-0.23 dicom2nifti-2.3.0 future-0.18.2 linecache2-1.0.0 medpy-0.4.0 nnunet pydicom-2.2.2 traceback2-1.4.0 unittest2-1.1.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "maic_dir = '/tf/backup/'\n",
    "base_dir = os.path.join(maic_dir, 'working')\n",
    "training_folder = '/mnt/dataset/train-valid_set'\n",
    "test_folder = '/mnt/dataset/test_set'\n",
    "# input_dir = '/mnt/dataset/train-valid_set/Graspers (straight) (OLYMPUS) (GRSL-UCOL)/'\n",
    "temp_dir = '/tf/temp/'\n",
    "\n",
    "maybe_mkdir_p(base_dir)\n",
    "maybe_mkdir_p(temp_dir)\n",
    "\n",
    "# ! git clone https://github.com/keemsir/nnUNet.git\n",
    "\n",
    "respository_dir = os.path.join(maic_dir, 'nnUNet')\n",
    "os.chdir(respository_dir)\n",
    "\n",
    "! pip install -e .\n",
    "\n",
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting Completed!\n"
     ]
    }
   ],
   "source": [
    "task_name = 'Task81_NDDR'\n",
    "'''\n",
    "Task80_GRSR\n",
    "Task81_NDDR\n",
    "Task82_BFCR\n",
    "Task83_MSCR\n",
    "Task84_SIRL\n",
    "Task85_GRSL\n",
    "Task86_NDHL\n",
    "Task87_CLALM3MT\n",
    "Task88_CLALUCUK\n",
    "'''\n",
    "\n",
    "main_dir = os.path.join(base_dir, 'nnUNet/nnunet')\n",
    "mainT_dir = os.path.join(temp_dir, 'nnUNet/nnunet')\n",
    "\n",
    "rawbase_dir = os.path.join(mainT_dir, 'nnUNet_raw_data_base/')\n",
    "\n",
    "pp_dir = os.path.join(mainT_dir, 'preprocessed')\n",
    "tasks_dir = os.path.join(mainT_dir, 'Tasks')\n",
    "task_dir = os.path.join(tasks_dir, task_name)\n",
    "\n",
    "model_dir = os.path.join(main_dir, 'nnUNet_trained_models')\n",
    "\n",
    "# 1. Data preprocessing\n",
    "maybe_mkdir_p(tasks_dir)\n",
    "maybe_mkdir_p(temp_dir)\n",
    "\n",
    "# 2. Directory\n",
    "maybe_mkdir_p(main_dir)\n",
    "maybe_mkdir_p(model_dir)\n",
    "maybe_mkdir_p(pp_dir)\n",
    "\n",
    "# 3. Directory\n",
    "# maybe_mkdir_p(result_dir)\n",
    "# maybe_mkdir_p(staple_dir)\n",
    "\n",
    "\n",
    "#Environment Setting\n",
    "os.environ['nnUNet_raw_data_base'] = rawbase_dir #os.path.join(mainT_dir, 'nnUNet_raw_data_base')\n",
    "os.environ['nnUNet_preprocessed'] = pp_dir #os.path.join(mainT_dir, 'preprocessed')\n",
    "os.environ['RESULTS_FOLDER'] = model_dir #os.path.join(main_dir, 'nnUNet_trained_models')\n",
    "\n",
    "\n",
    "print('Setting Completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-1. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# jsonPath : JSON Path\\n\\nf_json = open(jsonPath, 'rt', encoding='UTF8')\\njsonData =json.load(f_json)\\njsonPoints= jsonData.get('annotations')[0].get('points')\\njsonImgSize = jsonData.get('images')\\n\\n\\npoints = np.array(np.round(jsonPoints), dtype=np.int)\\nmask = np.zeros((jsonImgSize.get('height'), jsonImgSize.get('width')), dtype = np.uint8)\\ncv2.fillPoly(mask,[points], 1)\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# jsonPath : JSON Path\n",
    "\n",
    "f_json = open(jsonPath, 'rt', encoding='UTF8')\n",
    "jsonData =json.load(f_json)\n",
    "jsonPoints= jsonData.get('annotations')[0].get('points')\n",
    "jsonImgSize = jsonData.get('images')\n",
    "\n",
    "\n",
    "points = np.array(np.round(jsonPoints), dtype=np.int)\n",
    "mask = np.zeros((jsonImgSize.get('height'), jsonImgSize.get('width')), dtype = np.uint8)\n",
    "cv2.fillPoly(mask,[points], 1)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print surgery : R-Maryland (da Vinci) (BFCR-MADV)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['SNUH_DC07_JCW0_RLPN_0003',\n",
       " 'SNUH_DC07_JCW0_RALP_0000',\n",
       " 'SNUH_DC08_KHS0_ENME_0032',\n",
       " 'SNUH_DC07_JCW0_RALP_0031',\n",
       " 'SNUH_DC07_JCW0_RLPN_0008',\n",
       " 'SNUH_DC07_JCW0_RALP_0001',\n",
       " 'SNUH_DC07_JCW0_RLPN_0009',\n",
       " 'SNUH_DC07_JCW0_RLPN_0002',\n",
       " 'SNUH_DC07_JCW0_RALP_0021',\n",
       " 'SNUH_DC07_JCW0_RLPN_0014',\n",
       " 'SNUH_DC07_JCW0_RALP_0011']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Group_frame(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print surgery : Graspers (straight) (OLYMPUS) (GRSL-UCOL)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n"
     ]
    }
   ],
   "source": [
    "for i in subfiles('/mnt/dataset/train-valid_set/Graspers (straight) (OLYMPUS) (GRSL-UCOL)/',prefix=Group_frame(5)[6], suffix='.png'):\n",
    "    plt_i = plt.imread(i)\n",
    "    print(plt_i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Group_frame(surgery_NUM: int, surgery_path = '/mnt/dataset/train-valid_set'):\n",
    "\n",
    "    '''\n",
    "    surgery_path(default) : '/mnt/dataset/train-valid_set/'\n",
    "    surgery_NUM category : \n",
    "    '''\n",
    "    \n",
    "    surgery_DIC = {0: 'Prograsp (da Vinci) (GRSR-UCDV)',\n",
    "                   1: 'R-LND (da Vinci) (NDDR-LADV)',\n",
    "                   2: 'R-Maryland (da Vinci) (BFCR-MADV)',\n",
    "                   3: 'R-Scissors (da Vinci) (MSCR-UCDV)',\n",
    "                   4: 'Suction Irrigator (SIRL-UCUK)',\n",
    "                   5: 'Graspers (straight) (OLYMPUS) (GRSL-UCOL)',\n",
    "                   6: 'Needle Holder (AESCULAP) (NDHL-UCAE)',\n",
    "                   7: 'Metal Clip Applier (Medtronic) (CLAL-M3MT)',\n",
    "                   8: 'Polymer Clip Applier (CLAL-UCUK)'}\n",
    "\n",
    "    print('Print surgery : ' + (surgery_DIC[surgery_NUM]))\n",
    "\n",
    "    SG_listpath = os.path.join(surgery_path, surgery_DIC[surgery_NUM])\n",
    "    SG_listname = subfiles(SG_listpath, join=False, suffix='.json')\n",
    "    \n",
    "    Frame_class = []\n",
    "    \n",
    "    for sg in SG_listname:\n",
    "        name_, ext_ = os.path.splitext(sg)\n",
    "        name1, name2, name3, name4, name5, name6 = name_.split('_')\n",
    "        Frame_class.append('{}_{}_{}_{}_{}'.format(name1, name2, name3, name4, name5))\n",
    "    \n",
    "    set_class = list(set(Frame_class))\n",
    "\n",
    "    return set_class\n",
    "\n",
    "#\n",
    "# Group_frame(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def png2nifti(surgery_NUM: int, \n",
    "              training_folder: str = '/mnt/dataset/train-valid_set', test_folder: str = '/mnt/dataset/test_set',\n",
    "              save_folder: str = '/tf/temp/nnUNet/nnunet/Tasks/'):\n",
    "\n",
    "    # surgery_NUM : surgery_DIC Num (0~8)\n",
    "    # training_folder : training file path '/mnt/dataset/train-valid_set'\n",
    "    # test_folder : test file path '/mnt/dataset/test_set'\n",
    "    # save_folder : '/tf/temp/nnUNet/nnunet/Tasks/' [imagesTr, imagesTs] Save Folder path\n",
    "\n",
    "    # Surgery Catalog\n",
    "    surgery_DIC = {0: 'Prograsp (da Vinci) (GRSR-UCDV)',\n",
    "                   1: 'R-LND (da Vinci) (NDDR-LADV)',\n",
    "                   2: 'R-Maryland (da Vinci) (BFCR-MADV)',\n",
    "                   3: 'R-Scissors (da Vinci) (MSCR-UCDV)',\n",
    "                   4: 'Suction Irrigator (SIRL-UCUK)',\n",
    "                   5: 'Graspers (straight) (OLYMPUS) (GRSL-UCOL)',\n",
    "                   6: 'Needle Holder (AESCULAP) (NDHL-UCAE)',\n",
    "                   7: 'Metal Clip Applier (Medtronic) (CLAL-M3MT)',\n",
    "                   8: 'Polymer Clip Applier (CLAL-UCUK)'}\n",
    "    \n",
    "    task_NameDIC = {0: 'Task80_GRSR', \n",
    "                    1: 'Task81_NDDR', \n",
    "                    2: 'Task82_BFCR', \n",
    "                    3: 'Task83_MSCR', \n",
    "                    4: 'Task84_SIRL', \n",
    "                    5: 'Task85_GRSL', \n",
    "                    6: 'Task86_NDHL', \n",
    "                    7: 'Task87_CLALM3MT', \n",
    "                    8: 'Task88_CLALUCUK'}\n",
    "\n",
    "\n",
    "    maybe_mkdir_p(os.path.join(save_folder, task_NameDIC[surgery_NUM], 'imagesTr'))\n",
    "    maybe_mkdir_p(os.path.join(save_folder, task_NameDIC[surgery_NUM], 'imagesTs'))\n",
    "    maybe_mkdir_p(os.path.join(save_folder, task_NameDIC[surgery_NUM], 'labelsTr'))\n",
    "    \n",
    "    print('Creating \"{}\" Image & Label ..'.format(os.path.basename(os.path.normpath(task_NameDIC[surgery_NUM]))))\n",
    "\n",
    "\n",
    "    for gf in notebook.tqdm(Group_frame(surgery_NUM)):\n",
    "\n",
    "\n",
    "        training_files = subfiles(os.path.join(training_folder, surgery_DIC[surgery_NUM]), join=False, prefix=gf, suffix='.json')\n",
    "        \n",
    "        # Remove Item (surgery_NUMM = 2)\n",
    "\n",
    "        try:\n",
    "            training_files.remove('SNUH_DC07_JCW0_RLPN_0003_0038971.json')\n",
    "        \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        # Initial Setting\n",
    "\n",
    "        images = np.zeros([512, 512, 0], dtype=np.single)\n",
    "\n",
    "        f_json = open(os.path.join(training_folder, surgery_DIC[surgery_NUM], training_files[0]), 'rt', encoding='UTF8')  # temp training_files[0]\n",
    "        jsonData = json.load(f_json)\n",
    "        jsonImgSize = jsonData.get('images')\n",
    "        json_height = jsonImgSize.get('height')\n",
    "        json_width = jsonImgSize.get('width')\n",
    "\n",
    "        labels = np.zeros([512, 512, 0], dtype=np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "        for training_file in training_files: # training_files : JSON file list\n",
    "\n",
    "            training_file_name = os.path.splitext(training_file)[0]  # split suffix, Only Name\n",
    "            \n",
    "            try:\n",
    "                # json label\n",
    "                f_json = open(os.path.join(training_folder, surgery_DIC[surgery_NUM], training_file), 'rt', encoding='UTF8')\n",
    "                jsonData = json.load(f_json)\n",
    "                jsonPoints = jsonData.get('annotations')[0].get('points')\n",
    "                jsonImgSize = jsonData.get('images')\n",
    "                \n",
    "                points = np.array(np.round(jsonPoints), dtype=np.int_)\n",
    "                json_height = jsonImgSize.get('height')\n",
    "                json_width = jsonImgSize.get('width')\n",
    "                label_json = np.zeros((json_height, json_width), dtype=np.uint8)\n",
    "                cv2.fillPoly(label_json, [points], 1)\n",
    "                label_json = cv2.resize(label_json, dsize=(512, 512), interpolation=cv2.INTER_CUBIC) # reduce\n",
    "            except:\n",
    "                print('Error file :', training_file)\n",
    "\n",
    "\n",
    "            # png image\n",
    "            \n",
    "            \n",
    "            training_path = os.path.join(training_folder, surgery_DIC[surgery_NUM], training_file)\n",
    "            png_data = plt.imread(os.path.join(training_folder, training_path[:-5] + '.png'))\n",
    "            png_data = np.mean(png_data, axis=2)\n",
    "            png_data = cv2.resize(png_data, dsize=(512, 512), interpolation=cv2.INTER_CUBIC) # size reduce\n",
    "\n",
    "\n",
    "            image_png = np.expand_dims(png_data, axis=2)\n",
    "\n",
    "            images = np.append(images, image_png, axis=2)\n",
    "\n",
    "            label_json = np.expand_dims(label_json, axis=2)\n",
    "\n",
    "            labels = np.append(labels, label_json, axis=2)\n",
    "\n",
    "\n",
    "        niim = nib.Nifti1Image(images, affine=np.eye(4))\n",
    "        nib.save(niim, os.path.join(save_folder, task_NameDIC[surgery_NUM], 'imagesTr/{}.nii.gz'.format(gf)))\n",
    "        print(images.shape)\n",
    "        del images\n",
    "\n",
    "        nila = nib.Nifti1Image(labels, affine=np.eye(4))\n",
    "        nib.save(nila, os.path.join(save_folder, task_NameDIC[surgery_NUM], 'labelsTr/{}.nii.gz'.format(gf)))\n",
    "\n",
    "        del labels\n",
    "\n",
    "\n",
    "    print('\"{}\" Image & Label Completed !!'.format(os.path.basename(os.path.normpath(task_NameDIC[surgery_NUM]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating \"Task83_MSCR\" Image & Label ..\n",
      "Print surgery : R-Scissors (da Vinci) (MSCR-UCDV)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69cb9901d4e04249b78427f3aa3f3dd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 262)\n",
      "(512, 512, 253)\n",
      "(512, 512, 282)\n",
      "(512, 512, 145)\n",
      "(512, 512, 253)\n",
      "(512, 512, 166)\n",
      "(512, 512, 697)\n",
      "(512, 512, 161)\n",
      "(512, 512, 166)\n",
      "(512, 512, 174)\n",
      "(512, 512, 128)\n",
      "(512, 512, 328)\n",
      "\"Task83_MSCR\" Image & Label Completed !!\n"
     ]
    }
   ],
   "source": [
    "png2nifti(surgery_NUM=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/dataset/train-valid_set/R-Maryland (da Vinci) (BFCR-MADV)/SNUH_DC07_JCW0_RLPN_0003_0038971.json',\n",
       " '/mnt/dataset/train-valid_set/R-Maryland (da Vinci) (BFCR-MADV)/SNUH_DC07_JCW0_RLPN_0003_0038971.xml']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.listdir('/mnt/dataset/train-valid_set/R-Maryland (da Vinci) (BFCR-MADV)/SNUH_DC07_JCW0_RLPN')\n",
    "subfiles('/mnt/dataset/train-valid_set/R-Maryland (da Vinci) (BFCR-MADV)/', prefix='SNUH_DC07_JCW0_RLPN_0003_0038971')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_mk(save_dir: str):\n",
    "    # Path\n",
    "    imagesTr = os.path.join(save_dir, 'imagesTr')\n",
    "    imagesTs = os.path.join(save_dir, 'imagesTs')\n",
    "    maybe_mkdir_p(imagesTr)\n",
    "    maybe_mkdir_p(imagesTs)\n",
    "    \n",
    "    overwrite_json_file = True\n",
    "    json_file_exist = False\n",
    "    \n",
    "    if os.path.exists(os.path.join(save_dir, 'dataset.json')):\n",
    "        print('dataset.json already exist!')\n",
    "        json_file_exist = True\n",
    "        \n",
    "    if json_file_exist == False or overwrite_json_file:\n",
    "        \n",
    "        json_dict = OrderedDict()\n",
    "        json_dict['name'] = \"SUR\"\n",
    "        json_dict['description'] = \"Robotic Surgery AI Challenge 2021\"\n",
    "        json_dict['tensorImageSize'] = \"3D\"\n",
    "        json_dict['reference'] = \"https://maic.or.kr/\"\n",
    "        json_dict['licence'] = \"SNUH\"\n",
    "        json_dict['release'] = \"24/11/2021\"\n",
    "        \n",
    "        json_dict['modality'] = {\n",
    "            \"0\": \"png\"\n",
    "        }\n",
    "        json_dict['labels'] = {\n",
    "            \"0\": \"background\",\n",
    "            \"1\": \"surgery\"\n",
    "        }\n",
    "\n",
    "        train_ids = subfiles(imagesTr, join=False, suffix='.nii.gz')\n",
    "        test_ids = subfiles(imagesTs, join=False, suffix='.nii.gz')\n",
    "        json_dict['numTraining'] = len(train_ids)\n",
    "        json_dict['numTest'] = len(test_ids)\n",
    "\n",
    "        json_dict['training'] = [{'image': \"./imagesTr/%s\" % i, \"label\": \"./labelsTr/%s\" % i} for i in train_ids]\n",
    "\n",
    "        json_dict['test'] = [\"./imagesTs/%s\" % i for i in test_ids] #(i[:i.find(\"_0000\")])\n",
    "\n",
    "        with open(os.path.join(save_dir, \"dataset.json\"), 'w') as f:\n",
    "            json.dump(json_dict, f, indent=4, sort_keys=False)\n",
    "\n",
    "        if os.path.exists(os.path.join(save_dir, 'dataset.json')):\n",
    "            if json_file_exist == False:\n",
    "                print('{}/dataset.json <-- created!'.format(save_dir))\n",
    "            else:\n",
    "                print('{}/dataset.json <-- overwritten!'.format(save_dir))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Task82_BFCR', 'Task99_Inference', '.ipynb_checkpoints', 'Task83_MSCR']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/tf/temp/nnUNet/nnunet/Tasks/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/temp/nnUNet/nnunet/Tasks/Task83_MSCR/dataset.json <-- created!\n"
     ]
    }
   ],
   "source": [
    "json_mk('/tf/temp/nnUNet/nnunet/Tasks/Task83_MSCR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-2. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "SNUH_DC07_JCW0_RALP_0000\n",
      "SNUH_DC07_JCW0_RALP_0001\n",
      "SNUH_DC07_JCW0_RALP_0011\n",
      "SNUH_DC07_JCW0_RALP_0021\n",
      "SNUH_DC07_JCW0_RALP_0031\n",
      "SNUH_DC07_JCW0_RLPN_0002\n",
      "SNUH_DC07_JCW0_RLPN_0003\n",
      "SNUH_DC07_JCW0_RLPN_0008\n",
      "before crop: (1, 128, 512, 512) after crop: (1, 128, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (1, 145, 512, 512) after crop: (1, 145, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (1, 166, 512, 512) after crop: (1, 166, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (1, 174, 512, 512) after crop: (1, 174, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (1, 253, 512, 512) after crop: (1, 253, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (1, 253, 512, 512) after crop: (1, 253, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (1, 262, 512, 512) after crop: (1, 262, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (1, 328, 512, 512) after crop: (1, 328, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "SNUH_DC07_JCW0_RLPN_0009\n",
      "SNUH_DC07_JCW0_RLPN_0014\n",
      "before crop: (1, 166, 512, 512) after crop: (1, 166, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "SNUH_DC08_KHS0_ENME_0032\n",
      "SNUH_DC08_KHS0_ENME_0039\n",
      "before crop: (1, 161, 512, 512) after crop: (1, 161, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (1, 282, 512, 512) after crop: (1, 282, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (1, 697, 512, 512) after crop: (1, 697, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Task483_MSCR\n",
      "number of threads:  (8, 8) \n",
      "\n",
      "not using nonzero mask for normalization\n",
      "Are we using the nonzero mask for normalizaion? OrderedDict([(0, False)])\n",
      "the median shape of the dataset is  [213.5 512.  512. ]\n",
      "the max shape in the dataset is  [697. 512. 512.]\n",
      "the min shape in the dataset is  [128. 512. 512.]\n",
      "we don't want feature maps smaller than  4  in the bottleneck\n",
      "the transposed median shape of the dataset is  [213.5 512.  512. ]\n",
      "generating configuration for 3d_fullres\n",
      "generating configuration for 3d_lowres\n",
      "{0: {'batch_size': 2, 'num_pool_per_axis': [4, 5, 5], 'patch_size': array([ 80, 192, 160]), 'median_patient_size_in_voxels': array([119, 285, 285]), 'current_spacing': array([1.7987096, 1.7987096, 1.7987096]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}, 1: {'batch_size': 2, 'num_pool_per_axis': [4, 5, 5], 'patch_size': array([ 80, 192, 160]), 'median_patient_size_in_voxels': array([214, 512, 512]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}}\n",
      "transpose forward [0, 1, 2]\n",
      "transpose backward [0, 1, 2]\n",
      "Initializing to run preprocessing\n",
      "npz folder: /tf/temp/nnUNet/nnunet/nnUNet_raw_data_base/nnUNet_cropped_data/Task483_MSCR\n",
      "output_folder: /tf/temp/nnUNet/nnunet/preprocessed/Task483_MSCR\n",
      "no separate z, order 3\n",
      "no separate z, order 3\n",
      "no separate z, order 3\n",
      "no separate z, order 3\n",
      "no separate z, order 3\n",
      "no separate z, order 3\n",
      "no separate z, order 3\n",
      "no separate z, order 3\n",
      "no separate z, order 1\n",
      "no separate z, order 1\n",
      "no separate z, order 1\n",
      "no separate z, order 1\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 128, 512, 512)} \n",
      "after:  {'spacing': array([1.7987096, 1.7987096, 1.7987096]), 'data.shape (data is resampled)': (1, 71, 285, 285)} \n",
      "\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task483_MSCR/nnUNetData_plans_v2.1_stage0/SNUH_DC07_JCW0_RALP_0001.npz\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 145, 512, 512)} \n",
      "after:  {'spacing': array([1.7987096, 1.7987096, 1.7987096]), 'data.shape (data is resampled)': (1, 81, 285, 285)} \n",
      "\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task483_MSCR/nnUNetData_plans_v2.1_stage0/SNUH_DC07_JCW0_RALP_0031.npz\n",
      "no separate z, order 1\n",
      "no separate z, order 1\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 166, 512, 512)} \n",
      "after:  {'spacing': array([1.7987096, 1.7987096, 1.7987096]), 'data.shape (data is resampled)': (1, 92, 285, 285)} \n",
      "\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task483_MSCR/nnUNetData_plans_v2.1_stage0/SNUH_DC07_JCW0_RALP_0011.npz\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 174, 512, 512)} \n",
      "after:  {'spacing': array([1.7987096, 1.7987096, 1.7987096]), 'data.shape (data is resampled)': (1, 97, 285, 285)} \n",
      "\n",
      "no separate z, order 1\n",
      "no separate z, order 3\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task483_MSCR/nnUNetData_plans_v2.1_stage0/SNUH_DC07_JCW0_RALP_0021.npz\n",
      "no separate z, order 3\n",
      "no separate z, order 1\n",
      "no separate z, order 3\n",
      "no separate z, order 1\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 253, 512, 512)} \n",
      "after:  {'spacing': array([1.7987096, 1.7987096, 1.7987096]), 'data.shape (data is resampled)': (1, 141, 285, 285)} \n",
      "\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 253, 512, 512)} \n",
      "after:  {'spacing': array([1.7987096, 1.7987096, 1.7987096]), 'data.shape (data is resampled)': (1, 141, 285, 285)} \n",
      "\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task483_MSCR/nnUNetData_plans_v2.1_stage0/SNUH_DC07_JCW0_RLPN_0008.npz\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task483_MSCR/nnUNetData_plans_v2.1_stage0/SNUH_DC07_JCW0_RLPN_0003.npz\n",
      "no separate z, order 1\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 262, 512, 512)} \n",
      "after:  {'spacing': array([1.7987096, 1.7987096, 1.7987096]), 'data.shape (data is resampled)': (1, 146, 285, 285)} \n",
      "\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task483_MSCR/nnUNetData_plans_v2.1_stage0/SNUH_DC07_JCW0_RLPN_0002.npz\n",
      "no separate z, order 3\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 166, 512, 512)} \n",
      "after:  {'spacing': array([1.7987096, 1.7987096, 1.7987096]), 'data.shape (data is resampled)': (1, 92, 285, 285)} \n",
      "\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task483_MSCR/nnUNetData_plans_v2.1_stage0/SNUH_DC07_JCW0_RLPN_0009.npz\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 161, 512, 512)} \n",
      "after:  {'spacing': array([1.7987096, 1.7987096, 1.7987096]), 'data.shape (data is resampled)': (1, 90, 285, 285)} \n",
      "\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task483_MSCR/nnUNetData_plans_v2.1_stage0/SNUH_DC07_JCW0_RLPN_0014.npz\n",
      "no separate z, order 1\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 328, 512, 512)} \n",
      "after:  {'spacing': array([1.7987096, 1.7987096, 1.7987096]), 'data.shape (data is resampled)': (1, 182, 285, 285)} \n",
      "\n",
      "1 11606\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task483_MSCR/nnUNetData_plans_v2.1_stage0/SNUH_DC07_JCW0_RALP_0000.npz\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 282, 512, 512)} \n",
      "after:  {'spacing': array([1.7987096, 1.7987096, 1.7987096]), 'data.shape (data is resampled)': (1, 157, 285, 285)} \n",
      "\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task483_MSCR/nnUNetData_plans_v2.1_stage0/SNUH_DC08_KHS0_ENME_0032.npz\n",
      "no separate z, order 1\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 697, 512, 512)} \n",
      "after:  {'spacing': array([1.7987096, 1.7987096, 1.7987096]), 'data.shape (data is resampled)': (1, 388, 285, 285)} \n",
      "\n",
      "1 35140\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task483_MSCR/nnUNetData_plans_v2.1_stage0/SNUH_DC08_KHS0_ENME_0039.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 128, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 128, 512, 512)} \n",
      "\n",
      "1 22206\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task483_MSCR/nnUNetData_plans_v2.1_stage1/SNUH_DC07_JCW0_RALP_0001.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 145, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 145, 512, 512)} \n",
      "\n",
      "1 32164\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task483_MSCR/nnUNetData_plans_v2.1_stage1/SNUH_DC07_JCW0_RALP_0031.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 166, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 166, 512, 512)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 174, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 174, 512, 512)} \n",
      "\n",
      "1 35479\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task483_MSCR/nnUNetData_plans_v2.1_stage1/SNUH_DC07_JCW0_RALP_0011.npz\n",
      "1 35802\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task483_MSCR/nnUNetData_plans_v2.1_stage1/SNUH_DC07_JCW0_RALP_0021.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 253, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 253, 512, 512)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 253, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 253, 512, 512)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 262, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 262, 512, 512)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 328, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 328, 512, 512)} \n",
      "\n",
      "1 47435\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task483_MSCR/nnUNetData_plans_v2.1_stage1/SNUH_DC07_JCW0_RLPN_0003.npz\n",
      "1 49808\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task483_MSCR/nnUNetData_plans_v2.1_stage1/SNUH_DC07_JCW0_RLPN_0008.npz\n",
      "1 56588\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task483_MSCR/nnUNetData_plans_v2.1_stage1/SNUH_DC07_JCW0_RLPN_0002.npz\n",
      "1 68661\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task483_MSCR/nnUNetData_plans_v2.1_stage1/SNUH_DC07_JCW0_RALP_0000.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 166, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 166, 512, 512)} \n",
      "\n",
      "1 25038\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task483_MSCR/nnUNetData_plans_v2.1_stage1/SNUH_DC07_JCW0_RLPN_0009.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 161, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 161, 512, 512)} \n",
      "\n",
      "1 24967\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task483_MSCR/nnUNetData_plans_v2.1_stage1/SNUH_DC07_JCW0_RLPN_0014.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 282, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 282, 512, 512)} \n",
      "\n",
      "1 51213\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task483_MSCR/nnUNetData_plans_v2.1_stage1/SNUH_DC08_KHS0_ENME_0032.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 697, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 697, 512, 512)} \n",
      "\n",
      "1 203543\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task483_MSCR/nnUNetData_plans_v2.1_stage1/SNUH_DC08_KHS0_ENME_0039.npz\n",
      "not using nonzero mask for normalization\n",
      "Are we using the nonzero maks for normalizaion? OrderedDict([(0, False)])\n",
      "the median shape of the dataset is  [213.5 512.  512. ]\n",
      "the max shape in the dataset is  [697. 512. 512.]\n",
      "the min shape in the dataset is  [128. 512. 512.]\n",
      "we don't want feature maps smaller than  4  in the bottleneck\n",
      "the transposed median shape of the dataset is  [213.5 512.  512. ]\n",
      "[{'batch_size': 12, 'num_pool_per_axis': [7, 7], 'patch_size': array([512, 512]), 'median_patient_size_in_voxels': array([214, 512, 512]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}]\n",
      "Initializing to run preprocessing\n",
      "npz folder: /tf/temp/nnUNet/nnunet/nnUNet_raw_data_base/nnUNet_cropped_data/Task483_MSCR\n",
      "output_folder: /tf/temp/nnUNet/nnunet/preprocessed/Task483_MSCR\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 128, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 128, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 145, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 145, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 174, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 174, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 166, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 166, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "normalization done\n",
      "normalization done\n",
      "1 22206\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task483_MSCR/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC07_JCW0_RALP_0001.npz\n",
      "normalization done\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 253, 512, 512)} \n",
      "after: 1 32164\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task483_MSCR/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC07_JCW0_RALP_0031.npz\n",
      " {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 253, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 262, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 262, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 253, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 253, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "1 35802\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task483_MSCR/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC07_JCW0_RALP_0021.npz\n",
      "1 35479\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task483_MSCR/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC07_JCW0_RALP_0011.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 328, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 328, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "normalization done\n",
      "normalization done\n",
      "normalization done\n",
      "1 56588\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task483_MSCR/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC07_JCW0_RLPN_0002.npz\n",
      "1 47435\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task483_MSCR/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC07_JCW0_RLPN_0003.npz\n",
      "1 49808\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task483_MSCR/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC07_JCW0_RLPN_0008.npz\n",
      "1 68661\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task483_MSCR/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC07_JCW0_RALP_0000.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 166, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 166, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 25038\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task483_MSCR/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC07_JCW0_RLPN_0009.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 161, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 161, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 24967\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task483_MSCR/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC07_JCW0_RLPN_0014.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 282, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 282, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 51213\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task483_MSCR/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC08_KHS0_ENME_0032.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 697, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 697, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 203543\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task483_MSCR/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC08_KHS0_ENME_0039.npz\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!nnUNet_convert_decathlon_task -i /tf/temp/nnUNet/nnunet/Tasks/Task83_MSCR -output_task_id 483 # -i : task_dir\n",
    "!nnUNet_plan_and_preprocess -t 483 # --verify_dataset_integrity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'png'}\n",
      "use_mask_for_norm OrderedDict([(0, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 12, 'num_pool_per_axis': [7, 7], 'patch_size': array([512, 512]), 'median_patient_size_in_voxels': array([214, 512, 512]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /tf/temp/nnUNet/nnunet/preprocessed/Task483_MSCR/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "unpacking dataset\n",
      "done\n",
      "2021-12-03 18:31:21.632332: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-12-03 18:31:28.412198: Unable to plot network architecture:\n",
      "2021-12-03 18:31:28.461025: No module named 'hiddenlayer'\n",
      "2021-12-03 18:31:28.469845: \n",
      "printing the network instead:\n",
      "\n",
      "2021-12-03 18:31:28.476551: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (1): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (2): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (3): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (4): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (5): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (6): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (4): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (5): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (6): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-12-03 18:31:28.487963: \n",
      "\n",
      "2021-12-03 18:31:28.495613: \n",
      "epoch:  0\n",
      "2021-12-03 18:34:29.441951: train loss : -0.0079\n",
      "2021-12-03 18:34:42.732492: validation loss: -0.4048\n",
      "2021-12-03 18:34:42.740076: Average global foreground Dice: [0.6423]\n",
      "2021-12-03 18:34:42.746458: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 18:34:43.191006: lr: 0.00982\n",
      "2021-12-03 18:34:43.196557: This epoch took 194.695060 s\n",
      "\n",
      "2021-12-03 18:34:43.202258: \n",
      "epoch:  1\n",
      "2021-12-03 18:37:39.042322: train loss : -0.4523\n",
      "2021-12-03 18:37:52.345246: validation loss: -0.6311\n",
      "2021-12-03 18:37:52.353076: Average global foreground Dice: [0.779]\n",
      "2021-12-03 18:37:52.359107: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 18:37:52.894423: lr: 0.009639\n",
      "2021-12-03 18:37:53.016418: saving checkpoint...\n",
      "2021-12-03 18:37:54.427421: done, saving took 1.53 seconds\n",
      "2021-12-03 18:37:54.449974: This epoch took 191.241322 s\n",
      "\n",
      "2021-12-03 18:37:54.455347: \n",
      "epoch:  2\n",
      "2021-12-03 18:40:50.030518: train loss : -0.6227\n",
      "2021-12-03 18:41:03.335425: validation loss: -0.6985\n",
      "2021-12-03 18:41:03.342450: Average global foreground Dice: [0.8242]\n",
      "2021-12-03 18:41:03.348488: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 18:41:03.855382: lr: 0.009458\n",
      "2021-12-03 18:41:03.957397: saving checkpoint...\n",
      "2021-12-03 18:41:05.278987: done, saving took 1.42 seconds\n",
      "2021-12-03 18:41:05.306629: This epoch took 190.845236 s\n",
      "\n",
      "2021-12-03 18:41:05.312431: \n",
      "epoch:  3\n",
      "2021-12-03 18:44:00.719507: train loss : -0.6757\n",
      "2021-12-03 18:44:13.989971: validation loss: -0.7503\n",
      "2021-12-03 18:44:13.996302: Average global foreground Dice: [0.8539]\n",
      "2021-12-03 18:44:14.001690: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 18:44:14.508340: lr: 0.009277\n",
      "2021-12-03 18:44:14.600755: saving checkpoint...\n",
      "2021-12-03 18:44:16.017472: done, saving took 1.50 seconds\n",
      "2021-12-03 18:44:16.045035: This epoch took 190.727326 s\n",
      "\n",
      "2021-12-03 18:44:16.050888: \n",
      "epoch:  4\n",
      "2021-12-03 18:47:11.538017: train loss : -0.7049\n",
      "2021-12-03 18:47:24.884264: validation loss: -0.7748\n",
      "2021-12-03 18:47:24.890371: Average global foreground Dice: [0.8678]\n",
      "2021-12-03 18:47:24.896522: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 18:47:25.392004: lr: 0.009095\n",
      "2021-12-03 18:47:25.471509: saving checkpoint...\n",
      "2021-12-03 18:47:26.803732: done, saving took 1.41 seconds\n",
      "2021-12-03 18:47:26.830221: This epoch took 190.773707 s\n",
      "\n",
      "2021-12-03 18:47:26.836860: \n",
      "epoch:  5\n",
      "2021-12-03 18:50:22.190396: train loss : -0.7506\n",
      "2021-12-03 18:50:35.511549: validation loss: -0.8064\n",
      "2021-12-03 18:50:35.519711: Average global foreground Dice: [0.8846]\n",
      "2021-12-03 18:50:35.525605: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 18:50:36.024192: lr: 0.008913\n",
      "2021-12-03 18:50:36.105063: saving checkpoint...\n",
      "2021-12-03 18:50:37.412132: done, saving took 1.38 seconds\n",
      "2021-12-03 18:50:37.434086: This epoch took 190.591522 s\n",
      "\n",
      "2021-12-03 18:50:37.440530: \n",
      "epoch:  6\n",
      "2021-12-03 18:53:32.864723: train loss : -0.7829\n",
      "2021-12-03 18:53:46.177751: validation loss: -0.8093\n",
      "2021-12-03 18:53:46.184954: Average global foreground Dice: [0.8866]\n",
      "2021-12-03 18:53:46.190679: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 18:53:46.699480: lr: 0.008731\n",
      "2021-12-03 18:53:46.791811: saving checkpoint...\n",
      "2021-12-03 18:53:48.277139: done, saving took 1.57 seconds\n",
      "2021-12-03 18:53:48.306286: This epoch took 190.859540 s\n",
      "\n",
      "2021-12-03 18:53:48.313337: \n",
      "epoch:  7\n",
      "2021-12-03 18:56:43.622108: train loss : -0.8183\n",
      "2021-12-03 18:56:56.940074: validation loss: -0.8715\n",
      "2021-12-03 18:56:56.947803: Average global foreground Dice: [0.9248]\n",
      "2021-12-03 18:56:56.956664: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 18:56:57.549372: lr: 0.008548\n",
      "2021-12-03 18:56:57.595138: saving checkpoint...\n",
      "2021-12-03 18:56:58.852622: done, saving took 1.30 seconds\n",
      "2021-12-03 18:56:58.875920: This epoch took 190.556111 s\n",
      "\n",
      "2021-12-03 18:56:58.883098: \n",
      "epoch:  8\n",
      "2021-12-03 18:59:54.343055: train loss : -0.8222\n",
      "2021-12-03 19:00:07.628121: validation loss: -0.8670\n",
      "2021-12-03 19:00:07.637178: Average global foreground Dice: [0.9254]\n",
      "2021-12-03 19:00:07.643577: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 19:00:08.138112: lr: 0.008364\n",
      "2021-12-03 19:00:08.183827: saving checkpoint...\n",
      "2021-12-03 19:00:09.491114: done, saving took 1.35 seconds\n",
      "2021-12-03 19:00:09.511988: This epoch took 190.622348 s\n",
      "\n",
      "2021-12-03 19:00:09.518076: \n",
      "epoch:  9\n",
      "2021-12-03 19:03:05.028589: train loss : -0.8375\n",
      "2021-12-03 19:03:18.330840: validation loss: -0.8643\n",
      "2021-12-03 19:03:18.337316: Average global foreground Dice: [0.9215]\n",
      "2021-12-03 19:03:18.343997: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 19:03:18.852185: lr: 0.008181\n",
      "2021-12-03 19:03:18.897384: saving checkpoint...\n",
      "2021-12-03 19:03:20.283957: done, saving took 1.43 seconds\n",
      "2021-12-03 19:03:20.306406: This epoch took 190.782183 s\n",
      "\n",
      "2021-12-03 19:03:20.312757: \n",
      "epoch:  10\n",
      "2021-12-03 19:06:15.804284: train loss : -0.8420\n",
      "2021-12-03 19:06:29.116014: validation loss: -0.8799\n",
      "2021-12-03 19:06:29.122783: Average global foreground Dice: [0.9313]\n",
      "2021-12-03 19:06:29.129552: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 19:06:29.628338: lr: 0.007996\n",
      "2021-12-03 19:06:29.673805: saving checkpoint...\n",
      "2021-12-03 19:06:31.096165: done, saving took 1.46 seconds\n",
      "2021-12-03 19:06:31.123656: This epoch took 190.804394 s\n",
      "\n",
      "2021-12-03 19:06:31.130204: \n",
      "epoch:  11\n",
      "2021-12-03 19:09:26.706301: train loss : -0.8540\n",
      "2021-12-03 19:09:40.022260: validation loss: -0.8934\n",
      "2021-12-03 19:09:40.029917: Average global foreground Dice: [0.9382]\n",
      "2021-12-03 19:09:40.036898: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 19:09:40.532620: lr: 0.007811\n",
      "2021-12-03 19:09:40.610405: saving checkpoint...\n",
      "2021-12-03 19:09:41.891454: done, saving took 1.35 seconds\n",
      "2021-12-03 19:09:41.918494: This epoch took 190.781725 s\n",
      "\n",
      "2021-12-03 19:09:41.924768: \n",
      "epoch:  12\n",
      "/tf/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-12-03 19:12:37.498977: train loss : -0.8525\n",
      "2021-12-03 19:12:50.817010: validation loss: -0.8883\n",
      "2021-12-03 19:12:50.824503: Average global foreground Dice: [0.9344]\n",
      "2021-12-03 19:12:50.830948: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 19:12:51.337605: lr: 0.007626\n",
      "2021-12-03 19:12:51.404581: saving checkpoint...\n",
      "2021-12-03 19:12:52.767828: done, saving took 1.42 seconds\n",
      "2021-12-03 19:12:52.805248: This epoch took 190.873661 s\n",
      "\n",
      "2021-12-03 19:12:52.811730: \n",
      "epoch:  13\n",
      "2021-12-03 19:15:48.233922: train loss : -0.8588\n",
      "2021-12-03 19:16:01.557527: validation loss: -0.9020\n",
      "2021-12-03 19:16:01.571470: Average global foreground Dice: [0.9432]\n",
      "2021-12-03 19:16:01.577997: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 19:16:02.149357: lr: 0.00744\n",
      "2021-12-03 19:16:02.195703: saving checkpoint...\n",
      "2021-12-03 19:16:03.617759: done, saving took 1.46 seconds\n",
      "2021-12-03 19:16:03.638224: This epoch took 190.820300 s\n",
      "\n",
      "2021-12-03 19:16:03.644864: \n",
      "epoch:  14\n",
      "2021-12-03 19:18:58.995212: train loss : -0.8711\n",
      "2021-12-03 19:19:12.327019: validation loss: -0.9035\n",
      "2021-12-03 19:19:12.334493: Average global foreground Dice: [0.9433]\n",
      "2021-12-03 19:19:12.341187: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 19:19:12.836076: lr: 0.007254\n",
      "2021-12-03 19:19:12.880577: saving checkpoint...\n",
      "2021-12-03 19:19:14.159481: done, saving took 1.32 seconds\n",
      "2021-12-03 19:19:14.183309: This epoch took 190.531813 s\n",
      "\n",
      "2021-12-03 19:19:14.190387: \n",
      "epoch:  15\n",
      "2021-12-03 19:22:09.726488: train loss : -0.8797\n",
      "2021-12-03 19:22:23.066659: validation loss: -0.9051\n",
      "2021-12-03 19:22:23.073224: Average global foreground Dice: [0.9469]\n",
      "2021-12-03 19:22:23.079004: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 19:22:23.572964: lr: 0.007067\n",
      "2021-12-03 19:22:23.618663: saving checkpoint...\n",
      "2021-12-03 19:22:24.889612: done, saving took 1.31 seconds\n",
      "2021-12-03 19:22:24.913710: This epoch took 190.716845 s\n",
      "\n",
      "2021-12-03 19:22:24.919826: \n",
      "epoch:  16\n",
      "2021-12-03 19:25:20.316145: train loss : -0.8670\n",
      "2021-12-03 19:25:33.642323: validation loss: -0.9019\n",
      "2021-12-03 19:25:33.649081: Average global foreground Dice: [0.9417]\n",
      "2021-12-03 19:25:33.655213: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 19:25:34.148611: lr: 0.00688\n",
      "2021-12-03 19:25:34.194752: saving checkpoint...\n",
      "2021-12-03 19:25:35.672711: done, saving took 1.52 seconds\n",
      "2021-12-03 19:25:35.696443: This epoch took 190.769524 s\n",
      "\n",
      "2021-12-03 19:25:35.702772: \n",
      "epoch:  17\n",
      "2021-12-03 19:28:30.930357: train loss : -0.8821\n",
      "2021-12-03 19:28:44.247352: validation loss: -0.9145\n",
      "2021-12-03 19:28:44.255352: Average global foreground Dice: [0.9496]\n",
      "2021-12-03 19:28:44.261670: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 19:28:44.770886: lr: 0.006692\n",
      "2021-12-03 19:28:44.816733: saving checkpoint...\n",
      "2021-12-03 19:28:46.180564: done, saving took 1.40 seconds\n",
      "2021-12-03 19:28:46.204556: This epoch took 190.495779 s\n",
      "\n",
      "2021-12-03 19:28:46.210866: \n",
      "epoch:  18\n",
      "2021-12-03 19:31:41.389633: train loss : -0.8865\n",
      "2021-12-03 19:31:54.717696: validation loss: -0.9178\n",
      "2021-12-03 19:31:54.724523: Average global foreground Dice: [0.9527]\n",
      "2021-12-03 19:31:54.731514: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 19:31:55.221911: lr: 0.006504\n",
      "2021-12-03 19:31:55.267269: saving checkpoint...\n",
      "2021-12-03 19:31:56.589594: done, saving took 1.36 seconds\n",
      "2021-12-03 19:31:56.613955: This epoch took 190.397197 s\n",
      "\n",
      "2021-12-03 19:31:56.619919: \n",
      "epoch:  19\n",
      "2021-12-03 19:34:51.785152: train loss : -0.8983\n",
      "2021-12-03 19:35:05.092251: validation loss: -0.9008\n",
      "2021-12-03 19:35:05.100325: Average global foreground Dice: [0.9417]\n",
      "2021-12-03 19:35:05.106647: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 19:35:05.677312: lr: 0.006314\n",
      "2021-12-03 19:35:05.722623: saving checkpoint...\n",
      "2021-12-03 19:35:07.021357: done, saving took 1.34 seconds\n",
      "2021-12-03 19:35:07.042124: This epoch took 190.415699 s\n",
      "\n",
      "2021-12-03 19:35:07.047787: \n",
      "epoch:  20\n",
      "2021-12-03 19:38:02.242643: train loss : -0.8924\n",
      "2021-12-03 19:38:15.549774: validation loss: -0.9240\n",
      "2021-12-03 19:38:15.556840: Average global foreground Dice: [0.9558]\n",
      "2021-12-03 19:38:15.564001: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 19:38:16.064387: lr: 0.006125\n",
      "2021-12-03 19:38:16.110593: saving checkpoint...\n",
      "2021-12-03 19:38:17.558311: done, saving took 1.49 seconds\n",
      "2021-12-03 19:38:17.580042: This epoch took 190.526254 s\n",
      "\n",
      "2021-12-03 19:38:17.585925: \n",
      "epoch:  21\n",
      "2021-12-03 19:41:12.963985: train loss : -0.8940\n",
      "2021-12-03 19:41:26.285259: validation loss: -0.9240\n",
      "2021-12-03 19:41:26.293513: Average global foreground Dice: [0.9562]\n",
      "2021-12-03 19:41:26.301798: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 19:41:26.799881: lr: 0.005934\n",
      "2021-12-03 19:41:26.845104: saving checkpoint...\n",
      "2021-12-03 19:41:28.151642: done, saving took 1.35 seconds\n",
      "2021-12-03 19:41:28.173456: This epoch took 190.581078 s\n",
      "\n",
      "2021-12-03 19:41:28.179442: \n",
      "epoch:  22\n",
      "2021-12-03 19:44:23.624130: train loss : -0.9058\n",
      "2021-12-03 19:44:36.961628: validation loss: -0.9310\n",
      "2021-12-03 19:44:36.968344: Average global foreground Dice: [0.9597]\n",
      "2021-12-03 19:44:36.975483: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 19:44:37.463875: lr: 0.005743\n",
      "2021-12-03 19:44:37.509454: saving checkpoint...\n",
      "2021-12-03 19:44:38.792316: done, saving took 1.32 seconds\n",
      "2021-12-03 19:44:38.814737: This epoch took 190.628348 s\n",
      "\n",
      "2021-12-03 19:44:38.821113: \n",
      "epoch:  23\n",
      "2021-12-03 19:47:34.325664: train loss : -0.9104\n",
      "2021-12-03 19:47:47.630531: validation loss: -0.9307\n",
      "2021-12-03 19:47:47.636815: Average global foreground Dice: [0.9593]\n",
      "2021-12-03 19:47:47.643138: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 19:47:48.130282: lr: 0.005551\n",
      "2021-12-03 19:47:48.174841: saving checkpoint...\n",
      "2021-12-03 19:47:49.574499: done, saving took 1.44 seconds\n",
      "2021-12-03 19:47:49.597847: This epoch took 190.770269 s\n",
      "\n",
      "2021-12-03 19:47:49.604239: \n",
      "epoch:  24\n",
      "2021-12-03 19:50:44.955106: train loss : -0.9087\n",
      "2021-12-03 19:50:58.283404: validation loss: -0.9223\n",
      "2021-12-03 19:50:58.290256: Average global foreground Dice: [0.9545]\n",
      "2021-12-03 19:50:58.296334: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 19:50:58.788335: lr: 0.005359\n",
      "2021-12-03 19:50:58.843366: saving checkpoint...\n",
      "2021-12-03 19:51:00.139105: done, saving took 1.34 seconds\n",
      "2021-12-03 19:51:00.167169: This epoch took 190.556333 s\n",
      "\n",
      "2021-12-03 19:51:00.172995: \n",
      "epoch:  25\n",
      "2021-12-03 19:53:46.770838: train loss : -0.9063\n",
      "2021-12-03 19:53:59.339515: validation loss: -0.9324\n",
      "2021-12-03 19:53:59.346960: Average global foreground Dice: [0.9594]\n",
      "2021-12-03 19:53:59.353546: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 19:53:59.863433: lr: 0.005166\n",
      "2021-12-03 19:53:59.948649: saving checkpoint...\n",
      "2021-12-03 19:54:01.334742: done, saving took 1.46 seconds\n",
      "2021-12-03 19:54:01.362359: This epoch took 181.182940 s\n",
      "\n",
      "2021-12-03 19:54:01.368828: \n",
      "epoch:  26\n",
      "2021-12-03 19:56:49.757793: train loss : -0.9096\n",
      "2021-12-03 19:57:02.962368: validation loss: -0.9352\n",
      "2021-12-03 19:57:02.970635: Average global foreground Dice: [0.962]\n",
      "2021-12-03 19:57:02.978219: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 19:57:03.470615: lr: 0.004971\n",
      "2021-12-03 19:57:03.516351: saving checkpoint...\n",
      "2021-12-03 19:57:04.936322: done, saving took 1.46 seconds\n",
      "2021-12-03 19:57:04.959230: This epoch took 183.584389 s\n",
      "\n",
      "2021-12-03 19:57:04.966264: \n",
      "epoch:  27\n",
      "2021-12-03 19:59:59.962526: train loss : -0.9148\n",
      "2021-12-03 20:00:13.165948: validation loss: -0.9285\n",
      "2021-12-03 20:00:13.173979: Average global foreground Dice: [0.9585]\n",
      "2021-12-03 20:00:13.179745: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 20:00:13.681820: lr: 0.004776\n",
      "2021-12-03 20:00:13.727620: saving checkpoint...\n",
      "2021-12-03 20:00:15.056462: done, saving took 1.37 seconds\n",
      "2021-12-03 20:00:15.079467: This epoch took 190.107940 s\n",
      "\n",
      "2021-12-03 20:00:15.086363: \n",
      "epoch:  28\n",
      "2021-12-03 20:03:02.116625: train loss : -0.9184\n",
      "2021-12-03 20:03:14.689597: validation loss: -0.9350\n",
      "2021-12-03 20:03:14.696305: Average global foreground Dice: [0.9613]\n",
      "2021-12-03 20:03:14.702314: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 20:03:15.219117: lr: 0.004581\n",
      "2021-12-03 20:03:15.263926: saving checkpoint...\n",
      "2021-12-03 20:03:16.595823: done, saving took 1.37 seconds\n",
      "2021-12-03 20:03:16.619595: This epoch took 181.526736 s\n",
      "\n",
      "2021-12-03 20:03:16.626020: \n",
      "epoch:  29\n",
      "2021-12-03 20:06:04.939070: train loss : -0.9226\n",
      "2021-12-03 20:06:18.155804: validation loss: -0.9438\n",
      "2021-12-03 20:06:18.163301: Average global foreground Dice: [0.9663]\n",
      "2021-12-03 20:06:18.169750: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 20:06:18.663910: lr: 0.004384\n",
      "2021-12-03 20:06:18.709624: saving checkpoint...\n",
      "2021-12-03 20:06:20.043571: done, saving took 1.37 seconds\n",
      "2021-12-03 20:06:20.066669: This epoch took 183.433637 s\n",
      "\n",
      "2021-12-03 20:06:20.073205: \n",
      "epoch:  30\n",
      "2021-12-03 20:09:15.871434: train loss : -0.9267\n",
      "2021-12-03 20:09:29.236923: validation loss: -0.9432\n",
      "2021-12-03 20:09:29.243830: Average global foreground Dice: [0.9657]\n",
      "2021-12-03 20:09:29.250630: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 20:09:29.741808: lr: 0.004186\n",
      "2021-12-03 20:09:29.786474: saving checkpoint...\n",
      "2021-12-03 20:09:31.658884: done, saving took 1.91 seconds\n",
      "2021-12-03 20:09:31.684469: This epoch took 191.604796 s\n",
      "\n",
      "2021-12-03 20:09:31.691187: \n",
      "epoch:  31\n",
      "2021-12-03 20:12:27.081055: train loss : -0.9258\n",
      "2021-12-03 20:12:40.394741: validation loss: -0.9351\n",
      "2021-12-03 20:12:40.403834: Average global foreground Dice: [0.963]\n",
      "2021-12-03 20:12:40.410502: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 20:12:40.909286: lr: 0.003987\n",
      "2021-12-03 20:12:40.980097: saving checkpoint...\n",
      "2021-12-03 20:12:42.436799: done, saving took 1.52 seconds\n",
      "2021-12-03 20:12:42.464587: This epoch took 190.766866 s\n",
      "\n",
      "2021-12-03 20:12:42.470684: \n",
      "epoch:  32\n",
      "2021-12-03 20:15:37.864830: train loss : -0.9307\n",
      "2021-12-03 20:15:51.179688: validation loss: -0.9461\n",
      "2021-12-03 20:15:51.186821: Average global foreground Dice: [0.9685]\n",
      "2021-12-03 20:15:51.193126: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 20:15:51.701333: lr: 0.003787\n",
      "2021-12-03 20:15:51.746487: saving checkpoint...\n",
      "2021-12-03 20:15:53.084249: done, saving took 1.38 seconds\n",
      "2021-12-03 20:15:53.105130: This epoch took 190.628367 s\n",
      "\n",
      "2021-12-03 20:15:53.110619: \n",
      "epoch:  33\n",
      "2021-12-03 20:18:48.446395: train loss : -0.9307\n",
      "2021-12-03 20:19:01.766956: validation loss: -0.9456\n",
      "2021-12-03 20:19:01.774436: Average global foreground Dice: [0.968]\n",
      "2021-12-03 20:19:01.781374: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 20:19:02.303326: lr: 0.003586\n",
      "2021-12-03 20:19:02.349463: saving checkpoint...\n",
      "2021-12-03 20:19:03.893526: done, saving took 1.58 seconds\n",
      "2021-12-03 20:19:03.916555: This epoch took 190.800426 s\n",
      "\n",
      "2021-12-03 20:19:03.923820: \n",
      "epoch:  34\n",
      "2021-12-03 20:21:59.201622: train loss : -0.9316\n",
      "2021-12-03 20:22:12.527809: validation loss: -0.9465\n",
      "2021-12-03 20:22:12.535891: Average global foreground Dice: [0.9676]\n",
      "2021-12-03 20:22:12.542395: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 20:22:13.037324: lr: 0.003384\n",
      "2021-12-03 20:22:13.083840: saving checkpoint...\n",
      "2021-12-03 20:22:14.489002: done, saving took 1.44 seconds\n",
      "2021-12-03 20:22:14.512194: This epoch took 190.582433 s\n",
      "\n",
      "2021-12-03 20:22:14.517782: \n",
      "epoch:  35\n",
      "2021-12-03 20:25:09.907058: train loss : -0.9322\n",
      "2021-12-03 20:25:23.237264: validation loss: -0.9446\n",
      "2021-12-03 20:25:23.244916: Average global foreground Dice: [0.9667]\n",
      "2021-12-03 20:25:23.251931: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 20:25:23.768353: lr: 0.00318\n",
      "2021-12-03 20:25:23.814809: saving checkpoint...\n",
      "2021-12-03 20:25:25.271154: done, saving took 1.50 seconds\n",
      "2021-12-03 20:25:25.292613: This epoch took 190.768888 s\n",
      "\n",
      "2021-12-03 20:25:25.298420: \n",
      "epoch:  36\n",
      "2021-12-03 20:28:20.407744: train loss : -0.9270\n",
      "2021-12-03 20:28:33.732010: validation loss: -0.9392\n",
      "2021-12-03 20:28:33.739293: Average global foreground Dice: [0.9641]\n",
      "2021-12-03 20:28:33.745612: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 20:28:34.236590: lr: 0.002975\n",
      "2021-12-03 20:28:34.321720: saving checkpoint...\n",
      "2021-12-03 20:28:35.727777: done, saving took 1.49 seconds\n",
      "2021-12-03 20:28:35.752805: This epoch took 190.448024 s\n",
      "\n",
      "2021-12-03 20:28:35.759566: \n",
      "epoch:  37\n",
      "2021-12-03 20:31:30.961015: train loss : -0.9235\n",
      "2021-12-03 20:31:44.287771: validation loss: -0.9480\n",
      "2021-12-03 20:31:44.295172: Average global foreground Dice: [0.9691]\n",
      "2021-12-03 20:31:44.303316: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 20:31:44.886014: lr: 0.002768\n",
      "2021-12-03 20:31:44.930799: saving checkpoint...\n",
      "2021-12-03 20:31:46.762222: done, saving took 1.87 seconds\n",
      "2021-12-03 20:31:46.784781: This epoch took 191.018825 s\n",
      "\n",
      "2021-12-03 20:31:46.791002: \n",
      "epoch:  38\n",
      "2021-12-03 20:34:41.887601: train loss : -0.9320\n",
      "2021-12-03 20:34:55.214152: validation loss: -0.9451\n",
      "2021-12-03 20:34:55.221092: Average global foreground Dice: [0.9669]\n",
      "2021-12-03 20:34:55.227467: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 20:34:55.751292: lr: 0.00256\n",
      "2021-12-03 20:34:55.796226: saving checkpoint...\n",
      "2021-12-03 20:34:57.139980: done, saving took 1.38 seconds\n",
      "2021-12-03 20:34:57.164662: This epoch took 190.367455 s\n",
      "\n",
      "2021-12-03 20:34:57.170874: \n",
      "epoch:  39\n",
      "2021-12-03 20:37:44.877164: train loss : -0.9327\n",
      "2021-12-03 20:37:57.375062: validation loss: -0.9460\n",
      "2021-12-03 20:37:57.382710: Average global foreground Dice: [0.968]\n",
      "2021-12-03 20:37:57.389689: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 20:37:57.887208: lr: 0.002349\n",
      "2021-12-03 20:37:57.933003: saving checkpoint...\n",
      "2021-12-03 20:37:59.336877: done, saving took 1.44 seconds\n",
      "2021-12-03 20:37:59.358777: This epoch took 182.181759 s\n",
      "\n",
      "2021-12-03 20:37:59.364967: \n",
      "epoch:  40\n",
      "2021-12-03 20:40:42.133767: train loss : -0.9317\n",
      "2021-12-03 20:40:54.615376: validation loss: -0.9494\n",
      "2021-12-03 20:40:54.623018: Average global foreground Dice: [0.97]\n",
      "2021-12-03 20:40:54.629714: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 20:40:55.140957: lr: 0.002137\n",
      "2021-12-03 20:40:55.186934: saving checkpoint...\n",
      "2021-12-03 20:40:56.590942: done, saving took 1.44 seconds\n",
      "2021-12-03 20:40:56.612769: This epoch took 177.242006 s\n",
      "\n",
      "2021-12-03 20:40:56.618420: \n",
      "epoch:  41\n",
      "2021-12-03 20:43:40.144887: train loss : -0.9327\n",
      "2021-12-03 20:43:52.753038: validation loss: -0.9495\n",
      "2021-12-03 20:43:52.760748: Average global foreground Dice: [0.9697]\n",
      "2021-12-03 20:43:52.767188: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 20:43:53.267105: lr: 0.001922\n",
      "2021-12-03 20:43:53.313857: saving checkpoint...\n",
      "2021-12-03 20:43:54.753635: done, saving took 1.48 seconds\n",
      "2021-12-03 20:43:54.775647: This epoch took 178.150836 s\n",
      "\n",
      "2021-12-03 20:43:54.782870: \n",
      "epoch:  42\n",
      "2021-12-03 20:46:44.718982: train loss : -0.9379\n",
      "2021-12-03 20:46:58.078585: validation loss: -0.9460\n",
      "2021-12-03 20:46:58.085491: Average global foreground Dice: [0.9686]\n",
      "2021-12-03 20:46:58.092107: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 20:46:58.584577: lr: 0.001704\n",
      "2021-12-03 20:46:58.661957: saving checkpoint...\n",
      "2021-12-03 20:47:00.368018: done, saving took 1.78 seconds\n",
      "2021-12-03 20:47:00.396391: This epoch took 185.608014 s\n",
      "\n",
      "2021-12-03 20:47:00.403151: \n",
      "epoch:  43\n",
      "2021-12-03 20:49:55.828333: train loss : -0.9398\n",
      "2021-12-03 20:50:09.163497: validation loss: -0.9499\n",
      "2021-12-03 20:50:09.170788: Average global foreground Dice: [0.9699]\n",
      "2021-12-03 20:50:09.177380: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 20:50:09.668471: lr: 0.001483\n",
      "2021-12-03 20:50:09.744609: saving checkpoint...\n",
      "2021-12-03 20:50:11.239918: done, saving took 1.57 seconds\n",
      "2021-12-03 20:50:11.268701: This epoch took 190.859413 s\n",
      "\n",
      "2021-12-03 20:50:11.274743: \n",
      "epoch:  44\n",
      "2021-12-03 20:53:06.651523: train loss : -0.9392\n",
      "2021-12-03 20:53:19.984547: validation loss: -0.9463\n",
      "2021-12-03 20:53:19.993937: Average global foreground Dice: [0.9688]\n",
      "2021-12-03 20:53:20.000829: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 20:53:20.492707: lr: 0.001259\n",
      "2021-12-03 20:53:20.539004: saving checkpoint...\n",
      "2021-12-03 20:53:21.947337: done, saving took 1.45 seconds\n",
      "2021-12-03 20:53:21.968439: This epoch took 190.687501 s\n",
      "\n",
      "2021-12-03 20:53:21.974575: \n",
      "epoch:  45\n",
      "2021-12-03 20:56:17.398988: train loss : -0.9396\n",
      "2021-12-03 20:56:30.735773: validation loss: -0.9492\n",
      "2021-12-03 20:56:30.742940: Average global foreground Dice: [0.9697]\n",
      "2021-12-03 20:56:30.750079: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 20:56:31.256780: lr: 0.00103\n",
      "2021-12-03 20:56:31.302681: saving checkpoint...\n",
      "2021-12-03 20:56:32.664119: done, saving took 1.40 seconds\n",
      "2021-12-03 20:56:32.686950: This epoch took 190.706153 s\n",
      "\n",
      "2021-12-03 20:56:32.694901: \n",
      "epoch:  46\n",
      "2021-12-03 20:59:28.118824: train loss : -0.9408\n",
      "2021-12-03 20:59:41.475040: validation loss: -0.9481\n",
      "2021-12-03 20:59:41.481628: Average global foreground Dice: [0.9699]\n",
      "2021-12-03 20:59:41.487144: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 20:59:41.976134: lr: 0.000795\n",
      "2021-12-03 20:59:42.020592: saving checkpoint...\n",
      "2021-12-03 20:59:43.665929: done, saving took 1.68 seconds\n",
      "2021-12-03 20:59:43.688769: This epoch took 190.985673 s\n",
      "\n",
      "2021-12-03 20:59:43.695116: \n",
      "epoch:  47\n",
      "2021-12-03 21:02:39.236747: train loss : -0.9405\n",
      "2021-12-03 21:02:52.578655: validation loss: -0.9490\n",
      "2021-12-03 21:02:52.584745: Average global foreground Dice: [0.9703]\n",
      "2021-12-03 21:02:52.591668: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 21:02:53.099837: lr: 0.000552\n",
      "2021-12-03 21:02:53.145101: saving checkpoint...\n",
      "2021-12-03 21:02:54.482991: done, saving took 1.38 seconds\n",
      "2021-12-03 21:02:54.511329: This epoch took 190.810224 s\n",
      "\n",
      "2021-12-03 21:02:54.517856: \n",
      "epoch:  48\n",
      "2021-12-03 21:05:50.115014: train loss : -0.9429\n",
      "2021-12-03 21:06:03.467582: validation loss: -0.9470\n",
      "2021-12-03 21:06:03.474229: Average global foreground Dice: [0.9692]\n",
      "2021-12-03 21:06:03.480948: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 21:06:03.971071: lr: 0.000296\n",
      "2021-12-03 21:06:04.053497: saving checkpoint...\n",
      "2021-12-03 21:06:05.398267: done, saving took 1.42 seconds\n",
      "2021-12-03 21:06:05.426887: This epoch took 190.901947 s\n",
      "\n",
      "2021-12-03 21:06:05.433221: \n",
      "epoch:  49\n",
      "2021-12-03 21:09:00.791707: train loss : -0.9423\n",
      "2021-12-03 21:09:14.123752: validation loss: -0.9521\n",
      "2021-12-03 21:09:14.131437: Average global foreground Dice: [0.9714]\n",
      "2021-12-03 21:09:14.138898: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-03 21:09:14.706456: lr: 0.0\n",
      "2021-12-03 21:09:14.712104: saving scheduled checkpoint file...\n",
      "2021-12-03 21:09:14.757374: saving checkpoint...\n",
      "2021-12-03 21:09:15.979026: done, saving took 1.26 seconds\n",
      "2021-12-03 21:09:15.997049: done\n",
      "2021-12-03 21:09:16.043023: saving checkpoint...\n",
      "2021-12-03 21:09:17.520648: done, saving took 1.52 seconds\n",
      "2021-12-03 21:09:17.543912: This epoch took 192.104630 s\n",
      "\n",
      "2021-12-03 21:09:17.589332: saving checkpoint...\n",
      "2021-12-03 21:09:18.792823: done, saving took 1.24 seconds\n",
      "SNUH_DC07_JCW0_RALP_0000 (2, 328, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "SNUH_DC07_JCW0_RALP_0001 (2, 128, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RALP_0011 (2, 166, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RALP_0021 (2, 174, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RALP_0031 (2, 145, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RLPN_0002 (2, 262, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RLPN_0003 (2, 253, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RLPN_0008 (2, 253, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RLPN_0009 (2, 166, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RLPN_0014 (2, 161, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC08_KHS0_ENME_0032 (2, 282, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC08_KHS0_ENME_0039 (2, 697, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-12-03 21:15:51.944888: finished prediction\n",
      "2021-12-03 21:15:51.953677: evaluation of raw predictions\n",
      "2021-12-03 21:16:02.025433: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.9713421027137256\n",
      "after:  0.34906735729403354\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "!nnUNet_train 2d nnUNetTrainerV2 483 all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating \"Task85_GRSL\" Image & Label ..\n",
      "Print surgery : Graspers (straight) (OLYMPUS) (GRSL-UCOL)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6daece0f5ab4b7c9240ef2e3df01e80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 9)\n",
      "(512, 512, 129)\n",
      "(512, 512, 48)\n",
      "(512, 512, 116)\n",
      "(512, 512, 8)\n",
      "(512, 512, 10)\n",
      "(512, 512, 81)\n",
      "(512, 512, 145)\n",
      "(512, 512, 79)\n",
      "(512, 512, 180)\n",
      "\"Task85_GRSL\" Image & Label Completed !!\n"
     ]
    }
   ],
   "source": [
    "png2nifti(surgery_NUM=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/temp/nnUNet/nnunet/Tasks/Task85_GRSL/dataset.json <-- created!\n"
     ]
    }
   ],
   "source": [
    "json_mk('/tf/temp/nnUNet/nnunet/Tasks/Task85_GRSL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "SNUH_DC07_JCW0_RALP_0000\n",
      "SNUH_DC07_JCW0_RALP_0001\n",
      "SNUH_DC07_JCW0_RALP_0008\n",
      "SNUH_DC07_JCW0_RALP_0010\n",
      "SNUH_DC07_JCW0_RALP_0011\n",
      "SNUH_DC07_JCW0_RALP_0012\n",
      "SNUH_DC07_JCW0_RALP_0013\n",
      "SNUH_DC07_JCW0_RALP_0020\n",
      "before crop: (1, 8, 512, 512) after crop: (1, 8, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (1, 9, 512, 512) after crop: (1, 9, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (1, 10, 512, 512) after crop: (1, 10, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "SNUH_DC07_JCW0_RALP_0021\n",
      "SNUH_DC07_JCW0_RALP_0031\n",
      "before crop: (1, 48, 512, 512) after crop: (1, 48, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (1, 116, 512, 512) after crop: (1, 116, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (1, 79, 512, 512) after crop: (1, 79, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (1, 81, 512, 512) after crop: (1, 81, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (1, 129, 512, 512) after crop: (1, 129, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (1, 145, 512, 512) after crop: (1, 145, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (1, 180, 512, 512) after crop: (1, 180, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Task485_GRSL\n",
      "number of threads:  (8, 8) \n",
      "\n",
      "not using nonzero mask for normalization\n",
      "Are we using the nonzero mask for normalizaion? OrderedDict([(0, False)])\n",
      "the median shape of the dataset is  [ 80. 512. 512.]\n",
      "the max shape in the dataset is  [180. 512. 512.]\n",
      "the min shape in the dataset is  [  8. 512. 512.]\n",
      "we don't want feature maps smaller than  4  in the bottleneck\n",
      "the transposed median shape of the dataset is  [ 80. 512. 512.]\n",
      "generating configuration for 3d_fullres\n",
      "generating configuration for 3d_lowres\n",
      "{0: {'batch_size': 2, 'num_pool_per_axis': [3, 4, 4], 'patch_size': array([ 40, 256, 240]), 'median_patient_size_in_voxels': array([ 62, 395, 395]), 'current_spacing': array([1.29525631, 1.29525631, 1.29525631]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': True, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}, 1: {'batch_size': 2, 'num_pool_per_axis': [3, 4, 4], 'patch_size': array([ 40, 256, 240]), 'median_patient_size_in_voxels': array([ 80, 512, 512]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': True, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}}\n",
      "transpose forward [0, 1, 2]\n",
      "transpose backward [0, 1, 2]\n",
      "Initializing to run preprocessing\n",
      "npz folder: /tf/temp/nnUNet/nnunet/nnUNet_raw_data_base/nnUNet_cropped_data/Task485_GRSL\n",
      "output_folder: /tf/temp/nnUNet/nnunet/preprocessed/Task485_GRSL\n",
      "no separate z, order 3\n",
      "no separate z, order 3\n",
      "no separate z, order 3\n",
      "no separate z, order 3\n",
      "no separate z, order 1\n",
      "no separate z, order 1\n",
      "no separate z, order 1\n",
      "no separate z, order 3\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 8, 512, 512)} \n",
      "after:  {'spacing': array([1.29525631, 1.29525631, 1.29525631]), 'data.shape (data is resampled)': (1, 6, 395, 395)} \n",
      "\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task485_GRSL/nnUNetData_plans_v2.1_stage0/SNUH_DC07_JCW0_RALP_0012.npz\n",
      "no separate z, order 3\n",
      "no separate z, order 3\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 9, 512, 512)} \n",
      "after:  {'spacing': array([1.29525631, 1.29525631, 1.29525631]), 'data.shape (data is resampled)': (1, 7, 395, 395)} \n",
      "\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task485_GRSL/nnUNetData_plans_v2.1_stage0/SNUH_DC07_JCW0_RALP_0010.npz\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 10, 512, 512)} \n",
      "after:  {'spacing': array([1.29525631, 1.29525631, 1.29525631]), 'data.shape (data is resampled)': (1, 8, 395, 395)} \n",
      "\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task485_GRSL/nnUNetData_plans_v2.1_stage0/SNUH_DC07_JCW0_RALP_0020.npz\n",
      "no separate z, order 3\n",
      "no separate z, order 3\n",
      "no separate z, order 3\n",
      "no separate z, order 1\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 48, 512, 512)} \n",
      "after:  {'spacing': array([1.29525631, 1.29525631, 1.29525631]), 'data.shape (data is resampled)': (1, 37, 395, 395)} \n",
      "\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task485_GRSL/nnUNetData_plans_v2.1_stage0/SNUH_DC07_JCW0_RALP_0013.npz\n",
      "no separate z, order 1\n",
      "no separate z, order 1\n",
      "no separate z, order 1\n",
      "no separate z, order 1\n",
      "no separate z, order 1\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 129, 512, 512)} \n",
      "after:  {'spacing': array([1.29525631, 1.29525631, 1.29525631]), 'data.shape (data is resampled)': (1, 100, 395, 395)} \n",
      "\n",
      "no separate z, order 1\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task485_GRSL/nnUNetData_plans_v2.1_stage0/SNUH_DC07_JCW0_RALP_0000.npz\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 79, 512, 512)} \n",
      "after:  {'spacing': array([1.29525631, 1.29525631, 1.29525631]), 'data.shape (data is resampled)': (1, 61, 395, 395)} \n",
      "\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task485_GRSL/nnUNetData_plans_v2.1_stage0/SNUH_DC07_JCW0_RALP_0021.npz\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 81, 512, 512)} \n",
      "after:  {'spacing': array([1.29525631, 1.29525631, 1.29525631]), 'data.shape (data is resampled)': (1, 63, 395, 395)} \n",
      "\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task485_GRSL/nnUNetData_plans_v2.1_stage0/SNUH_DC07_JCW0_RALP_0031.npz\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 116, 512, 512)} \n",
      "after:  {'spacing': array([1.29525631, 1.29525631, 1.29525631]), 'data.shape (data is resampled)': (1, 90, 395, 395)} \n",
      "\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task485_GRSL/nnUNetData_plans_v2.1_stage0/SNUH_DC07_JCW0_RALP_0008.npz\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 145, 512, 512)} \n",
      "after:  {'spacing': array([1.29525631, 1.29525631, 1.29525631]), 'data.shape (data is resampled)': (1, 112, 395, 395)} \n",
      "\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 180, 512, 512)} \n",
      "after:  {'spacing': array([1.29525631, 1.29525631, 1.29525631]), 'data.shape (data is resampled)': (1, 139, 395, 395)} \n",
      "\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task485_GRSL/nnUNetData_plans_v2.1_stage0/SNUH_DC07_JCW0_RALP_0001.npz\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task485_GRSL/nnUNetData_plans_v2.1_stage0/SNUH_DC07_JCW0_RALP_0011.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 8, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 8, 512, 512)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 9, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 9, 512, 512)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 10, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 10, 512, 512)} \n",
      "\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task485_GRSL/nnUNetData_plans_v2.1_stage1/SNUH_DC07_JCW0_RALP_0012.npz\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task485_GRSL/nnUNetData_plans_v2.1_stage1/SNUH_DC07_JCW0_RALP_0010.npz\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task485_GRSL/nnUNetData_plans_v2.1_stage1/SNUH_DC07_JCW0_RALP_0020.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 48, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 48, 512, 512)} \n",
      "\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task485_GRSL/nnUNetData_plans_v2.1_stage1/SNUH_DC07_JCW0_RALP_0013.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 116, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 116, 512, 512)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 129, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 129, 512, 512)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 79, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 79, 512, 512)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 145, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 145, 512, 512)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 81, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 81, 512, 512)} \n",
      "\n",
      "1 13082\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task485_GRSL/nnUNetData_plans_v2.1_stage1/SNUH_DC07_JCW0_RALP_0008.npz\n",
      "1 19993\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task485_GRSL/nnUNetData_plans_v2.1_stage1/SNUH_DC07_JCW0_RALP_0000.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 180, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 180, 512, 512)} \n",
      "\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task485_GRSL/nnUNetData_plans_v2.1_stage1/SNUH_DC07_JCW0_RALP_0021.npz\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task485_GRSL/nnUNetData_plans_v2.1_stage1/SNUH_DC07_JCW0_RALP_0031.npz\n",
      "1 13968\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task485_GRSL/nnUNetData_plans_v2.1_stage1/SNUH_DC07_JCW0_RALP_0001.npz\n",
      "1 13596\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task485_GRSL/nnUNetData_plans_v2.1_stage1/SNUH_DC07_JCW0_RALP_0011.npz\n",
      "not using nonzero mask for normalization\n",
      "Are we using the nonzero maks for normalizaion? OrderedDict([(0, False)])\n",
      "the median shape of the dataset is  [ 80. 512. 512.]\n",
      "the max shape in the dataset is  [180. 512. 512.]\n",
      "the min shape in the dataset is  [  8. 512. 512.]\n",
      "we don't want feature maps smaller than  4  in the bottleneck\n",
      "the transposed median shape of the dataset is  [ 80. 512. 512.]\n",
      "[{'batch_size': 12, 'num_pool_per_axis': [7, 7], 'patch_size': array([512, 512]), 'median_patient_size_in_voxels': array([ 80, 512, 512]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}]\n",
      "Initializing to run preprocessing\n",
      "npz folder: /tf/temp/nnUNet/nnunet/nnUNet_raw_data_base/nnUNet_cropped_data/Task485_GRSL\n",
      "output_folder: /tf/temp/nnUNet/nnunet/preprocessed/Task485_GRSL\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 8, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 8, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 9, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 9, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 10, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 10, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "normalization done\n",
      "normalization done\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task485_GRSL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC07_JCW0_RALP_0012.npz\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task485_GRSL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC07_JCW0_RALP_0010.npz\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task485_GRSL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC07_JCW0_RALP_0020.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 48, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 48, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task485_GRSL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC07_JCW0_RALP_0013.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 116, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 116, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 129, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 129, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 145, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 145, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 79, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 79, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 81, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 81, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 180, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 180, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "normalization done\n",
      "1 13082\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task485_GRSL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC07_JCW0_RALP_0008.npz\n",
      "normalization done\n",
      "normalization done\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task485_GRSL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC07_JCW0_RALP_0021.npz\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task485_GRSL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC07_JCW0_RALP_0031.npz\n",
      "1 19993\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task485_GRSL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC07_JCW0_RALP_0000.npz\n",
      "normalization done\n",
      "1 13968\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task485_GRSL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC07_JCW0_RALP_0001.npz\n",
      "1 13596\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task485_GRSL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC07_JCW0_RALP_0011.npz\n"
     ]
    }
   ],
   "source": [
    "!nnUNet_convert_decathlon_task -i /tf/temp/nnUNet/nnunet/Tasks/Task85_GRSL -output_task_id 485 # -i : task_dir\n",
    "!nnUNet_plan_and_preprocess -t 485 # --verify_dataset_integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'png'}\n",
      "use_mask_for_norm OrderedDict([(0, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 12, 'num_pool_per_axis': [7, 7], 'patch_size': array([512, 512]), 'median_patient_size_in_voxels': array([ 80, 512, 512]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /tf/temp/nnUNet/nnunet/preprocessed/Task485_GRSL/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "unpacking dataset\n",
      "done\n",
      "2021-12-02 16:14:32.963418: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-12-02 16:14:39.652612: Unable to plot network architecture:\n",
      "2021-12-02 16:14:39.686017: No module named 'hiddenlayer'\n",
      "2021-12-02 16:14:39.692736: \n",
      "printing the network instead:\n",
      "\n",
      "2021-12-02 16:14:39.700989: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (1): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (2): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (3): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (4): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (5): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (6): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (4): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (5): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (6): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-12-02 16:14:39.711964: \n",
      "\n",
      "2021-12-02 16:14:39.717362: \n",
      "epoch:  0\n",
      "2021-12-02 16:17:39.029193: train loss : -0.0437\n",
      "2021-12-02 16:17:51.855382: validation loss: -0.3847\n",
      "2021-12-02 16:17:51.862019: Average global foreground Dice: [0.5731]\n",
      "2021-12-02 16:17:51.868273: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 16:17:52.280576: lr: 0.00982\n",
      "2021-12-02 16:17:52.287023: This epoch took 192.561411 s\n",
      "\n",
      "2021-12-02 16:17:52.292635: \n",
      "epoch:  1\n",
      "2021-12-02 16:20:46.634770: train loss : -0.4040\n",
      "2021-12-02 16:20:59.655804: validation loss: -0.5709\n",
      "2021-12-02 16:20:59.662521: Average global foreground Dice: [0.7059]\n",
      "2021-12-02 16:20:59.668906: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 16:21:00.183838: lr: 0.009639\n",
      "2021-12-02 16:21:00.299588: saving checkpoint...\n",
      "2021-12-02 16:21:01.785763: done, saving took 1.60 seconds\n",
      "2021-12-02 16:21:01.805827: This epoch took 189.507554 s\n",
      "\n",
      "2021-12-02 16:21:01.814232: \n",
      "epoch:  2\n",
      "2021-12-02 16:23:55.985337: train loss : -0.5449\n",
      "2021-12-02 16:24:08.271373: validation loss: -0.6925\n",
      "2021-12-02 16:24:08.279299: Average global foreground Dice: [0.796]\n",
      "2021-12-02 16:24:08.284803: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 16:24:08.791990: lr: 0.009458\n",
      "2021-12-02 16:24:08.908316: saving checkpoint...\n",
      "2021-12-02 16:24:10.210079: done, saving took 1.41 seconds\n",
      "2021-12-02 16:24:10.234885: This epoch took 188.414934 s\n",
      "\n",
      "2021-12-02 16:24:10.240838: \n",
      "epoch:  3\n",
      "2021-12-02 16:26:55.679221: train loss : -0.6603\n",
      "2021-12-02 16:27:08.021561: validation loss: -0.7253\n",
      "2021-12-02 16:27:08.029306: Average global foreground Dice: [0.8157]\n",
      "2021-12-02 16:27:08.035049: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 16:27:08.536295: lr: 0.009277\n",
      "2021-12-02 16:27:08.628698: saving checkpoint...\n",
      "2021-12-02 16:27:09.977375: done, saving took 1.44 seconds\n",
      "2021-12-02 16:27:10.003939: This epoch took 179.757175 s\n",
      "\n",
      "2021-12-02 16:27:10.010372: \n",
      "epoch:  4\n",
      "2021-12-02 16:30:02.730172: train loss : -0.7133\n",
      "2021-12-02 16:30:15.874530: validation loss: -0.7842\n",
      "2021-12-02 16:30:15.881380: Average global foreground Dice: [0.8588]\n",
      "2021-12-02 16:30:15.887783: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 16:30:16.423057: lr: 0.009095\n",
      "2021-12-02 16:30:16.531048: saving checkpoint...\n",
      "2021-12-02 16:30:17.833012: done, saving took 1.40 seconds\n",
      "2021-12-02 16:30:17.860235: This epoch took 187.843327 s\n",
      "\n",
      "2021-12-02 16:30:17.865439: \n",
      "epoch:  5\n",
      "2021-12-02 16:33:13.143971: train loss : -0.7426\n",
      "2021-12-02 16:33:26.148795: validation loss: -0.8197\n",
      "2021-12-02 16:33:26.156525: Average global foreground Dice: [0.8812]\n",
      "2021-12-02 16:33:26.162302: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 16:33:26.662210: lr: 0.008913\n",
      "2021-12-02 16:33:26.728250: saving checkpoint...\n",
      "2021-12-02 16:33:28.112412: done, saving took 1.44 seconds\n",
      "2021-12-02 16:33:28.134462: This epoch took 190.263912 s\n",
      "\n",
      "2021-12-02 16:33:28.139949: \n",
      "epoch:  6\n",
      "2021-12-02 16:36:14.030087: train loss : -0.7777\n",
      "2021-12-02 16:36:26.316044: validation loss: -0.8209\n",
      "2021-12-02 16:36:26.322671: Average global foreground Dice: [0.8817]\n",
      "2021-12-02 16:36:26.328939: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 16:36:26.870348: lr: 0.008731\n",
      "2021-12-02 16:36:26.965298: saving checkpoint...\n",
      "2021-12-02 16:36:28.290330: done, saving took 1.41 seconds\n",
      "2021-12-02 16:36:28.315619: This epoch took 180.169268 s\n",
      "\n",
      "2021-12-02 16:36:28.321491: \n",
      "epoch:  7\n",
      "2021-12-02 16:39:18.479326: train loss : -0.8116\n",
      "2021-12-02 16:39:31.652071: validation loss: -0.8538\n",
      "2021-12-02 16:39:31.659035: Average global foreground Dice: [0.9065]\n",
      "2021-12-02 16:39:31.664818: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 16:39:32.226892: lr: 0.008548\n",
      "2021-12-02 16:39:32.272140: saving checkpoint...\n",
      "2021-12-02 16:39:33.574693: done, saving took 1.34 seconds\n",
      "2021-12-02 16:39:33.595155: This epoch took 185.266225 s\n",
      "\n",
      "2021-12-02 16:39:33.601405: \n",
      "epoch:  8\n",
      "2021-12-02 16:42:30.125590: train loss : -0.8344\n",
      "2021-12-02 16:42:43.337313: validation loss: -0.8685\n",
      "2021-12-02 16:42:43.343995: Average global foreground Dice: [0.9163]\n",
      "2021-12-02 16:42:43.350174: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 16:42:43.850039: lr: 0.008364\n",
      "2021-12-02 16:42:43.895564: saving checkpoint...\n",
      "2021-12-02 16:42:45.267620: done, saving took 1.41 seconds\n",
      "2021-12-02 16:42:45.291039: This epoch took 191.683392 s\n",
      "\n",
      "2021-12-02 16:42:45.297515: \n",
      "epoch:  9\n",
      "2021-12-02 16:45:41.550286: train loss : -0.8452\n",
      "2021-12-02 16:45:54.738607: validation loss: -0.8837\n",
      "2021-12-02 16:45:54.745788: Average global foreground Dice: [0.9248]\n",
      "2021-12-02 16:45:54.752703: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 16:45:55.239181: lr: 0.008181\n",
      "2021-12-02 16:45:55.314875: saving checkpoint...\n",
      "2021-12-02 16:45:56.614261: done, saving took 1.37 seconds\n",
      "2021-12-02 16:45:56.639382: This epoch took 191.335360 s\n",
      "\n",
      "2021-12-02 16:45:56.646004: \n",
      "epoch:  10\n",
      "2021-12-02 16:48:53.006165: train loss : -0.8446\n",
      "2021-12-02 16:49:06.196445: validation loss: -0.8811\n",
      "2021-12-02 16:49:06.203551: Average global foreground Dice: [0.9215]\n",
      "2021-12-02 16:49:06.209933: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 16:49:06.710058: lr: 0.007996\n",
      "2021-12-02 16:49:06.787650: saving checkpoint...\n",
      "2021-12-02 16:49:08.111840: done, saving took 1.40 seconds\n",
      "2021-12-02 16:49:08.137116: This epoch took 191.485202 s\n",
      "\n",
      "2021-12-02 16:49:08.142687: \n",
      "epoch:  11\n",
      "2021-12-02 16:52:04.612843: train loss : -0.8639\n",
      "2021-12-02 16:52:17.805343: validation loss: -0.8906\n",
      "2021-12-02 16:52:17.811957: Average global foreground Dice: [0.9281]\n",
      "2021-12-02 16:52:17.818146: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 16:52:18.318341: lr: 0.007811\n",
      "2021-12-02 16:52:18.384684: saving checkpoint...\n",
      "2021-12-02 16:52:19.699218: done, saving took 1.37 seconds\n",
      "2021-12-02 16:52:19.727136: This epoch took 191.577961 s\n",
      "\n",
      "2021-12-02 16:52:19.733580: \n",
      "epoch:  12\n",
      "2021-12-02 16:55:16.291939: train loss : -0.8645\n",
      "2021-12-02 16:55:29.501086: validation loss: -0.9058\n",
      "2021-12-02 16:55:29.509418: Average global foreground Dice: [0.9387]\n",
      "2021-12-02 16:55:29.515543: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 16:55:30.015619: lr: 0.007626\n",
      "2021-12-02 16:55:30.083821: saving checkpoint...\n",
      "2021-12-02 16:55:31.493238: done, saving took 1.47 seconds\n",
      "2021-12-02 16:55:31.518644: This epoch took 191.779315 s\n",
      "\n",
      "2021-12-02 16:55:31.525283: \n",
      "epoch:  13\n",
      "2021-12-02 16:58:28.375474: train loss : -0.8846\n",
      "2021-12-02 16:58:41.600335: validation loss: -0.9138\n",
      "2021-12-02 16:58:41.606487: Average global foreground Dice: [0.9437]\n",
      "2021-12-02 16:58:41.613053: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 16:58:42.172908: lr: 0.00744\n",
      "2021-12-02 16:58:42.217376: saving checkpoint...\n",
      "2021-12-02 16:58:43.564784: done, saving took 1.39 seconds\n",
      "2021-12-02 16:58:43.585156: This epoch took 192.053565 s\n",
      "\n",
      "2021-12-02 16:58:43.591275: \n",
      "epoch:  14\n",
      "2021-12-02 17:01:39.838304: train loss : -0.8943\n",
      "2021-12-02 17:01:53.049758: validation loss: -0.9164\n",
      "2021-12-02 17:01:53.057609: Average global foreground Dice: [0.9459]\n",
      "2021-12-02 17:01:53.063292: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 17:01:53.564123: lr: 0.007254\n",
      "2021-12-02 17:01:53.608360: saving checkpoint...\n",
      "2021-12-02 17:01:54.914383: done, saving took 1.34 seconds\n",
      "2021-12-02 17:01:54.936922: This epoch took 191.340024 s\n",
      "\n",
      "2021-12-02 17:01:54.942925: \n",
      "epoch:  15\n",
      "2021-12-02 17:04:51.296635: train loss : -0.8988\n",
      "2021-12-02 17:05:04.499517: validation loss: -0.9208\n",
      "2021-12-02 17:05:04.506239: Average global foreground Dice: [0.9487]\n",
      "2021-12-02 17:05:04.512670: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 17:05:05.029074: lr: 0.007067\n",
      "2021-12-02 17:05:05.074192: saving checkpoint...\n",
      "2021-12-02 17:05:06.431983: done, saving took 1.40 seconds\n",
      "2021-12-02 17:05:06.454282: This epoch took 191.505128 s\n",
      "\n",
      "2021-12-02 17:05:06.463376: \n",
      "epoch:  16\n",
      "2021-12-02 17:08:03.225694: train loss : -0.8975\n",
      "2021-12-02 17:08:16.429168: validation loss: -0.9187\n",
      "2021-12-02 17:08:16.435971: Average global foreground Dice: [0.9469]\n",
      "2021-12-02 17:08:16.442083: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 17:08:16.952479: lr: 0.00688\n",
      "2021-12-02 17:08:16.997074: saving checkpoint...\n",
      "2021-12-02 17:08:18.276348: done, saving took 1.32 seconds\n",
      "2021-12-02 17:08:18.298625: This epoch took 191.829240 s\n",
      "\n",
      "2021-12-02 17:08:18.304985: \n",
      "epoch:  17\n",
      "2021-12-02 17:11:15.366625: train loss : -0.9001\n",
      "2021-12-02 17:11:28.565578: validation loss: -0.9178\n",
      "2021-12-02 17:11:28.573930: Average global foreground Dice: [0.9461]\n",
      "2021-12-02 17:11:28.580373: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 17:11:29.094072: lr: 0.006692\n",
      "2021-12-02 17:11:29.138055: saving checkpoint...\n",
      "2021-12-02 17:11:31.185332: done, saving took 2.09 seconds\n",
      "2021-12-02 17:11:31.208473: This epoch took 192.897572 s\n",
      "\n",
      "2021-12-02 17:11:31.215127: \n",
      "epoch:  18\n",
      "2021-12-02 17:14:27.876986: train loss : -0.8973\n",
      "2021-12-02 17:14:41.084131: validation loss: -0.9139\n",
      "2021-12-02 17:14:41.090895: Average global foreground Dice: [0.9436]\n",
      "2021-12-02 17:14:41.096578: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 17:14:41.609821: lr: 0.006504\n",
      "2021-12-02 17:14:41.654709: saving checkpoint...\n",
      "2021-12-02 17:14:43.187038: done, saving took 1.57 seconds\n",
      "2021-12-02 17:14:43.211236: This epoch took 191.989719 s\n",
      "\n",
      "2021-12-02 17:14:43.218191: \n",
      "epoch:  19\n",
      "2021-12-02 17:17:40.022673: train loss : -0.9077\n",
      "2021-12-02 17:17:53.254437: validation loss: -0.9321\n",
      "2021-12-02 17:17:53.262660: Average global foreground Dice: [0.9564]\n",
      "2021-12-02 17:17:53.269607: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 17:17:53.834027: lr: 0.006314\n",
      "2021-12-02 17:17:53.880655: saving checkpoint...\n",
      "2021-12-02 17:17:55.264116: done, saving took 1.42 seconds\n",
      "2021-12-02 17:17:55.285352: This epoch took 192.059874 s\n",
      "\n",
      "2021-12-02 17:17:55.292116: \n",
      "epoch:  20\n",
      "2021-12-02 17:20:52.022856: train loss : -0.9111\n",
      "2021-12-02 17:21:05.240007: validation loss: -0.9324\n",
      "2021-12-02 17:21:05.246651: Average global foreground Dice: [0.956]\n",
      "2021-12-02 17:21:05.252615: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 17:21:05.746571: lr: 0.006125\n",
      "2021-12-02 17:21:05.791511: saving checkpoint...\n",
      "2021-12-02 17:21:07.227099: done, saving took 1.47 seconds\n",
      "2021-12-02 17:21:07.254518: This epoch took 191.956184 s\n",
      "\n",
      "2021-12-02 17:21:07.260709: \n",
      "epoch:  21\n",
      "2021-12-02 17:24:03.939261: train loss : -0.9176\n",
      "2021-12-02 17:24:17.123902: validation loss: -0.9330\n",
      "2021-12-02 17:24:17.130217: Average global foreground Dice: [0.9571]\n",
      "2021-12-02 17:24:17.136265: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 17:24:17.628557: lr: 0.005934\n",
      "2021-12-02 17:24:17.716803: saving checkpoint...\n",
      "2021-12-02 17:24:19.052129: done, saving took 1.42 seconds\n",
      "2021-12-02 17:24:19.080684: This epoch took 191.813189 s\n",
      "\n",
      "2021-12-02 17:24:19.086377: \n",
      "epoch:  22\n",
      "2021-12-02 17:27:15.536274: train loss : -0.9161\n",
      "2021-12-02 17:27:28.730544: validation loss: -0.9367\n",
      "2021-12-02 17:27:28.739171: Average global foreground Dice: [0.9587]\n",
      "2021-12-02 17:27:28.744979: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 17:27:29.247854: lr: 0.005743\n",
      "2021-12-02 17:27:29.329174: saving checkpoint...\n",
      "2021-12-02 17:27:30.744690: done, saving took 1.49 seconds\n",
      "2021-12-02 17:27:30.772436: This epoch took 191.679617 s\n",
      "\n",
      "2021-12-02 17:27:30.778148: \n",
      "epoch:  23\n",
      "2021-12-02 17:30:20.152823: train loss : -0.9219\n",
      "2021-12-02 17:30:32.345035: validation loss: -0.9415\n",
      "2021-12-02 17:30:32.353502: Average global foreground Dice: [0.962]\n",
      "2021-12-02 17:30:32.360110: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 17:30:32.847989: lr: 0.005551\n",
      "2021-12-02 17:30:32.942201: saving checkpoint...\n",
      "2021-12-02 17:30:34.342150: done, saving took 1.49 seconds\n",
      "2021-12-02 17:30:34.364910: This epoch took 183.581351 s\n",
      "\n",
      "2021-12-02 17:30:34.371491: \n",
      "epoch:  24\n",
      "2021-12-02 17:33:22.145640: train loss : -0.9235\n",
      "2021-12-02 17:33:35.054980: validation loss: -0.9382\n",
      "2021-12-02 17:33:35.061472: Average global foreground Dice: [0.9608]\n",
      "2021-12-02 17:33:35.068220: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 17:33:35.623373: lr: 0.005359\n",
      "2021-12-02 17:33:35.715871: saving checkpoint...\n",
      "2021-12-02 17:33:38.277521: done, saving took 2.65 seconds\n",
      "2021-12-02 17:33:38.306898: This epoch took 183.929298 s\n",
      "\n",
      "2021-12-02 17:33:38.313953: \n",
      "epoch:  25\n",
      "/tf/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-12-02 17:36:34.762235: train loss : -0.9253\n",
      "2021-12-02 17:36:47.959654: validation loss: -0.9404\n",
      "2021-12-02 17:36:47.967500: Average global foreground Dice: [0.9616]\n",
      "2021-12-02 17:36:47.974058: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 17:36:48.576571: lr: 0.005166\n",
      "2021-12-02 17:36:48.621516: saving checkpoint...\n",
      "2021-12-02 17:36:49.955420: done, saving took 1.37 seconds\n",
      "2021-12-02 17:36:49.976659: This epoch took 191.654202 s\n",
      "\n",
      "2021-12-02 17:36:49.983221: \n",
      "epoch:  26\n",
      "2021-12-02 17:39:46.413724: train loss : -0.9287\n",
      "2021-12-02 17:39:59.595008: validation loss: -0.9402\n",
      "2021-12-02 17:39:59.601507: Average global foreground Dice: [0.9614]\n",
      "2021-12-02 17:39:59.608061: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 17:40:00.101557: lr: 0.004971\n",
      "2021-12-02 17:40:00.146701: saving checkpoint...\n",
      "2021-12-02 17:40:01.514986: done, saving took 1.41 seconds\n",
      "2021-12-02 17:40:01.540038: This epoch took 191.550950 s\n",
      "\n",
      "2021-12-02 17:40:01.546384: \n",
      "epoch:  27\n",
      "2021-12-02 17:42:57.961920: train loss : -0.9293\n",
      "2021-12-02 17:43:11.142053: validation loss: -0.9456\n",
      "2021-12-02 17:43:11.149702: Average global foreground Dice: [0.9651]\n",
      "2021-12-02 17:43:11.156294: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 17:43:11.643063: lr: 0.004776\n",
      "2021-12-02 17:43:11.688238: saving checkpoint...\n",
      "2021-12-02 17:43:13.126065: done, saving took 1.48 seconds\n",
      "2021-12-02 17:43:13.148566: This epoch took 191.595290 s\n",
      "\n",
      "2021-12-02 17:43:13.156081: \n",
      "epoch:  28\n",
      "2021-12-02 17:46:09.263088: train loss : -0.9269\n",
      "2021-12-02 17:46:22.458917: validation loss: -0.9438\n",
      "2021-12-02 17:46:22.465816: Average global foreground Dice: [0.964]\n",
      "2021-12-02 17:46:22.471465: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 17:46:22.958909: lr: 0.004581\n",
      "2021-12-02 17:46:23.002717: saving checkpoint...\n",
      "2021-12-02 17:46:24.327598: done, saving took 1.36 seconds\n",
      "2021-12-02 17:46:24.352402: This epoch took 191.190003 s\n",
      "\n",
      "2021-12-02 17:46:24.359419: \n",
      "epoch:  29\n",
      "2021-12-02 17:49:20.582442: train loss : -0.9310\n",
      "2021-12-02 17:49:33.775059: validation loss: -0.9483\n",
      "2021-12-02 17:49:33.781419: Average global foreground Dice: [0.9666]\n",
      "2021-12-02 17:49:33.787886: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 17:49:34.276423: lr: 0.004384\n",
      "2021-12-02 17:49:34.322410: saving checkpoint...\n",
      "2021-12-02 17:49:35.892180: done, saving took 1.61 seconds\n",
      "2021-12-02 17:49:35.917907: This epoch took 191.552784 s\n",
      "\n",
      "2021-12-02 17:49:35.923872: \n",
      "epoch:  30\n",
      "2021-12-02 17:52:32.308481: train loss : -0.9334\n",
      "2021-12-02 17:52:45.531148: validation loss: -0.9458\n",
      "2021-12-02 17:52:45.538204: Average global foreground Dice: [0.9654]\n",
      "2021-12-02 17:52:45.544284: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 17:52:46.032467: lr: 0.004186\n",
      "2021-12-02 17:52:46.076955: saving checkpoint...\n",
      "2021-12-02 17:52:47.369650: done, saving took 1.33 seconds\n",
      "2021-12-02 17:52:47.397802: This epoch took 191.468162 s\n",
      "\n",
      "2021-12-02 17:52:47.403657: \n",
      "epoch:  31\n",
      "2021-12-02 17:55:35.799841: train loss : -0.9341\n",
      "2021-12-02 17:55:48.022014: validation loss: -0.9488\n",
      "2021-12-02 17:55:48.028942: Average global foreground Dice: [0.9671]\n",
      "2021-12-02 17:55:48.034174: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 17:55:48.588490: lr: 0.003987\n",
      "2021-12-02 17:55:48.632781: saving checkpoint...\n",
      "2021-12-02 17:55:49.915489: done, saving took 1.32 seconds\n",
      "2021-12-02 17:55:49.936943: This epoch took 182.527596 s\n",
      "\n",
      "2021-12-02 17:55:49.943569: \n",
      "epoch:  32\n",
      "2021-12-02 17:58:38.247385: train loss : -0.9367\n",
      "2021-12-02 17:58:51.192278: validation loss: -0.9490\n",
      "2021-12-02 17:58:51.199236: Average global foreground Dice: [0.9671]\n",
      "2021-12-02 17:58:51.205256: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 17:58:51.704112: lr: 0.003787\n",
      "2021-12-02 17:58:51.749055: saving checkpoint...\n",
      "2021-12-02 17:58:53.059557: done, saving took 1.35 seconds\n",
      "2021-12-02 17:58:53.081476: This epoch took 183.131981 s\n",
      "\n",
      "2021-12-02 17:58:53.087617: \n",
      "epoch:  33\n",
      "2021-12-02 18:01:49.178684: train loss : -0.9404\n",
      "2021-12-02 18:02:02.322712: validation loss: -0.9527\n",
      "2021-12-02 18:02:02.331576: Average global foreground Dice: [0.9695]\n",
      "2021-12-02 18:02:02.339149: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 18:02:02.828452: lr: 0.003586\n",
      "2021-12-02 18:02:02.874119: saving checkpoint...\n",
      "2021-12-02 18:02:04.200565: done, saving took 1.37 seconds\n",
      "2021-12-02 18:02:04.223253: This epoch took 191.129883 s\n",
      "\n",
      "2021-12-02 18:02:04.229804: \n",
      "epoch:  34\n",
      "2021-12-02 18:04:55.520901: train loss : -0.9405\n",
      "2021-12-02 18:05:07.734374: validation loss: -0.9509\n",
      "2021-12-02 18:05:07.741536: Average global foreground Dice: [0.9682]\n",
      "2021-12-02 18:05:07.747401: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 18:05:08.246024: lr: 0.003384\n",
      "2021-12-02 18:05:08.292685: saving checkpoint...\n",
      "2021-12-02 18:05:09.736280: done, saving took 1.48 seconds\n",
      "2021-12-02 18:05:09.762562: This epoch took 185.526864 s\n",
      "\n",
      "2021-12-02 18:05:09.767929: \n",
      "epoch:  35\n",
      "2021-12-02 18:07:56.560993: train loss : -0.9357\n",
      "2021-12-02 18:08:09.245756: validation loss: -0.9520\n",
      "2021-12-02 18:08:09.253780: Average global foreground Dice: [0.9695]\n",
      "2021-12-02 18:08:09.260155: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 18:08:09.764987: lr: 0.00318\n",
      "2021-12-02 18:08:09.842029: saving checkpoint...\n",
      "2021-12-02 18:08:11.195189: done, saving took 1.42 seconds\n",
      "2021-12-02 18:08:11.221920: This epoch took 181.447789 s\n",
      "\n",
      "2021-12-02 18:08:11.228388: \n",
      "epoch:  36\n",
      "2021-12-02 18:11:06.582648: train loss : -0.9393\n",
      "2021-12-02 18:11:19.606598: validation loss: -0.9532\n",
      "2021-12-02 18:11:19.613365: Average global foreground Dice: [0.9696]\n",
      "2021-12-02 18:11:19.620020: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 18:11:20.114070: lr: 0.002975\n",
      "2021-12-02 18:11:20.204190: saving checkpoint...\n",
      "2021-12-02 18:11:21.681498: done, saving took 1.56 seconds\n",
      "2021-12-02 18:11:21.707537: This epoch took 190.472866 s\n",
      "\n",
      "2021-12-02 18:11:21.713917: \n",
      "epoch:  37\n",
      "2021-12-02 18:14:18.750069: train loss : -0.9416\n",
      "2021-12-02 18:14:31.935364: validation loss: -0.9539\n",
      "2021-12-02 18:14:31.941823: Average global foreground Dice: [0.9703]\n",
      "2021-12-02 18:14:31.948228: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 18:14:32.522038: lr: 0.002768\n",
      "2021-12-02 18:14:32.567023: saving checkpoint...\n",
      "2021-12-02 18:14:33.872851: done, saving took 1.34 seconds\n",
      "2021-12-02 18:14:33.897121: This epoch took 192.177197 s\n",
      "\n",
      "2021-12-02 18:14:33.903745: \n",
      "epoch:  38\n",
      "2021-12-02 18:17:30.299075: train loss : -0.9405\n",
      "2021-12-02 18:17:43.438030: validation loss: -0.9562\n",
      "2021-12-02 18:17:43.445546: Average global foreground Dice: [0.9718]\n",
      "2021-12-02 18:17:43.451281: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 18:17:43.955560: lr: 0.00256\n",
      "2021-12-02 18:17:43.999411: saving checkpoint...\n",
      "2021-12-02 18:17:45.362716: done, saving took 1.40 seconds\n",
      "2021-12-02 18:17:45.383659: This epoch took 191.473761 s\n",
      "\n",
      "2021-12-02 18:17:45.389280: \n",
      "epoch:  39\n",
      "2021-12-02 18:20:41.401458: train loss : -0.9438\n",
      "2021-12-02 18:20:54.563687: validation loss: -0.9558\n",
      "2021-12-02 18:20:54.569758: Average global foreground Dice: [0.9715]\n",
      "2021-12-02 18:20:54.576260: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 18:20:55.076936: lr: 0.002349\n",
      "2021-12-02 18:20:55.126313: saving checkpoint...\n",
      "2021-12-02 18:20:56.467842: done, saving took 1.38 seconds\n",
      "2021-12-02 18:20:56.488374: This epoch took 191.093225 s\n",
      "\n",
      "2021-12-02 18:20:56.494701: \n",
      "epoch:  40\n",
      "2021-12-02 18:23:52.803871: train loss : -0.9447\n",
      "2021-12-02 18:24:05.999795: validation loss: -0.9547\n",
      "2021-12-02 18:24:06.006937: Average global foreground Dice: [0.9705]\n",
      "2021-12-02 18:24:06.013678: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 18:24:06.516483: lr: 0.002137\n",
      "2021-12-02 18:24:06.560958: saving checkpoint...\n",
      "2021-12-02 18:24:07.942659: done, saving took 1.42 seconds\n",
      "2021-12-02 18:24:07.967321: This epoch took 191.466612 s\n",
      "\n",
      "2021-12-02 18:24:07.973786: \n",
      "epoch:  41\n",
      "2021-12-02 18:27:04.423541: train loss : -0.9437\n",
      "2021-12-02 18:27:17.614993: validation loss: -0.9554\n",
      "2021-12-02 18:27:17.621701: Average global foreground Dice: [0.972]\n",
      "2021-12-02 18:27:17.628140: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 18:27:18.136206: lr: 0.001922\n",
      "2021-12-02 18:27:18.214957: saving checkpoint...\n",
      "2021-12-02 18:27:19.529344: done, saving took 1.39 seconds\n",
      "2021-12-02 18:27:19.554918: This epoch took 191.575158 s\n",
      "\n",
      "2021-12-02 18:27:19.560867: \n",
      "epoch:  42\n",
      "2021-12-02 18:30:15.431798: train loss : -0.9463\n",
      "2021-12-02 18:30:28.609003: validation loss: -0.9569\n",
      "2021-12-02 18:30:28.617243: Average global foreground Dice: [0.9726]\n",
      "2021-12-02 18:30:28.622866: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 18:30:29.118877: lr: 0.001704\n",
      "2021-12-02 18:30:29.185550: saving checkpoint...\n",
      "2021-12-02 18:30:30.490334: done, saving took 1.36 seconds\n",
      "2021-12-02 18:30:30.510698: This epoch took 190.942872 s\n",
      "\n",
      "2021-12-02 18:30:30.516351: \n",
      "epoch:  43\n",
      "2021-12-02 18:33:26.809389: train loss : -0.9477\n",
      "2021-12-02 18:33:40.006926: validation loss: -0.9572\n",
      "2021-12-02 18:33:40.013735: Average global foreground Dice: [0.9726]\n",
      "2021-12-02 18:33:40.020840: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 18:33:40.503776: lr: 0.001483\n",
      "2021-12-02 18:33:40.573505: saving checkpoint...\n",
      "2021-12-02 18:33:42.027786: done, saving took 1.52 seconds\n",
      "2021-12-02 18:33:42.056928: This epoch took 191.534701 s\n",
      "\n",
      "2021-12-02 18:33:42.062497: \n",
      "epoch:  44\n",
      "2021-12-02 18:36:38.757990: train loss : -0.9483\n",
      "2021-12-02 18:36:51.961876: validation loss: -0.9605\n",
      "2021-12-02 18:36:51.968495: Average global foreground Dice: [0.9749]\n",
      "2021-12-02 18:36:51.974860: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 18:36:52.471065: lr: 0.001259\n",
      "2021-12-02 18:36:52.518329: saving checkpoint...\n",
      "2021-12-02 18:36:53.912156: done, saving took 1.43 seconds\n",
      "2021-12-02 18:36:53.934812: This epoch took 191.866471 s\n",
      "\n",
      "2021-12-02 18:36:53.941369: \n",
      "epoch:  45\n",
      "2021-12-02 18:39:50.650993: train loss : -0.9503\n",
      "2021-12-02 18:40:03.875598: validation loss: -0.9580\n",
      "2021-12-02 18:40:03.882522: Average global foreground Dice: [0.9736]\n",
      "2021-12-02 18:40:03.889474: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 18:40:04.377715: lr: 0.00103\n",
      "2021-12-02 18:40:04.423015: saving checkpoint...\n",
      "2021-12-02 18:40:05.800233: done, saving took 1.42 seconds\n",
      "2021-12-02 18:40:05.826223: This epoch took 191.875517 s\n",
      "\n",
      "2021-12-02 18:40:05.832963: \n",
      "epoch:  46\n",
      "2021-12-02 18:43:02.681962: train loss : -0.9489\n",
      "2021-12-02 18:43:15.890335: validation loss: -0.9595\n",
      "2021-12-02 18:43:15.896502: Average global foreground Dice: [0.9745]\n",
      "2021-12-02 18:43:15.902241: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 18:43:16.389798: lr: 0.000795\n",
      "2021-12-02 18:43:16.466928: saving checkpoint...\n",
      "2021-12-02 18:43:17.767450: done, saving took 1.37 seconds\n",
      "2021-12-02 18:43:17.792925: This epoch took 191.953879 s\n",
      "\n",
      "2021-12-02 18:43:17.799573: \n",
      "epoch:  47\n",
      "2021-12-02 18:46:13.871364: train loss : -0.9491\n",
      "2021-12-02 18:46:27.068026: validation loss: -0.9600\n",
      "2021-12-02 18:46:27.075187: Average global foreground Dice: [0.9746]\n",
      "2021-12-02 18:46:27.082051: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 18:46:27.575763: lr: 0.000552\n",
      "2021-12-02 18:46:27.653874: saving checkpoint...\n",
      "2021-12-02 18:46:28.985891: done, saving took 1.40 seconds\n",
      "2021-12-02 18:46:29.012013: This epoch took 191.206022 s\n",
      "\n",
      "2021-12-02 18:46:29.019086: \n",
      "epoch:  48\n",
      "2021-12-02 18:49:25.864326: train loss : -0.9515\n",
      "2021-12-02 18:49:39.073242: validation loss: -0.9616\n",
      "2021-12-02 18:49:39.081078: Average global foreground Dice: [0.976]\n",
      "2021-12-02 18:49:39.087122: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 18:49:39.587770: lr: 0.000296\n",
      "2021-12-02 18:49:39.668304: saving checkpoint...\n",
      "2021-12-02 18:49:41.049528: done, saving took 1.46 seconds\n",
      "2021-12-02 18:49:41.078072: This epoch took 192.052552 s\n",
      "\n",
      "2021-12-02 18:49:41.083955: \n",
      "epoch:  49\n",
      "2021-12-02 18:52:38.091164: train loss : -0.9514\n",
      "2021-12-02 18:52:51.270556: validation loss: -0.9617\n",
      "2021-12-02 18:52:51.278343: Average global foreground Dice: [0.9755]\n",
      "2021-12-02 18:52:51.284087: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 18:52:51.840524: lr: 0.0\n",
      "2021-12-02 18:52:51.845887: saving scheduled checkpoint file...\n",
      "2021-12-02 18:52:51.890186: saving checkpoint...\n",
      "2021-12-02 18:52:53.177218: done, saving took 1.33 seconds\n",
      "2021-12-02 18:52:53.192364: done\n",
      "2021-12-02 18:52:53.238108: saving checkpoint...\n",
      "2021-12-02 18:52:54.594624: done, saving took 1.40 seconds\n",
      "2021-12-02 18:52:54.616686: This epoch took 193.527103 s\n",
      "\n",
      "2021-12-02 18:52:54.661671: saving checkpoint...\n",
      "2021-12-02 18:52:55.788994: done, saving took 1.17 seconds\n",
      "SNUH_DC07_JCW0_RALP_0000 (2, 129, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RALP_0001 (2, 145, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RALP_0008 (2, 116, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "SNUH_DC07_JCW0_RALP_0010 (2, 9, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RALP_0011 (2, 180, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "SNUH_DC07_JCW0_RALP_0012 (2, 8, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RALP_0013 (2, 48, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "SNUH_DC07_JCW0_RALP_0020 (2, 10, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RALP_0021 (2, 79, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RALP_0031 (2, 81, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-12-02 18:54:38.840644: finished prediction\n",
      "2021-12-02 18:54:38.846709: evaluation of raw predictions\n",
      "2021-12-02 18:54:41.297178: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.9753861138204026\n",
      "after:  0.6353732340712644\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "!nnUNet_train 2d nnUNetTrainerV2 485 all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating \"Task86_NDHL\" Image & Label ..\n",
      "Print surgery : Needle Holder (AESCULAP) (NDHL-UCAE)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b224ba88945f49dab635051e2b9df6dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 16)\n",
      "(512, 512, 71)\n",
      "(512, 512, 11)\n",
      "(512, 512, 75)\n",
      "(512, 512, 27)\n",
      "(512, 512, 9)\n",
      "(512, 512, 46)\n",
      "(512, 512, 6)\n",
      "(512, 512, 17)\n",
      "(512, 512, 82)\n",
      "(512, 512, 4)\n",
      "(512, 512, 3)\n",
      "(512, 512, 70)\n",
      "(512, 512, 28)\n",
      "(512, 512, 1)\n",
      "(512, 512, 6)\n",
      "(512, 512, 9)\n",
      "(512, 512, 12)\n",
      "(512, 512, 9)\n",
      "(512, 512, 16)\n",
      "(512, 512, 29)\n",
      "(512, 512, 23)\n",
      "(512, 512, 19)\n",
      "(512, 512, 3)\n",
      "(512, 512, 12)\n",
      "(512, 512, 28)\n",
      "(512, 512, 27)\n",
      "(512, 512, 32)\n",
      "(512, 512, 8)\n",
      "(512, 512, 7)\n",
      "(512, 512, 16)\n",
      "(512, 512, 1)\n",
      "(512, 512, 3)\n",
      "(512, 512, 25)\n",
      "(512, 512, 100)\n",
      "(512, 512, 43)\n",
      "(512, 512, 52)\n",
      "(512, 512, 32)\n",
      "\"Task86_NDHL\" Image & Label Completed !!\n"
     ]
    }
   ],
   "source": [
    "png2nifti(surgery_NUM=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/temp/nnUNet/nnunet/Tasks/Task86_NDHL/dataset.json <-- created!\n"
     ]
    }
   ],
   "source": [
    "json_mk('/tf/temp/nnUNet/nnunet/Tasks/Task86_NDHL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "SNUH_DC07_JCW0_RALP_0000\n",
      "SNUH_DC07_JCW0_RALP_0002\n",
      "SNUH_DC07_JCW0_RALP_0020\n",
      "SNUH_DC07_JCW0_RALP_0031\n",
      "SNUH_DC16_KSH0_LDG0_0032\n",
      "SNUH_DC16_KSH0_LDG0_0034\n",
      "SNUH_DC16_KSH0_LDG0_0036\n",
      "SNUH_DC16_KSH0_LDG0_0038\n",
      "before crop: (1, 3, 512, 512) after crop: (1, 3, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "SNUH_DC07_JCW0_RALP_0021\n",
      "before crop: (1, 16, 512, 512) after crop: (1, 16, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (1, 25, 512, 512) after crop: (1, 25, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (1, 27, 512, 512) after crop: (1, 27, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (1, 28, 512, 512) after crop: (1, 28, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (1, 29, 512, 512) after crop: (1, 29, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (1, 32, 512, 512) after crop: (1, 32, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "SNUH_DC07_JCW0_RALP_0001\n",
      "before crop: (1, 70, 512, 512) after crop: (1, 70, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "SNUH_DC16_KSH0_LDG0_0039\n",
      "SNUH_DC16_KSH0_LDG0_0033\n",
      "before crop: (1, 100, 512, 512) after crop: (1, 100, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "SNUH_DC16_KSH0_LDG0_0037\n",
      "SNUH_DC16_KSH0_LDG0_0035\n",
      "before crop: (1, 16, 512, 512) after crop: (1, 16, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (1, 28, 512, 512) after crop: (1, 28, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "SNUH_DC07_JCW0_RALP_0011\n",
      "before crop: (1, 75, 512, 512) after crop: (1, 75, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (1, 43, 512, 512) after crop: (1, 43, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "SNUH_DC16_KSH0_LDG0_0040\n",
      "before crop: (1, 52, 512, 512) after crop: (1, 52, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (1, 71, 512, 512) after crop: (1, 71, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "SNUH_DC16_KSH0_LDG0_0042\n",
      "before crop: (1, 12, 512, 512) after crop: (1, 12, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (1, 82, 512, 512) after crop: (1, 82, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "SNUH_DC16_KSH0_LDG0_0043\n",
      "before crop: (1, 3, 512, 512) after crop: (1, 3, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "SNUH_DC16_KSH0_LDG0_0044\n",
      "before crop: (1, 1, 512, 512) after crop: (1, 1, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "SNUH_DC16_KSH0_LDG0_0045\n",
      "before crop: (1, 9, 512, 512) after crop: (1, 9, 510, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "SNUH_DC16_KSH0_LDG0_0046\n",
      "before crop: (1, 4, 512, 512) after crop: (1, 4, 507, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "SNUH_DC16_KSH0_LDG0_0031\n",
      "SNUH_DC16_KSH0_LDG0_0048\n",
      "SNUH_DC16_KSH0_LDG0_0047\n",
      "before crop: (1, 3, 512, 512) after crop: (1, 3, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "SNUH_DC16_KSH0_LDG0_0050\n",
      "before crop: (1, 11, 512, 512) after crop: (1, 11, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (1, 32, 512, 512) after crop: (1, 32, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (1, 46, 512, 512) after crop: (1, 46, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "SNUH_DC16_KSH0_LDG0_0052\n",
      "before crop: (1, 6, 512, 512) after crop: (1, 6, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "SNUH_DC16_KSH0_LDG0_0051\n",
      "SNUH_DC16_KSH0_LDG0_0053\n",
      "before crop: (1, 7, 512, 512) after crop: (1, 7, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "SNUH_DC16_KSH0_LDG0_0054\n",
      "before crop: (1, 27, 512, 512) after crop: (1, 27, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (1, 6, 512, 512) after crop: (1, 6, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "SNUH_DC16_KSH0_LDG0_0056\n",
      "SNUH_DC16_KSH0_LDG0_0055\n",
      "SNUH_DC16_KSH0_LDG0_0058\n",
      "before crop: (1, 9, 512, 512) after crop: (1, 9, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (1, 17, 512, 512) after crop: (1, 17, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "SNUH_DC16_PJW0_RHC0_0001\n",
      "SNUH_DC16_KSH0_LDG0_0049\n",
      "before crop: (1, 19, 512, 512) after crop: (1, 19, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (1, 12, 512, 512) after crop: (1, 12, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (1, 16, 512, 512) after crop: (1, 16, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "SNUH_DC16_KSH0_LDG0_0057\n",
      "SNUH_DC16_PJW0_RHC0_0007\n",
      "before crop: (1, 8, 512, 512) after crop: (1, 8, 494, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "SNUH_DC16_KSH0_LDG0_0041\n",
      "before crop: (1, 1, 512, 512) after crop: (1, 1, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "SNUH_DC16_KSH0_LDG0_0059\n",
      "before crop: (1, 9, 512, 512) after crop: (1, 9, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "before crop: (1, 23, 512, 512) after crop: (1, 23, 512, 512) spacing: [1. 1. 1.] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Task486_NDHL\n",
      "number of threads:  (8, 8) \n",
      "\n",
      "not using nonzero mask for normalization\n",
      "Are we using the nonzero mask for normalizaion? OrderedDict([(0, False)])\n",
      "the median shape of the dataset is  [ 16.5 512.  512. ]\n",
      "the max shape in the dataset is  [100. 512. 512.]\n",
      "the min shape in the dataset is  [  1. 494. 512.]\n",
      "we don't want feature maps smaller than  4  in the bottleneck\n",
      "the transposed median shape of the dataset is  [ 16.5 512.  512. ]\n",
      "generating configuration for 3d_fullres\n",
      "{0: {'batch_size': 2, 'num_pool_per_axis': [1, 2, 2], 'patch_size': array([ 12, 444, 444]), 'median_patient_size_in_voxels': array([ 16, 512, 512]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': True, 'pool_op_kernel_sizes': [[2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3]]}}\n",
      "transpose forward [0, 1, 2]\n",
      "transpose backward [0, 1, 2]\n",
      "Initializing to run preprocessing\n",
      "npz folder: /tf/temp/nnUNet/nnunet/nnUNet_raw_data_base/nnUNet_cropped_data/Task486_NDHL\n",
      "output_folder: /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 3, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 3, 512, 512)} \n",
      "\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_stage0/SNUH_DC07_JCW0_RALP_0020.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 16, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 16, 512, 512)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 27, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 27, 512, 512)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 25, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 25, 512, 512)} \n",
      "\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_stage0/SNUH_DC07_JCW0_RALP_0000.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 28, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 28, 512, 512)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 29, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 29, 512, 512)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 32, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 32, 512, 512)} \n",
      "\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_stage0/SNUH_DC16_KSH0_LDG0_0038.npz\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_stage0/SNUH_DC16_KSH0_LDG0_0032.npz\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_stage0/SNUH_DC16_KSH0_LDG0_0036.npz\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_stage0/SNUH_DC16_KSH0_LDG0_0034.npz\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_stage0/SNUH_DC07_JCW0_RALP_0002.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 70, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 70, 512, 512)} \n",
      "\n",
      "1 10843\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_stage0/SNUH_DC07_JCW0_RALP_0031.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 100, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 100, 512, 512)} \n",
      "\n",
      "1 12137\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_stage0/SNUH_DC07_JCW0_RALP_0021.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 75, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 75, 512, 512)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 16, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 16, 512, 512)} \n",
      "\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_stage0/SNUH_DC16_KSH0_LDG0_0039.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 28, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 28, 512, 512)} \n",
      "\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_stage0/SNUH_DC07_JCW0_RALP_0001.npz\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_stage0/SNUH_DC16_KSH0_LDG0_0033.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 43, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 43, 512, 512)} \n",
      "\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_stage0/SNUH_DC16_KSH0_LDG0_0037.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 71, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 71, 512, 512)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 52, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 52, 512, 512)} \n",
      "\n",
      "1 11662\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_stage0/SNUH_DC16_KSH0_LDG0_0035.npz\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_stage0/SNUH_DC07_JCW0_RALP_0011.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 82, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 82, 512, 512)} \n",
      "\n",
      "1 14243\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_stage0/SNUH_DC16_KSH0_LDG0_0040.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 12, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 12, 512, 512)} \n",
      "\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_stage0/SNUH_DC16_KSH0_LDG0_0042.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 3, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 3, 512, 512)} \n",
      "\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_stage0/SNUH_DC16_KSH0_LDG0_0043.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 1, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 1, 512, 512)} \n",
      "\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_stage0/SNUH_DC16_KSH0_LDG0_0044.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 4, 507, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 4, 507, 512)} \n",
      "\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_stage0/SNUH_DC16_KSH0_LDG0_0046.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 9, 510, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 9, 510, 512)} \n",
      "\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_stage0/SNUH_DC16_KSH0_LDG0_0045.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 3, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 3, 512, 512)} \n",
      "\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_stage0/SNUH_DC16_KSH0_LDG0_0047.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 46, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 46, 512, 512)} \n",
      "\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_stage0/SNUH_DC16_KSH0_LDG0_0031.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 32, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 32, 512, 512)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 11, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 11, 512, 512)} \n",
      "\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_stage0/SNUH_DC16_KSH0_LDG0_0050.npz\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_stage0/SNUH_DC16_KSH0_LDG0_0048.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 6, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 6, 512, 512)} \n",
      "\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_stage0/SNUH_DC16_KSH0_LDG0_0052.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 27, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 27, 512, 512)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 6, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 6, 512, 512)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 7, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 7, 512, 512)} \n",
      "\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_stage0/SNUH_DC16_KSH0_LDG0_0054.npz\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_stage0/SNUH_DC16_KSH0_LDG0_0051.npz\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_stage0/SNUH_DC16_KSH0_LDG0_0053.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 17, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 17, 512, 512)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 9, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 9, 512, 512)} \n",
      "\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_stage0/SNUH_DC16_KSH0_LDG0_0055.npz\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_stage0/SNUH_DC16_KSH0_LDG0_0056.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 19, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 19, 512, 512)} \n",
      "\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_stage0/SNUH_DC16_KSH0_LDG0_0058.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 12, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 12, 512, 512)} \n",
      "\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_stage0/SNUH_DC16_PJW0_RHC0_0001.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 16, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 16, 512, 512)} \n",
      "\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_stage0/SNUH_DC16_KSH0_LDG0_0049.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 8, 494, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 8, 494, 512)} \n",
      "\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_stage0/SNUH_DC16_KSH0_LDG0_0057.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 1, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 1, 512, 512)} \n",
      "\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_stage0/SNUH_DC16_KSH0_LDG0_0041.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 9, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 9, 512, 512)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 23, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 23, 512, 512)} \n",
      "\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_stage0/SNUH_DC16_KSH0_LDG0_0059.npz\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_stage0/SNUH_DC16_PJW0_RHC0_0007.npz\n",
      "not using nonzero mask for normalization\n",
      "Are we using the nonzero maks for normalizaion? OrderedDict([(0, False)])\n",
      "the median shape of the dataset is  [ 16.5 512.  512. ]\n",
      "the max shape in the dataset is  [100. 512. 512.]\n",
      "the min shape in the dataset is  [  1. 494. 512.]\n",
      "we don't want feature maps smaller than  4  in the bottleneck\n",
      "the transposed median shape of the dataset is  [ 16.5 512.  512. ]\n",
      "[{'batch_size': 12, 'num_pool_per_axis': [7, 7], 'patch_size': array([512, 512]), 'median_patient_size_in_voxels': array([ 16, 512, 512]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}]\n",
      "Initializing to run preprocessing\n",
      "npz folder: /tf/temp/nnUNet/nnunet/nnUNet_raw_data_base/nnUNet_cropped_data/Task486_NDHL\n",
      "output_folder: /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 3, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 3, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC07_JCW0_RALP_0020.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 16, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 16, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 27, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 27, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 25, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 25, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 28, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 28, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC07_JCW0_RALP_0000.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 29, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 29, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 32, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 32, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "normalization done\n",
      "normalization done\n",
      "normalization done\n",
      "normalization done\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC16_KSH0_LDG0_0032.npz\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC16_KSH0_LDG0_0036.npz\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC16_KSH0_LDG0_0038.npz\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC16_KSH0_LDG0_0034.npz\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC07_JCW0_RALP_0002.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 70, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 70, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 10843\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC07_JCW0_RALP_0031.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 100, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 100, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 12137\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC07_JCW0_RALP_0021.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 75, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 75, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 16, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 16, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "normalization done\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC16_KSH0_LDG0_0039.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 28, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 28, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC07_JCW0_RALP_0001.npz\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC16_KSH0_LDG0_0033.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 43, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 43, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC16_KSH0_LDG0_0037.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 71, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 71, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 52, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 52, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "1 11662\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC16_KSH0_LDG0_0035.npz\n",
      "normalization done\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC07_JCW0_RALP_0011.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 82, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 82, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 12, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 12, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC16_KSH0_LDG0_0042.npz\n",
      "normalization done\n",
      "1 14243\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC16_KSH0_LDG0_0040.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 3, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 3, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC16_KSH0_LDG0_0043.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 1, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 1, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC16_KSH0_LDG0_0044.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 9, 510, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 9, 510, 512)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC16_KSH0_LDG0_0045.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 4, 507, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 4, 507, 512)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC16_KSH0_LDG0_0046.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 3, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 3, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC16_KSH0_LDG0_0047.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 46, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 46, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 11, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 11, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC16_KSH0_LDG0_0050.npz\n",
      "normalization done\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 32, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 32, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC16_KSH0_LDG0_0031.npz\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC16_KSH0_LDG0_0048.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 6, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 6, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC16_KSH0_LDG0_0052.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 27, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 27, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC16_KSH0_LDG0_0051.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 6, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 6, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC16_KSH0_LDG0_0054.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 7, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 7, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC16_KSH0_LDG0_0053.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 9, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 9, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC16_KSH0_LDG0_0055.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 17, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 17, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC16_KSH0_LDG0_0056.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 19, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 19, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC16_KSH0_LDG0_0058.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 12, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 12, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 16, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 16, 512, 512)} \n",
      "\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC16_PJW0_RHC0_0001.npz\n",
      "normalization...\n",
      "normalization done\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC16_KSH0_LDG0_0049.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 8, 494, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 8, 494, 512)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 9, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 9, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC16_KSH0_LDG0_0057.npz\n",
      "normalization done\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC16_KSH0_LDG0_0059.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 23, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 23, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 1, 512, 512)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 1, 512, 512)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC16_KSH0_LDG0_0041.npz\n",
      "normalization done\n",
      "1 10000\n",
      "saving:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_2D_stage0/SNUH_DC16_PJW0_RHC0_0007.npz\n"
     ]
    }
   ],
   "source": [
    "!nnUNet_convert_decathlon_task -i /tf/temp/nnUNet/nnunet/Tasks/Task86_NDHL -output_task_id 486 # -i : task_dir\n",
    "!nnUNet_plan_and_preprocess -t 486 # --verify_dataset_integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'png'}\n",
      "use_mask_for_norm OrderedDict([(0, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 12, 'num_pool_per_axis': [7, 7], 'patch_size': array([512, 512]), 'median_patient_size_in_voxels': array([ 16, 512, 512]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /tf/temp/nnUNet/nnunet/preprocessed/Task486_NDHL/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "unpacking dataset\n",
      "done\n",
      "2021-12-02 18:58:54.751395: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-12-02 18:59:01.286137: Unable to plot network architecture:\n",
      "2021-12-02 18:59:01.291675: No module named 'hiddenlayer'\n",
      "2021-12-02 18:59:01.298073: \n",
      "printing the network instead:\n",
      "\n",
      "2021-12-02 18:59:01.304009: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (1): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (2): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (3): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (4): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (5): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (6): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (4): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (5): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (6): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-12-02 18:59:01.315592: \n",
      "\n",
      "2021-12-02 18:59:01.321559: \n",
      "epoch:  0\n",
      "2021-12-02 19:02:00.826707: train loss : -0.3713\n",
      "2021-12-02 19:02:13.597348: validation loss: -0.6588\n",
      "2021-12-02 19:02:13.603206: Average global foreground Dice: [0.7874]\n",
      "2021-12-02 19:02:13.608675: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 19:02:14.026041: lr: 0.00982\n",
      "2021-12-02 19:02:14.032092: This epoch took 192.704250 s\n",
      "\n",
      "2021-12-02 19:02:14.039898: \n",
      "epoch:  1\n",
      "2021-12-02 19:05:08.098540: train loss : -0.6605\n",
      "2021-12-02 19:05:21.103650: validation loss: -0.7344\n",
      "2021-12-02 19:05:21.109650: Average global foreground Dice: [0.8367]\n",
      "2021-12-02 19:05:21.115144: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 19:05:21.621252: lr: 0.009639\n",
      "2021-12-02 19:05:21.735425: saving checkpoint...\n",
      "2021-12-02 19:05:22.969930: done, saving took 1.34 seconds\n",
      "2021-12-02 19:05:22.984689: This epoch took 188.938340 s\n",
      "\n",
      "2021-12-02 19:05:22.990646: \n",
      "epoch:  2\n",
      "2021-12-02 19:08:18.653898: train loss : -0.7177\n",
      "2021-12-02 19:08:31.837468: validation loss: -0.7736\n",
      "2021-12-02 19:08:31.844042: Average global foreground Dice: [0.8575]\n",
      "2021-12-02 19:08:31.850049: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 19:08:32.359487: lr: 0.009458\n",
      "2021-12-02 19:08:32.465366: saving checkpoint...\n",
      "2021-12-02 19:08:33.807407: done, saving took 1.44 seconds\n",
      "2021-12-02 19:08:33.830138: This epoch took 190.830099 s\n",
      "\n",
      "2021-12-02 19:08:33.836706: \n",
      "epoch:  3\n",
      "2021-12-02 19:11:29.888819: train loss : -0.7491\n",
      "2021-12-02 19:11:43.072901: validation loss: -0.8030\n",
      "2021-12-02 19:11:43.078890: Average global foreground Dice: [0.8826]\n",
      "2021-12-02 19:11:43.084746: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 19:11:43.591413: lr: 0.009277\n",
      "2021-12-02 19:11:43.683407: saving checkpoint...\n",
      "2021-12-02 19:11:45.047377: done, saving took 1.45 seconds\n",
      "2021-12-02 19:11:45.069220: This epoch took 191.226308 s\n",
      "\n",
      "2021-12-02 19:11:45.075088: \n",
      "epoch:  4\n",
      "2021-12-02 19:14:41.082238: train loss : -0.7734\n",
      "2021-12-02 19:14:54.211234: validation loss: -0.8142\n",
      "2021-12-02 19:14:54.218551: Average global foreground Dice: [0.8855]\n",
      "2021-12-02 19:14:54.224475: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 19:14:54.718279: lr: 0.009095\n",
      "2021-12-02 19:14:54.800370: saving checkpoint...\n",
      "2021-12-02 19:14:56.167093: done, saving took 1.44 seconds\n",
      "2021-12-02 19:14:56.195608: This epoch took 191.113804 s\n",
      "\n",
      "2021-12-02 19:14:56.202841: \n",
      "epoch:  5\n",
      "2021-12-02 19:17:52.098065: train loss : -0.7908\n",
      "2021-12-02 19:18:05.292158: validation loss: -0.8390\n",
      "2021-12-02 19:18:05.299385: Average global foreground Dice: [0.903]\n",
      "2021-12-02 19:18:05.305905: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 19:18:05.789661: lr: 0.008913\n",
      "2021-12-02 19:18:05.872053: saving checkpoint...\n",
      "2021-12-02 19:18:07.244954: done, saving took 1.45 seconds\n",
      "2021-12-02 19:18:07.271419: This epoch took 191.062367 s\n",
      "\n",
      "2021-12-02 19:18:07.278246: \n",
      "epoch:  6\n",
      "2021-12-02 19:21:03.312945: train loss : -0.8172\n",
      "2021-12-02 19:21:16.498011: validation loss: -0.8527\n",
      "2021-12-02 19:21:16.504758: Average global foreground Dice: [0.9092]\n",
      "2021-12-02 19:21:16.511604: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 19:21:17.008185: lr: 0.008731\n",
      "2021-12-02 19:21:17.099371: saving checkpoint...\n",
      "2021-12-02 19:21:18.381897: done, saving took 1.37 seconds\n",
      "2021-12-02 19:21:18.408664: This epoch took 191.123778 s\n",
      "\n",
      "2021-12-02 19:21:18.414900: \n",
      "epoch:  7\n",
      "2021-12-02 19:24:14.807209: train loss : -0.8447\n",
      "2021-12-02 19:24:28.006242: validation loss: -0.8790\n",
      "2021-12-02 19:24:28.013571: Average global foreground Dice: [0.9255]\n",
      "2021-12-02 19:24:28.019601: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 19:24:28.602911: lr: 0.008548\n",
      "2021-12-02 19:24:28.647776: saving checkpoint...\n",
      "2021-12-02 19:24:29.995361: done, saving took 1.39 seconds\n",
      "2021-12-02 19:24:30.016258: This epoch took 191.595429 s\n",
      "\n",
      "2021-12-02 19:24:30.022407: \n",
      "epoch:  8\n",
      "2021-12-02 19:27:26.937289: train loss : -0.8450\n",
      "2021-12-02 19:27:40.147601: validation loss: -0.8519\n",
      "2021-12-02 19:27:40.154690: Average global foreground Dice: [0.9114]\n",
      "2021-12-02 19:27:40.161307: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 19:27:40.660457: lr: 0.008364\n",
      "2021-12-02 19:27:40.704734: saving checkpoint...\n",
      "2021-12-02 19:27:42.020707: done, saving took 1.35 seconds\n",
      "2021-12-02 19:27:42.044600: This epoch took 192.015497 s\n",
      "\n",
      "2021-12-02 19:27:42.050322: \n",
      "epoch:  9\n",
      "2021-12-02 19:30:38.242301: train loss : -0.8419\n",
      "2021-12-02 19:30:51.403772: validation loss: -0.8841\n",
      "2021-12-02 19:30:51.410407: Average global foreground Dice: [0.9295]\n",
      "2021-12-02 19:30:51.417211: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 19:30:51.919606: lr: 0.008181\n",
      "2021-12-02 19:30:51.964223: saving checkpoint...\n",
      "2021-12-02 19:30:53.332646: done, saving took 1.41 seconds\n",
      "2021-12-02 19:30:53.357444: This epoch took 191.301018 s\n",
      "\n",
      "2021-12-02 19:30:53.364646: \n",
      "epoch:  10\n",
      "2021-12-02 19:33:49.539590: train loss : -0.8761\n",
      "2021-12-02 19:34:02.744981: validation loss: -0.8991\n",
      "2021-12-02 19:34:02.751639: Average global foreground Dice: [0.9384]\n",
      "2021-12-02 19:34:02.757960: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 19:34:03.289370: lr: 0.007996\n",
      "2021-12-02 19:34:03.335957: saving checkpoint...\n",
      "2021-12-02 19:34:04.690662: done, saving took 1.40 seconds\n",
      "2021-12-02 19:34:04.715254: This epoch took 191.343966 s\n",
      "\n",
      "2021-12-02 19:34:04.721281: \n",
      "epoch:  11\n",
      "2021-12-02 19:37:01.403481: train loss : -0.8811\n",
      "2021-12-02 19:37:14.606718: validation loss: -0.9014\n",
      "2021-12-02 19:37:14.613601: Average global foreground Dice: [0.94]\n",
      "2021-12-02 19:37:14.619342: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 19:37:15.130401: lr: 0.007811\n",
      "2021-12-02 19:37:15.176516: saving checkpoint...\n",
      "2021-12-02 19:37:16.567129: done, saving took 1.43 seconds\n",
      "2021-12-02 19:37:16.595238: This epoch took 191.867338 s\n",
      "\n",
      "2021-12-02 19:37:16.601583: \n",
      "epoch:  12\n",
      "2021-12-02 19:40:13.588094: train loss : -0.8779\n",
      "2021-12-02 19:40:26.793693: validation loss: -0.8955\n",
      "2021-12-02 19:40:26.803314: Average global foreground Dice: [0.9365]\n",
      "2021-12-02 19:40:26.809136: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 19:40:27.310820: lr: 0.007626\n",
      "2021-12-02 19:40:27.369209: saving checkpoint...\n",
      "2021-12-02 19:40:28.767276: done, saving took 1.45 seconds\n",
      "2021-12-02 19:40:28.796351: This epoch took 192.188311 s\n",
      "\n",
      "2021-12-02 19:40:28.803028: \n",
      "epoch:  13\n",
      "2021-12-02 19:43:25.241420: train loss : -0.8913\n",
      "2021-12-02 19:43:38.430715: validation loss: -0.9110\n",
      "2021-12-02 19:43:38.437200: Average global foreground Dice: [0.9466]\n",
      "2021-12-02 19:43:38.444998: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 19:43:38.960779: lr: 0.00744\n",
      "2021-12-02 19:43:39.005495: saving checkpoint...\n",
      "2021-12-02 19:43:40.297418: done, saving took 1.33 seconds\n",
      "2021-12-02 19:43:40.320433: This epoch took 191.511613 s\n",
      "\n",
      "2021-12-02 19:43:40.326831: \n",
      "epoch:  14\n",
      "2021-12-02 19:46:36.405180: train loss : -0.8996\n",
      "2021-12-02 19:46:49.604874: validation loss: -0.9193\n",
      "2021-12-02 19:46:49.611959: Average global foreground Dice: [0.9509]\n",
      "2021-12-02 19:46:49.618433: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 19:46:50.144376: lr: 0.007254\n",
      "2021-12-02 19:46:50.188597: saving checkpoint...\n",
      "2021-12-02 19:46:51.486679: done, saving took 1.34 seconds\n",
      "2021-12-02 19:46:51.508562: This epoch took 191.175744 s\n",
      "\n",
      "2021-12-02 19:46:51.514768: \n",
      "epoch:  15\n",
      "2021-12-02 19:49:47.802161: train loss : -0.9099\n",
      "2021-12-02 19:50:01.030186: validation loss: -0.9265\n",
      "2021-12-02 19:50:01.037294: Average global foreground Dice: [0.9551]\n",
      "2021-12-02 19:50:01.043507: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 19:50:01.545618: lr: 0.007067\n",
      "2021-12-02 19:50:01.590294: saving checkpoint...\n",
      "2021-12-02 19:50:02.920289: done, saving took 1.37 seconds\n",
      "2021-12-02 19:50:02.941239: This epoch took 191.420370 s\n",
      "\n",
      "2021-12-02 19:50:02.947479: \n",
      "epoch:  16\n",
      "2021-12-02 19:52:59.917330: train loss : -0.9037\n",
      "2021-12-02 19:53:13.147757: validation loss: -0.9267\n",
      "2021-12-02 19:53:13.154653: Average global foreground Dice: [0.9556]\n",
      "2021-12-02 19:53:13.161266: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 19:53:13.700692: lr: 0.00688\n",
      "2021-12-02 19:53:13.784174: saving checkpoint...\n",
      "2021-12-02 19:53:15.116307: done, saving took 1.41 seconds\n",
      "2021-12-02 19:53:15.142868: This epoch took 192.189649 s\n",
      "\n",
      "2021-12-02 19:53:15.149449: \n",
      "epoch:  17\n",
      "2021-12-02 19:56:12.331513: train loss : -0.9106\n",
      "2021-12-02 19:56:25.537373: validation loss: -0.9294\n",
      "2021-12-02 19:56:25.544880: Average global foreground Dice: [0.9568]\n",
      "2021-12-02 19:56:25.550870: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 19:56:26.059548: lr: 0.006692\n",
      "2021-12-02 19:56:26.147527: saving checkpoint...\n",
      "2021-12-02 19:56:27.455879: done, saving took 1.39 seconds\n",
      "2021-12-02 19:56:27.484234: This epoch took 192.328557 s\n",
      "\n",
      "2021-12-02 19:56:27.490772: \n",
      "epoch:  18\n",
      "2021-12-02 19:59:24.314178: train loss : -0.9145\n",
      "2021-12-02 19:59:37.507868: validation loss: -0.9324\n",
      "2021-12-02 19:59:37.514925: Average global foreground Dice: [0.959]\n",
      "2021-12-02 19:59:37.521566: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 19:59:38.022232: lr: 0.006504\n",
      "2021-12-02 19:59:38.114418: saving checkpoint...\n",
      "2021-12-02 19:59:39.503252: done, saving took 1.47 seconds\n",
      "2021-12-02 19:59:39.531001: This epoch took 192.034528 s\n",
      "\n",
      "2021-12-02 19:59:39.537296: \n",
      "epoch:  19\n",
      "2021-12-02 20:02:35.877988: train loss : -0.9155\n",
      "2021-12-02 20:02:49.063507: validation loss: -0.9270\n",
      "2021-12-02 20:02:49.069752: Average global foreground Dice: [0.9556]\n",
      "2021-12-02 20:02:49.076120: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 20:02:49.566689: lr: 0.006314\n",
      "2021-12-02 20:02:49.645437: saving checkpoint...\n",
      "2021-12-02 20:02:50.932711: done, saving took 1.36 seconds\n",
      "2021-12-02 20:02:50.960971: This epoch took 191.417480 s\n",
      "\n",
      "2021-12-02 20:02:50.966424: \n",
      "epoch:  20\n",
      "2021-12-02 20:05:47.611408: train loss : -0.9137\n",
      "2021-12-02 20:06:00.802720: validation loss: -0.9323\n",
      "2021-12-02 20:06:00.809273: Average global foreground Dice: [0.9585]\n",
      "2021-12-02 20:06:00.815670: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 20:06:01.323996: lr: 0.006125\n",
      "2021-12-02 20:06:01.416384: saving checkpoint...\n",
      "2021-12-02 20:06:02.748476: done, saving took 1.42 seconds\n",
      "2021-12-02 20:06:02.778090: This epoch took 191.805748 s\n",
      "\n",
      "2021-12-02 20:06:02.784241: \n",
      "epoch:  21\n",
      "2021-12-02 20:08:59.493358: train loss : -0.9156\n",
      "2021-12-02 20:09:12.690045: validation loss: -0.9357\n",
      "2021-12-02 20:09:12.697752: Average global foreground Dice: [0.9599]\n",
      "2021-12-02 20:09:12.704706: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 20:09:13.207351: lr: 0.005934\n",
      "2021-12-02 20:09:13.300819: saving checkpoint...\n",
      "2021-12-02 20:09:14.702625: done, saving took 1.49 seconds\n",
      "2021-12-02 20:09:14.732754: This epoch took 191.942097 s\n",
      "\n",
      "2021-12-02 20:09:14.739257: \n",
      "epoch:  22\n",
      "2021-12-02 20:12:11.109532: train loss : -0.9202\n",
      "2021-12-02 20:12:24.315665: validation loss: -0.9410\n",
      "2021-12-02 20:12:24.322999: Average global foreground Dice: [0.9644]\n",
      "2021-12-02 20:12:24.329190: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 20:12:24.821729: lr: 0.005743\n",
      "2021-12-02 20:12:24.915205: saving checkpoint...\n",
      "2021-12-02 20:12:26.238328: done, saving took 1.41 seconds\n",
      "2021-12-02 20:12:26.269347: This epoch took 191.522996 s\n",
      "\n",
      "2021-12-02 20:12:26.275199: \n",
      "epoch:  23\n",
      "2021-12-02 20:15:22.053148: train loss : -0.9296\n",
      "2021-12-02 20:15:35.198313: validation loss: -0.9386\n",
      "2021-12-02 20:15:35.204631: Average global foreground Dice: [0.9624]\n",
      "2021-12-02 20:15:35.210166: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 20:15:35.695269: lr: 0.005551\n",
      "2021-12-02 20:15:35.769373: saving checkpoint...\n",
      "2021-12-02 20:15:37.054739: done, saving took 1.35 seconds\n",
      "2021-12-02 20:15:37.083131: This epoch took 190.801295 s\n",
      "\n",
      "2021-12-02 20:15:37.088789: \n",
      "epoch:  24\n",
      "/tf/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-12-02 20:18:33.050224: train loss : -0.9278\n",
      "2021-12-02 20:18:45.573073: validation loss: -0.9411\n",
      "2021-12-02 20:18:45.579770: Average global foreground Dice: [0.9638]\n",
      "2021-12-02 20:18:45.586455: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 20:18:46.078152: lr: 0.005359\n",
      "2021-12-02 20:18:46.151198: saving checkpoint...\n",
      "2021-12-02 20:18:47.497571: done, saving took 1.41 seconds\n",
      "2021-12-02 20:18:47.522159: This epoch took 190.427047 s\n",
      "\n",
      "2021-12-02 20:18:47.528209: \n",
      "epoch:  25\n",
      "2021-12-02 20:21:33.010698: train loss : -0.9299\n",
      "2021-12-02 20:21:45.317043: validation loss: -0.9420\n",
      "2021-12-02 20:21:45.324172: Average global foreground Dice: [0.9646]\n",
      "2021-12-02 20:21:45.330669: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 20:21:45.829115: lr: 0.005166\n",
      "2021-12-02 20:21:45.873009: saving checkpoint...\n",
      "2021-12-02 20:21:47.232786: done, saving took 1.40 seconds\n",
      "2021-12-02 20:21:47.254193: This epoch took 179.720290 s\n",
      "\n",
      "2021-12-02 20:21:47.260139: \n",
      "epoch:  26\n",
      "2021-12-02 20:24:38.784224: train loss : -0.9318\n",
      "2021-12-02 20:24:52.018779: validation loss: -0.9452\n",
      "2021-12-02 20:24:52.025376: Average global foreground Dice: [0.9664]\n",
      "2021-12-02 20:24:52.031688: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 20:24:52.525074: lr: 0.004971\n",
      "2021-12-02 20:24:52.569978: saving checkpoint...\n",
      "2021-12-02 20:24:53.871162: done, saving took 1.34 seconds\n",
      "2021-12-02 20:24:53.893091: This epoch took 186.626756 s\n",
      "\n",
      "2021-12-02 20:24:53.899542: \n",
      "epoch:  27\n",
      "2021-12-02 20:27:49.619781: train loss : -0.9308\n",
      "2021-12-02 20:28:02.723075: validation loss: -0.9393\n",
      "2021-12-02 20:28:02.729745: Average global foreground Dice: [0.9624]\n",
      "2021-12-02 20:28:02.736688: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 20:28:03.238432: lr: 0.004776\n",
      "2021-12-02 20:28:03.284137: saving checkpoint...\n",
      "2021-12-02 20:28:04.638128: done, saving took 1.39 seconds\n",
      "2021-12-02 20:28:04.659722: This epoch took 190.754709 s\n",
      "\n",
      "2021-12-02 20:28:04.666187: \n",
      "epoch:  28\n",
      "2021-12-02 20:31:00.819746: train loss : -0.9304\n",
      "2021-12-02 20:31:14.005700: validation loss: -0.9421\n",
      "2021-12-02 20:31:14.012139: Average global foreground Dice: [0.9644]\n",
      "2021-12-02 20:31:14.018627: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 20:31:14.535725: lr: 0.004581\n",
      "2021-12-02 20:31:14.580605: saving checkpoint...\n",
      "2021-12-02 20:31:15.854271: done, saving took 1.31 seconds\n",
      "2021-12-02 20:31:15.876449: This epoch took 191.203725 s\n",
      "\n",
      "2021-12-02 20:31:15.883045: \n",
      "epoch:  29\n",
      "2021-12-02 20:34:12.683838: train loss : -0.9281\n",
      "2021-12-02 20:34:25.835208: validation loss: -0.9482\n",
      "2021-12-02 20:34:25.843132: Average global foreground Dice: [0.9682]\n",
      "2021-12-02 20:34:25.850170: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 20:34:26.357743: lr: 0.004384\n",
      "2021-12-02 20:34:26.407587: saving checkpoint...\n",
      "2021-12-02 20:34:27.729521: done, saving took 1.36 seconds\n",
      "2021-12-02 20:34:27.756283: This epoch took 191.866540 s\n",
      "\n",
      "2021-12-02 20:34:27.762535: \n",
      "epoch:  30\n",
      "2021-12-02 20:37:23.563494: train loss : -0.9361\n",
      "2021-12-02 20:37:36.770716: validation loss: -0.9491\n",
      "2021-12-02 20:37:36.778546: Average global foreground Dice: [0.9693]\n",
      "2021-12-02 20:37:36.784811: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 20:37:37.280926: lr: 0.004186\n",
      "2021-12-02 20:37:37.361595: saving checkpoint...\n",
      "2021-12-02 20:37:38.776868: done, saving took 1.49 seconds\n",
      "2021-12-02 20:37:38.809934: This epoch took 191.040776 s\n",
      "\n",
      "2021-12-02 20:37:38.816555: \n",
      "epoch:  31\n",
      "2021-12-02 20:40:35.226720: train loss : -0.9402\n",
      "2021-12-02 20:40:48.396538: validation loss: -0.9521\n",
      "2021-12-02 20:40:48.403364: Average global foreground Dice: [0.9708]\n",
      "2021-12-02 20:40:48.409693: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 20:40:48.902137: lr: 0.003987\n",
      "2021-12-02 20:40:48.980407: saving checkpoint...\n",
      "2021-12-02 20:40:50.292099: done, saving took 1.38 seconds\n",
      "2021-12-02 20:40:50.319420: This epoch took 191.496083 s\n",
      "\n",
      "2021-12-02 20:40:50.326035: \n",
      "epoch:  32\n",
      "2021-12-02 20:43:46.386942: train loss : -0.9406\n",
      "2021-12-02 20:43:59.479375: validation loss: -0.9472\n",
      "2021-12-02 20:43:59.487305: Average global foreground Dice: [0.9677]\n",
      "2021-12-02 20:43:59.493224: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 20:44:00.003111: lr: 0.003787\n",
      "2021-12-02 20:44:00.098145: saving checkpoint...\n",
      "2021-12-02 20:44:01.549557: done, saving took 1.54 seconds\n",
      "2021-12-02 20:44:01.578652: This epoch took 191.247322 s\n",
      "\n",
      "2021-12-02 20:44:01.584907: \n",
      "epoch:  33\n",
      "2021-12-02 20:46:57.851312: train loss : -0.9386\n",
      "2021-12-02 20:47:11.050006: validation loss: -0.9514\n",
      "2021-12-02 20:47:11.057179: Average global foreground Dice: [0.9702]\n",
      "2021-12-02 20:47:11.062902: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 20:47:11.564620: lr: 0.003586\n",
      "2021-12-02 20:47:11.659452: saving checkpoint...\n",
      "2021-12-02 20:47:12.971546: done, saving took 1.40 seconds\n",
      "2021-12-02 20:47:13.000667: This epoch took 191.409810 s\n",
      "\n",
      "2021-12-02 20:47:13.005998: \n",
      "epoch:  34\n",
      "2021-12-02 20:50:08.886512: train loss : -0.9411\n",
      "2021-12-02 20:50:22.059538: validation loss: -0.9513\n",
      "2021-12-02 20:50:22.067338: Average global foreground Dice: [0.9699]\n",
      "2021-12-02 20:50:22.074306: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 20:50:22.588246: lr: 0.003384\n",
      "2021-12-02 20:50:22.683636: saving checkpoint...\n",
      "2021-12-02 20:50:23.988563: done, saving took 1.39 seconds\n",
      "2021-12-02 20:50:24.015574: This epoch took 191.003001 s\n",
      "\n",
      "2021-12-02 20:50:24.022291: \n",
      "epoch:  35\n",
      "2021-12-02 20:53:19.575617: train loss : -0.9430\n",
      "2021-12-02 20:53:32.696009: validation loss: -0.9524\n",
      "2021-12-02 20:53:32.702586: Average global foreground Dice: [0.9706]\n",
      "2021-12-02 20:53:32.709231: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 20:53:33.200122: lr: 0.00318\n",
      "2021-12-02 20:53:33.271746: saving checkpoint...\n",
      "2021-12-02 20:53:34.564029: done, saving took 1.36 seconds\n",
      "2021-12-02 20:53:34.591183: This epoch took 190.562634 s\n",
      "\n",
      "2021-12-02 20:53:34.598102: \n",
      "epoch:  36\n",
      "2021-12-02 20:56:30.310671: train loss : -0.9433\n",
      "2021-12-02 20:56:43.493145: validation loss: -0.9531\n",
      "2021-12-02 20:56:43.499802: Average global foreground Dice: [0.9711]\n",
      "2021-12-02 20:56:43.506029: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 20:56:44.027991: lr: 0.002975\n",
      "2021-12-02 20:56:44.099304: saving checkpoint...\n",
      "2021-12-02 20:56:45.467319: done, saving took 1.43 seconds\n",
      "2021-12-02 20:56:45.500452: This epoch took 190.895929 s\n",
      "\n",
      "2021-12-02 20:56:45.507526: \n",
      "epoch:  37\n",
      "2021-12-02 20:59:40.905865: train loss : -0.9463\n",
      "2021-12-02 20:59:53.996081: validation loss: -0.9552\n",
      "2021-12-02 20:59:54.002808: Average global foreground Dice: [0.9729]\n",
      "2021-12-02 20:59:54.008789: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 20:59:54.503419: lr: 0.002768\n",
      "2021-12-02 20:59:54.582262: saving checkpoint...\n",
      "2021-12-02 20:59:55.884493: done, saving took 1.37 seconds\n",
      "2021-12-02 20:59:55.912549: This epoch took 190.398730 s\n",
      "\n",
      "2021-12-02 20:59:55.918868: \n",
      "epoch:  38\n",
      "2021-12-02 21:02:50.926613: train loss : -0.9462\n",
      "2021-12-02 21:03:04.052691: validation loss: -0.9551\n",
      "2021-12-02 21:03:04.060371: Average global foreground Dice: [0.9725]\n",
      "2021-12-02 21:03:04.066732: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 21:03:04.580942: lr: 0.00256\n",
      "2021-12-02 21:03:04.674141: saving checkpoint...\n",
      "2021-12-02 21:03:05.981733: done, saving took 1.39 seconds\n",
      "2021-12-02 21:03:06.011969: This epoch took 190.086782 s\n",
      "\n",
      "2021-12-02 21:03:06.017459: \n",
      "epoch:  39\n",
      "2021-12-02 21:06:01.762738: train loss : -0.9432\n",
      "2021-12-02 21:06:14.870868: validation loss: -0.9526\n",
      "2021-12-02 21:06:14.879610: Average global foreground Dice: [0.9712]\n",
      "2021-12-02 21:06:14.885545: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 21:06:15.383332: lr: 0.002349\n",
      "2021-12-02 21:06:15.480815: saving checkpoint...\n",
      "2021-12-02 21:06:16.912006: done, saving took 1.52 seconds\n",
      "2021-12-02 21:06:16.934214: This epoch took 190.910309 s\n",
      "\n",
      "2021-12-02 21:06:16.940699: \n",
      "epoch:  40\n",
      "2021-12-02 21:09:10.762246: train loss : -0.9468\n",
      "2021-12-02 21:09:23.016264: validation loss: -0.9558\n",
      "2021-12-02 21:09:23.025100: Average global foreground Dice: [0.9728]\n",
      "2021-12-02 21:09:23.031576: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 21:09:23.561161: lr: 0.002137\n",
      "2021-12-02 21:09:23.656220: saving checkpoint...\n",
      "2021-12-02 21:09:24.993699: done, saving took 1.43 seconds\n",
      "2021-12-02 21:09:25.021451: This epoch took 188.074548 s\n",
      "\n",
      "2021-12-02 21:09:25.027820: \n",
      "epoch:  41\n",
      "2021-12-02 21:12:10.514831: train loss : -0.9473\n",
      "2021-12-02 21:12:22.926127: validation loss: -0.9562\n",
      "2021-12-02 21:12:22.932439: Average global foreground Dice: [0.9731]\n",
      "2021-12-02 21:12:22.938212: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 21:12:23.431630: lr: 0.001922\n",
      "2021-12-02 21:12:23.504005: saving checkpoint...\n",
      "2021-12-02 21:12:24.808357: done, saving took 1.37 seconds\n",
      "2021-12-02 21:12:24.834180: This epoch took 179.800408 s\n",
      "\n",
      "2021-12-02 21:12:24.839794: \n",
      "epoch:  42\n",
      "2021-12-02 21:15:18.144110: train loss : -0.9489\n",
      "2021-12-02 21:15:31.140265: validation loss: -0.9558\n",
      "2021-12-02 21:15:31.147350: Average global foreground Dice: [0.9727]\n",
      "2021-12-02 21:15:31.153322: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 21:15:31.686268: lr: 0.001704\n",
      "2021-12-02 21:15:31.760236: saving checkpoint...\n",
      "2021-12-02 21:15:33.104447: done, saving took 1.41 seconds\n",
      "2021-12-02 21:15:33.133031: This epoch took 188.287675 s\n",
      "\n",
      "2021-12-02 21:15:33.139130: \n",
      "epoch:  43\n",
      "2021-12-02 21:18:28.783587: train loss : -0.9494\n",
      "2021-12-02 21:18:41.982569: validation loss: -0.9577\n",
      "2021-12-02 21:18:41.989707: Average global foreground Dice: [0.9742]\n",
      "2021-12-02 21:18:41.996612: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 21:18:42.486411: lr: 0.001483\n",
      "2021-12-02 21:18:42.531670: saving checkpoint...\n",
      "2021-12-02 21:18:43.874849: done, saving took 1.38 seconds\n",
      "2021-12-02 21:18:43.898767: This epoch took 190.753576 s\n",
      "\n",
      "2021-12-02 21:18:43.905386: \n",
      "epoch:  44\n",
      "2021-12-02 21:21:40.070618: train loss : -0.9500\n",
      "2021-12-02 21:21:53.279270: validation loss: -0.9593\n",
      "2021-12-02 21:21:53.286694: Average global foreground Dice: [0.975]\n",
      "2021-12-02 21:21:53.293665: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 21:21:53.795626: lr: 0.001259\n",
      "2021-12-02 21:21:53.839439: saving checkpoint...\n",
      "2021-12-02 21:21:55.177282: done, saving took 1.38 seconds\n",
      "2021-12-02 21:21:55.199157: This epoch took 191.288169 s\n",
      "\n",
      "2021-12-02 21:21:55.205109: \n",
      "epoch:  45\n",
      "2021-12-02 21:24:51.299126: train loss : -0.9520\n",
      "2021-12-02 21:25:04.481073: validation loss: -0.9589\n",
      "2021-12-02 21:25:04.487798: Average global foreground Dice: [0.9751]\n",
      "2021-12-02 21:25:04.493866: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 21:25:05.013463: lr: 0.00103\n",
      "2021-12-02 21:25:05.060608: saving checkpoint...\n",
      "2021-12-02 21:25:06.536187: done, saving took 1.51 seconds\n",
      "2021-12-02 21:25:06.559351: This epoch took 191.347986 s\n",
      "\n",
      "2021-12-02 21:25:06.566054: \n",
      "epoch:  46\n",
      "2021-12-02 21:28:02.878176: train loss : -0.9521\n",
      "2021-12-02 21:28:16.072905: validation loss: -0.9606\n",
      "2021-12-02 21:28:16.080084: Average global foreground Dice: [0.9761]\n",
      "2021-12-02 21:28:16.086275: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 21:28:16.577760: lr: 0.000795\n",
      "2021-12-02 21:28:16.623460: saving checkpoint...\n",
      "2021-12-02 21:28:17.929191: done, saving took 1.34 seconds\n",
      "2021-12-02 21:28:17.953097: This epoch took 191.380838 s\n",
      "\n",
      "2021-12-02 21:28:17.960054: \n",
      "epoch:  47\n",
      "2021-12-02 21:31:14.652762: train loss : -0.9526\n",
      "2021-12-02 21:31:27.874483: validation loss: -0.9598\n",
      "2021-12-02 21:31:27.883152: Average global foreground Dice: [0.9757]\n",
      "2021-12-02 21:31:27.889184: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 21:31:28.376667: lr: 0.000552\n",
      "2021-12-02 21:31:28.421897: saving checkpoint...\n",
      "2021-12-02 21:31:29.840307: done, saving took 1.46 seconds\n",
      "2021-12-02 21:31:29.866070: This epoch took 191.899842 s\n",
      "\n",
      "2021-12-02 21:31:29.872451: \n",
      "epoch:  48\n",
      "2021-12-02 21:34:26.738682: train loss : -0.9515\n",
      "2021-12-02 21:34:39.969464: validation loss: -0.9600\n",
      "2021-12-02 21:34:39.976074: Average global foreground Dice: [0.9757]\n",
      "2021-12-02 21:34:39.982663: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 21:34:40.482841: lr: 0.000296\n",
      "2021-12-02 21:34:40.554546: saving checkpoint...\n",
      "2021-12-02 21:34:41.947576: done, saving took 1.46 seconds\n",
      "2021-12-02 21:34:41.977921: This epoch took 192.098996 s\n",
      "\n",
      "2021-12-02 21:34:41.984201: \n",
      "epoch:  49\n",
      "2021-12-02 21:37:38.975253: train loss : -0.9534\n",
      "2021-12-02 21:37:52.183761: validation loss: -0.9616\n",
      "2021-12-02 21:37:52.191178: Average global foreground Dice: [0.977]\n",
      "2021-12-02 21:37:52.197530: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-12-02 21:37:52.690169: lr: 0.0\n",
      "2021-12-02 21:37:52.696300: saving scheduled checkpoint file...\n",
      "2021-12-02 21:37:52.775215: saving checkpoint...\n",
      "2021-12-02 21:37:53.935047: done, saving took 1.23 seconds\n",
      "2021-12-02 21:37:53.955683: done\n",
      "2021-12-02 21:37:54.034953: saving checkpoint...\n",
      "2021-12-02 21:37:55.315674: done, saving took 1.35 seconds\n",
      "2021-12-02 21:37:55.342019: This epoch took 193.351379 s\n",
      "\n",
      "2021-12-02 21:37:55.421079: saving checkpoint...\n",
      "2021-12-02 21:37:56.642646: done, saving took 1.29 seconds\n",
      "SNUH_DC07_JCW0_RALP_0000 (2, 16, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RALP_0001 (2, 75, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RALP_0002 (2, 32, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RALP_0011 (2, 52, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "SNUH_DC07_JCW0_RALP_0020 (2, 3, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RALP_0021 (2, 100, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RALP_0031 (2, 70, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC16_KSH0_LDG0_0031 (2, 46, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC16_KSH0_LDG0_0032 (2, 27, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC16_KSH0_LDG0_0033 (2, 28, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC16_KSH0_LDG0_0034 (2, 29, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC16_KSH0_LDG0_0035 (2, 71, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC16_KSH0_LDG0_0036 (2, 28, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC16_KSH0_LDG0_0037 (2, 43, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC16_KSH0_LDG0_0038 (2, 25, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC16_KSH0_LDG0_0039 (2, 16, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC16_KSH0_LDG0_0040 (2, 82, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "SNUH_DC16_KSH0_LDG0_0041 (2, 1, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "SNUH_DC16_KSH0_LDG0_0042 (2, 12, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC16_KSH0_LDG0_0043 (2, 3, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC16_KSH0_LDG0_0044 (2, 1, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC16_KSH0_LDG0_0045 (2, 9, 510, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC16_KSH0_LDG0_0046 (2, 4, 507, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC16_KSH0_LDG0_0047 (2, 3, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC16_KSH0_LDG0_0048 (2, 32, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC16_KSH0_LDG0_0049 (2, 16, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC16_KSH0_LDG0_0050 (2, 11, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC16_KSH0_LDG0_0051 (2, 27, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "SNUH_DC16_KSH0_LDG0_0052 (2, 6, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC16_KSH0_LDG0_0053 (2, 7, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC16_KSH0_LDG0_0054 (2, 6, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC16_KSH0_LDG0_0055 (2, 9, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC16_KSH0_LDG0_0056 (2, 17, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC16_KSH0_LDG0_0057 (2, 8, 494, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC16_KSH0_LDG0_0058 (2, 19, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC16_KSH0_LDG0_0059 (2, 9, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC16_PJW0_RHC0_0001 (2, 12, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC16_PJW0_RHC0_0007 (2, 23, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-12-02 21:40:04.031063: finished prediction\n",
      "2021-12-02 21:40:04.039084: evaluation of raw predictions\n",
      "2021-12-02 21:40:06.618382: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.9760732229695084\n",
      "after:  0.5527762397304363\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "!nnUNet_train 2d nnUNetTrainerV2 486 all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'png'}\n",
      "use_mask_for_norm OrderedDict([(0, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [3, 4, 4], 'patch_size': array([ 40, 256, 240]), 'median_patient_size_in_voxels': array([ 67, 380, 380]), 'current_spacing': array([1.34784892, 1.34784892, 1.34784892]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': True, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "stage:  1\n",
      "{'batch_size': 2, 'num_pool_per_axis': [3, 4, 4], 'patch_size': array([ 40, 256, 240]), 'median_patient_size_in_voxels': array([ 90, 512, 512]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': True, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 1 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /tf/temp/nnUNet/nnunet/preprocessed/Task480_GRSR/nnUNetData_plans_v2.1\n",
      "###############################################\n",
      "2021-11-28 01:23:31.603028: Using dummy2d data augmentation\n",
      "loading dataset\n",
      "loading all case properties\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-28 01:23:46.810214: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-28 01:23:56.920214: Unable to plot network architecture:\n",
      "2021-11-28 01:23:56.929540: No module named 'hiddenlayer'\n",
      "2021-11-28 01:23:56.936451: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-28 01:23:57.008937: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose3d(320, 256, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)\n",
      "    (1): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (2): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (3): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (1): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (2): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (3): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-28 01:23:57.020546: \n",
      "\n",
      "2021-11-28 01:23:57.027313: \n",
      "epoch:  0\n",
      "2021-11-28 01:29:10.103974: train loss : 0.2984\n",
      "2021-11-28 01:29:31.401932: validation loss: 0.2402\n",
      "2021-11-28 01:29:31.409589: Average global foreground Dice: [0.0013]\n",
      "2021-11-28 01:29:31.415964: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 01:29:31.856273: lr: 0.00982\n",
      "2021-11-28 01:29:31.863616: This epoch took 334.830037 s\n",
      "\n",
      "2021-11-28 01:29:31.870094: \n",
      "epoch:  1\n",
      "2021-11-28 01:34:21.360800: train loss : 0.2380\n",
      "2021-11-28 01:34:42.713287: validation loss: 0.2369\n",
      "2021-11-28 01:34:42.721510: Average global foreground Dice: [0.0009]\n",
      "2021-11-28 01:34:42.727642: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 01:34:43.239060: lr: 0.009639\n",
      "2021-11-28 01:34:43.249839: This epoch took 311.373793 s\n",
      "\n",
      "2021-11-28 01:34:43.259934: \n",
      "epoch:  2\n",
      "2021-11-28 01:39:32.580458: train loss : 0.2380\n",
      "2021-11-28 01:39:53.894269: validation loss: 0.2513\n",
      "2021-11-28 01:39:53.901269: Average global foreground Dice: [0.0039]\n",
      "2021-11-28 01:39:53.908525: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 01:39:54.418704: lr: 0.009458\n",
      "2021-11-28 01:39:54.451496: saving checkpoint...\n",
      "2021-11-28 01:39:55.048198: done, saving took 0.62 seconds\n",
      "2021-11-28 01:39:55.067245: This epoch took 311.800808 s\n",
      "\n",
      "2021-11-28 01:39:55.073737: \n",
      "epoch:  3\n",
      "2021-11-28 01:44:44.451833: train loss : 0.2307\n",
      "2021-11-28 01:45:05.771967: validation loss: 0.2288\n",
      "2021-11-28 01:45:05.779692: Average global foreground Dice: [0.0013]\n",
      "2021-11-28 01:45:05.786085: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 01:45:06.334333: lr: 0.009277\n",
      "2021-11-28 01:45:06.341506: This epoch took 311.261024 s\n",
      "\n",
      "2021-11-28 01:45:06.348156: \n",
      "epoch:  4\n",
      "2021-11-28 01:49:56.005390: train loss : 0.2241\n",
      "2021-11-28 01:50:17.338642: validation loss: 0.2351\n",
      "2021-11-28 01:50:17.346729: Average global foreground Dice: [0.0055]\n",
      "2021-11-28 01:50:17.353718: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 01:50:17.875872: lr: 0.009095\n",
      "2021-11-28 01:50:17.916442: saving checkpoint...\n",
      "2021-11-28 01:50:18.492527: done, saving took 0.61 seconds\n",
      "2021-11-28 01:50:18.517428: This epoch took 312.162616 s\n",
      "\n",
      "2021-11-28 01:50:18.524273: \n",
      "epoch:  5\n",
      "2021-11-28 01:55:08.233726: train loss : 0.2167\n",
      "2021-11-28 01:55:29.540889: validation loss: 0.2109\n",
      "2021-11-28 01:55:29.547956: Average global foreground Dice: [0.0047]\n",
      "2021-11-28 01:55:29.555104: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 01:55:30.071034: lr: 0.008913\n",
      "2021-11-28 01:55:30.106626: saving checkpoint...\n",
      "2021-11-28 01:55:30.646905: done, saving took 0.57 seconds\n",
      "2021-11-28 01:55:30.673878: This epoch took 312.142251 s\n",
      "\n",
      "2021-11-28 01:55:30.681129: \n",
      "epoch:  6\n",
      "2021-11-28 02:00:20.257231: train loss : 0.2137\n",
      "2021-11-28 02:00:41.587873: validation loss: 0.2117\n",
      "2021-11-28 02:00:41.594789: Average global foreground Dice: [0.0205]\n",
      "2021-11-28 02:00:41.602209: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 02:00:42.125364: lr: 0.008731\n",
      "2021-11-28 02:00:42.158345: saving checkpoint...\n",
      "2021-11-28 02:00:42.678530: done, saving took 0.55 seconds\n",
      "2021-11-28 02:00:42.702477: This epoch took 312.014557 s\n",
      "\n",
      "2021-11-28 02:00:42.709031: \n",
      "epoch:  7\n",
      "2021-11-28 02:05:32.879152: train loss : 0.1936\n",
      "2021-11-28 02:05:54.184376: validation loss: 0.1825\n",
      "2021-11-28 02:05:54.191502: Average global foreground Dice: [0.0138]\n",
      "2021-11-28 02:05:54.198600: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 02:05:54.732713: lr: 0.008548\n",
      "2021-11-28 02:05:54.765509: saving checkpoint...\n",
      "2021-11-28 02:05:55.297238: done, saving took 0.56 seconds\n",
      "2021-11-28 02:05:55.321591: This epoch took 312.606372 s\n",
      "\n",
      "2021-11-28 02:05:55.328234: \n",
      "epoch:  8\n",
      "2021-11-28 02:10:44.713797: train loss : 0.2096\n",
      "2021-11-28 02:11:06.021933: validation loss: 0.2212\n",
      "2021-11-28 02:11:06.029491: Average global foreground Dice: [0.0823]\n",
      "2021-11-28 02:11:06.035875: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 02:11:06.603988: lr: 0.008364\n",
      "2021-11-28 02:11:06.626734: saving checkpoint...\n",
      "2021-11-28 02:11:07.147213: done, saving took 0.54 seconds\n",
      "2021-11-28 02:11:07.171499: This epoch took 311.836734 s\n",
      "\n",
      "2021-11-28 02:11:07.178338: \n",
      "epoch:  9\n",
      "2021-11-28 02:15:56.731390: train loss : 0.1981\n",
      "2021-11-28 02:16:18.077929: validation loss: 0.1833\n",
      "2021-11-28 02:16:18.085485: Average global foreground Dice: [0.067]\n",
      "2021-11-28 02:16:18.092031: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 02:16:18.621051: lr: 0.008181\n",
      "2021-11-28 02:16:18.643225: saving checkpoint...\n",
      "2021-11-28 02:16:19.656848: done, saving took 1.03 seconds\n",
      "2021-11-28 02:16:19.680889: This epoch took 312.496021 s\n",
      "\n",
      "2021-11-28 02:16:19.687351: \n",
      "epoch:  10\n",
      "2021-11-28 02:21:09.534589: train loss : 0.1955\n",
      "2021-11-28 02:21:30.839498: validation loss: 0.1924\n",
      "2021-11-28 02:21:30.847043: Average global foreground Dice: [0.0285]\n",
      "2021-11-28 02:21:30.853517: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 02:21:31.359529: lr: 0.007996\n",
      "2021-11-28 02:21:31.381379: saving checkpoint...\n",
      "2021-11-28 02:21:31.971008: done, saving took 0.61 seconds\n",
      "2021-11-28 02:21:31.994722: This epoch took 312.300426 s\n",
      "\n",
      "2021-11-28 02:21:32.002046: \n",
      "epoch:  11\n",
      "2021-11-28 02:26:21.679580: train loss : 0.1866\n",
      "2021-11-28 02:26:42.999168: validation loss: 0.2103\n",
      "2021-11-28 02:26:43.006163: Average global foreground Dice: [0.1516]\n",
      "2021-11-28 02:26:43.012643: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 02:26:43.517899: lr: 0.007811\n",
      "2021-11-28 02:26:43.539702: saving checkpoint...\n",
      "2021-11-28 02:26:44.082722: done, saving took 0.56 seconds\n",
      "2021-11-28 02:26:44.106779: This epoch took 312.098147 s\n",
      "\n",
      "2021-11-28 02:26:44.112997: \n",
      "epoch:  12\n",
      "2021-11-28 02:31:33.486044: train loss : 0.1877\n",
      "2021-11-28 02:31:54.802210: validation loss: 0.2122\n",
      "2021-11-28 02:31:54.809919: Average global foreground Dice: [0.0325]\n",
      "2021-11-28 02:31:54.816388: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 02:31:55.324185: lr: 0.007626\n",
      "2021-11-28 02:31:55.346449: saving checkpoint...\n",
      "2021-11-28 02:31:55.917765: done, saving took 0.59 seconds\n",
      "2021-11-28 02:31:55.941538: This epoch took 311.821718 s\n",
      "\n",
      "2021-11-28 02:31:55.947933: \n",
      "epoch:  13\n",
      "2021-11-28 02:36:45.350268: train loss : 0.1844\n",
      "2021-11-28 02:37:06.656386: validation loss: 0.2039\n",
      "2021-11-28 02:37:06.663364: Average global foreground Dice: [0.1036]\n",
      "2021-11-28 02:37:06.669348: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 02:37:07.182450: lr: 0.00744\n",
      "2021-11-28 02:37:07.206056: saving checkpoint...\n",
      "2021-11-28 02:37:07.755004: done, saving took 0.57 seconds\n",
      "2021-11-28 02:37:07.779972: This epoch took 311.825646 s\n",
      "\n",
      "2021-11-28 02:37:07.786216: \n",
      "epoch:  14\n",
      "2021-11-28 02:41:58.004413: train loss : 0.1864\n",
      "2021-11-28 02:42:19.732572: validation loss: 0.1875\n",
      "2021-11-28 02:42:19.739748: Average global foreground Dice: [0.146]\n",
      "2021-11-28 02:42:19.747547: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 02:42:20.286588: lr: 0.007254\n",
      "2021-11-28 02:42:20.315660: saving checkpoint...\n",
      "2021-11-28 02:42:20.904937: done, saving took 0.61 seconds\n",
      "2021-11-28 02:42:20.934980: This epoch took 313.141722 s\n",
      "\n",
      "2021-11-28 02:42:20.941810: \n",
      "epoch:  15\n",
      "2021-11-28 02:47:10.534199: train loss : 0.1745\n",
      "2021-11-28 02:47:32.049900: validation loss: 0.1725\n",
      "2021-11-28 02:47:32.057029: Average global foreground Dice: [0.075]\n",
      "2021-11-28 02:47:32.063853: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 02:47:32.575274: lr: 0.007067\n",
      "2021-11-28 02:47:32.597901: saving checkpoint...\n",
      "2021-11-28 02:47:33.113244: done, saving took 0.53 seconds\n",
      "2021-11-28 02:47:33.137465: This epoch took 312.188238 s\n",
      "\n",
      "2021-11-28 02:47:33.143831: \n",
      "epoch:  16\n",
      "2021-11-28 02:52:23.469570: train loss : 0.1794\n",
      "2021-11-28 02:52:45.050732: validation loss: 0.1771\n",
      "2021-11-28 02:52:45.058694: Average global foreground Dice: [0.2233]\n",
      "2021-11-28 02:52:45.065665: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 02:52:45.571866: lr: 0.00688\n",
      "2021-11-28 02:52:45.594084: saving checkpoint...\n",
      "2021-11-28 02:52:46.123631: done, saving took 0.55 seconds\n",
      "2021-11-28 02:52:46.147370: This epoch took 312.996733 s\n",
      "\n",
      "2021-11-28 02:52:46.154112: \n",
      "epoch:  17\n",
      "2021-11-28 02:57:35.795710: train loss : 0.1714\n",
      "2021-11-28 02:57:57.474576: validation loss: 0.2118\n",
      "2021-11-28 02:57:57.482226: Average global foreground Dice: [0.1247]\n",
      "2021-11-28 02:57:57.489176: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 02:57:58.014738: lr: 0.006692\n",
      "2021-11-28 02:57:58.037550: saving checkpoint...\n",
      "2021-11-28 02:57:58.583060: done, saving took 0.56 seconds\n",
      "2021-11-28 02:57:58.615942: This epoch took 312.455263 s\n",
      "\n",
      "2021-11-28 02:57:58.623370: \n",
      "epoch:  18\n",
      "/tf/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-11-28 03:02:47.985394: train loss : 0.1711\n",
      "2021-11-28 03:03:09.850052: validation loss: 0.1730\n",
      "2021-11-28 03:03:09.857770: Average global foreground Dice: [0.2141]\n",
      "2021-11-28 03:03:09.865006: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 03:03:10.381778: lr: 0.006504\n",
      "2021-11-28 03:03:10.405060: saving checkpoint...\n",
      "2021-11-28 03:03:10.943984: done, saving took 0.55 seconds\n",
      "2021-11-28 03:03:10.968680: This epoch took 312.338197 s\n",
      "\n",
      "2021-11-28 03:03:10.976089: \n",
      "epoch:  19\n",
      "2021-11-28 03:08:00.670936: train loss : 0.1690\n",
      "2021-11-28 03:08:22.499468: validation loss: 0.1952\n",
      "2021-11-28 03:08:22.508348: Average global foreground Dice: [0.0241]\n",
      "2021-11-28 03:08:22.515889: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 03:08:23.034408: lr: 0.006314\n",
      "2021-11-28 03:08:23.041809: This epoch took 312.059091 s\n",
      "\n",
      "2021-11-28 03:08:23.049481: \n",
      "epoch:  20\n",
      "2021-11-28 03:13:13.121490: train loss : 0.1851\n",
      "2021-11-28 03:13:35.028049: validation loss: 0.1822\n",
      "2021-11-28 03:13:35.036178: Average global foreground Dice: [0.1308]\n",
      "2021-11-28 03:13:35.043492: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 03:13:35.572069: lr: 0.006125\n",
      "2021-11-28 03:13:35.579534: This epoch took 312.523324 s\n",
      "\n",
      "2021-11-28 03:13:35.588909: \n",
      "epoch:  21\n",
      "2021-11-28 03:18:26.636139: train loss : 0.1710\n",
      "2021-11-28 03:18:49.061377: validation loss: 0.1439\n",
      "2021-11-28 03:18:49.069112: Average global foreground Dice: [0.2392]\n",
      "2021-11-28 03:18:49.075535: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 03:18:49.594464: lr: 0.005934\n",
      "2021-11-28 03:18:49.617380: saving checkpoint...\n",
      "2021-11-28 03:18:50.181657: done, saving took 0.58 seconds\n",
      "2021-11-28 03:18:50.206524: This epoch took 314.610724 s\n",
      "\n",
      "2021-11-28 03:18:50.214964: \n",
      "epoch:  22\n",
      "2021-11-28 03:23:55.640312: train loss : 0.1615\n",
      "2021-11-28 03:24:16.946322: validation loss: 0.1906\n",
      "2021-11-28 03:24:16.954169: Average global foreground Dice: [0.1332]\n",
      "2021-11-28 03:24:16.961158: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 03:24:17.488626: lr: 0.005743\n",
      "2021-11-28 03:24:17.511061: saving checkpoint...\n",
      "2021-11-28 03:24:18.075815: done, saving took 0.58 seconds\n",
      "2021-11-28 03:24:18.100740: This epoch took 327.879166 s\n",
      "\n",
      "2021-11-28 03:24:18.108235: \n",
      "epoch:  23\n",
      "2021-11-28 03:29:07.482166: train loss : 0.1565\n",
      "2021-11-28 03:29:28.816483: validation loss: 0.1346\n",
      "2021-11-28 03:29:28.824579: Average global foreground Dice: [0.2755]\n",
      "2021-11-28 03:29:28.831954: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 03:29:29.346531: lr: 0.005551\n",
      "2021-11-28 03:29:29.371074: saving checkpoint...\n",
      "2021-11-28 03:29:29.945046: done, saving took 0.59 seconds\n",
      "2021-11-28 03:29:29.971251: This epoch took 311.854764 s\n",
      "\n",
      "2021-11-28 03:29:29.978397: \n",
      "epoch:  24\n",
      "2021-11-28 03:34:21.223096: train loss : 0.1620\n",
      "2021-11-28 03:34:42.525271: validation loss: 0.1254\n",
      "2021-11-28 03:34:42.533237: Average global foreground Dice: [0.2501]\n",
      "2021-11-28 03:34:42.540720: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 03:34:43.081347: lr: 0.005359\n",
      "2021-11-28 03:34:43.104946: saving checkpoint...\n",
      "2021-11-28 03:34:43.642113: done, saving took 0.55 seconds\n",
      "2021-11-28 03:34:43.667767: This epoch took 313.682117 s\n",
      "\n",
      "2021-11-28 03:34:43.674811: \n",
      "epoch:  25\n",
      "2021-11-28 03:39:33.584074: train loss : 0.1331\n",
      "2021-11-28 03:39:54.908290: validation loss: 0.1929\n",
      "2021-11-28 03:39:54.916270: Average global foreground Dice: [0.2617]\n",
      "2021-11-28 03:39:54.922994: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 03:39:55.446141: lr: 0.005166\n",
      "2021-11-28 03:39:55.470647: saving checkpoint...\n",
      "2021-11-28 03:39:56.004213: done, saving took 0.55 seconds\n",
      "2021-11-28 03:39:56.029647: This epoch took 312.347481 s\n",
      "\n",
      "2021-11-28 03:39:56.037750: \n",
      "epoch:  26\n",
      "2021-11-28 03:44:47.463717: train loss : 0.1619\n",
      "2021-11-28 03:45:08.811091: validation loss: 0.1092\n",
      "2021-11-28 03:45:08.818295: Average global foreground Dice: [0.2881]\n",
      "2021-11-28 03:45:08.825392: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 03:45:09.367430: lr: 0.004971\n",
      "2021-11-28 03:45:09.402494: saving checkpoint...\n",
      "2021-11-28 03:45:09.954386: done, saving took 0.58 seconds\n",
      "2021-11-28 03:45:09.978385: This epoch took 313.932913 s\n",
      "\n",
      "2021-11-28 03:45:09.984904: \n",
      "epoch:  27\n",
      "2021-11-28 03:50:01.111788: train loss : 0.1420\n",
      "2021-11-28 03:50:22.415077: validation loss: 0.1256\n",
      "2021-11-28 03:50:22.422485: Average global foreground Dice: [0.2869]\n",
      "2021-11-28 03:50:22.429092: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 03:50:22.953235: lr: 0.004776\n",
      "2021-11-28 03:50:22.981093: saving checkpoint...\n",
      "2021-11-28 03:50:23.591465: done, saving took 0.63 seconds\n",
      "2021-11-28 03:50:23.616507: This epoch took 313.624508 s\n",
      "\n",
      "2021-11-28 03:50:23.624144: \n",
      "epoch:  28\n",
      "2021-11-28 03:55:14.314589: train loss : 0.1406\n",
      "2021-11-28 03:55:35.653409: validation loss: 0.1436\n",
      "2021-11-28 03:55:35.660805: Average global foreground Dice: [0.2543]\n",
      "2021-11-28 03:55:35.667827: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 03:55:36.199956: lr: 0.004581\n",
      "2021-11-28 03:55:36.223037: saving checkpoint...\n",
      "2021-11-28 03:55:36.741735: done, saving took 0.53 seconds\n",
      "2021-11-28 03:55:36.766331: This epoch took 313.134863 s\n",
      "\n",
      "2021-11-28 03:55:36.773680: \n",
      "epoch:  29\n",
      "2021-11-28 04:00:26.842176: train loss : 0.1320\n",
      "2021-11-28 04:00:48.149709: validation loss: 0.1388\n",
      "2021-11-28 04:00:48.158047: Average global foreground Dice: [0.2179]\n",
      "2021-11-28 04:00:48.165938: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 04:00:48.690944: lr: 0.004384\n",
      "2021-11-28 04:00:48.714308: saving checkpoint...\n",
      "2021-11-28 04:00:49.219562: done, saving took 0.52 seconds\n",
      "2021-11-28 04:00:49.244147: This epoch took 312.462574 s\n",
      "\n",
      "2021-11-28 04:00:49.252203: \n",
      "epoch:  30\n",
      "2021-11-28 04:05:39.350514: train loss : 0.1511\n",
      "2021-11-28 04:06:00.650985: validation loss: 0.1334\n",
      "2021-11-28 04:06:00.658932: Average global foreground Dice: [0.2702]\n",
      "2021-11-28 04:06:00.666669: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 04:06:01.197287: lr: 0.004186\n",
      "2021-11-28 04:06:01.220753: saving checkpoint...\n",
      "2021-11-28 04:06:01.750239: done, saving took 0.55 seconds\n",
      "2021-11-28 04:06:01.776212: This epoch took 312.516907 s\n",
      "\n",
      "2021-11-28 04:06:01.782929: \n",
      "epoch:  31\n",
      "2021-11-28 04:10:51.756779: train loss : 0.1334\n",
      "2021-11-28 04:11:13.093428: validation loss: 0.1030\n",
      "2021-11-28 04:11:13.102240: Average global foreground Dice: [0.2605]\n",
      "2021-11-28 04:11:13.109388: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 04:11:13.639205: lr: 0.003987\n",
      "2021-11-28 04:11:13.661794: saving checkpoint...\n",
      "2021-11-28 04:11:14.243301: done, saving took 0.60 seconds\n",
      "2021-11-28 04:11:14.272229: This epoch took 312.479944 s\n",
      "\n",
      "2021-11-28 04:11:14.279063: \n",
      "epoch:  32\n",
      "2021-11-28 04:16:04.831658: train loss : 0.1237\n",
      "2021-11-28 04:16:26.139021: validation loss: 0.1455\n",
      "2021-11-28 04:16:26.148204: Average global foreground Dice: [0.2777]\n",
      "2021-11-28 04:16:26.154563: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 04:16:26.683766: lr: 0.003787\n",
      "2021-11-28 04:16:26.706699: saving checkpoint...\n",
      "2021-11-28 04:16:27.225265: done, saving took 0.53 seconds\n",
      "2021-11-28 04:16:27.251442: This epoch took 312.965403 s\n",
      "\n",
      "2021-11-28 04:16:27.258777: \n",
      "epoch:  33\n",
      "2021-11-28 04:21:17.580391: train loss : 0.1289\n",
      "2021-11-28 04:21:38.908238: validation loss: 0.1523\n",
      "2021-11-28 04:21:38.916156: Average global foreground Dice: [0.2859]\n",
      "2021-11-28 04:21:38.922702: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 04:21:39.455177: lr: 0.003586\n",
      "2021-11-28 04:21:39.477748: saving checkpoint...\n",
      "2021-11-28 04:21:40.077017: done, saving took 0.62 seconds\n",
      "2021-11-28 04:21:40.108673: This epoch took 312.842688 s\n",
      "\n",
      "2021-11-28 04:21:40.116264: \n",
      "epoch:  34\n",
      "2021-11-28 04:26:30.265955: train loss : 0.1205\n",
      "2021-11-28 04:26:51.579100: validation loss: 0.1313\n",
      "2021-11-28 04:26:51.586510: Average global foreground Dice: [0.2306]\n",
      "2021-11-28 04:26:51.593987: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 04:26:52.143781: lr: 0.003384\n",
      "2021-11-28 04:26:52.167744: saving checkpoint...\n",
      "2021-11-28 04:26:52.773158: done, saving took 0.62 seconds\n",
      "2021-11-28 04:26:52.798821: This epoch took 312.675655 s\n",
      "\n",
      "2021-11-28 04:26:52.805925: \n",
      "epoch:  35\n",
      "2021-11-28 04:31:43.560478: train loss : 0.1196\n",
      "2021-11-28 04:32:04.907015: validation loss: 0.1065\n",
      "2021-11-28 04:32:04.915346: Average global foreground Dice: [0.3292]\n",
      "2021-11-28 04:32:04.922462: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 04:32:05.458785: lr: 0.00318\n",
      "2021-11-28 04:32:05.482235: saving checkpoint...\n",
      "2021-11-28 04:32:06.005300: done, saving took 0.54 seconds\n",
      "2021-11-28 04:32:06.030064: This epoch took 313.216906 s\n",
      "\n",
      "2021-11-28 04:32:06.036730: \n",
      "epoch:  36\n",
      "2021-11-28 04:36:57.100158: train loss : 0.1069\n",
      "2021-11-28 04:37:18.495502: validation loss: 0.1130\n",
      "2021-11-28 04:37:18.503618: Average global foreground Dice: [0.3026]\n",
      "2021-11-28 04:37:18.511192: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 04:37:19.055618: lr: 0.002975\n",
      "2021-11-28 04:37:19.078551: saving checkpoint...\n",
      "2021-11-28 04:37:19.678375: done, saving took 0.62 seconds\n",
      "2021-11-28 04:37:19.703881: This epoch took 313.660201 s\n",
      "\n",
      "2021-11-28 04:37:19.711612: \n",
      "epoch:  37\n",
      "2021-11-28 04:42:10.085220: train loss : 0.1239\n",
      "2021-11-28 04:42:31.593081: validation loss: 0.1148\n",
      "2021-11-28 04:42:31.600382: Average global foreground Dice: [0.3109]\n",
      "2021-11-28 04:42:31.607675: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 04:42:32.163105: lr: 0.002768\n",
      "2021-11-28 04:42:32.185818: saving checkpoint...\n",
      "2021-11-28 04:42:32.836607: done, saving took 0.67 seconds\n",
      "2021-11-28 04:42:32.861770: This epoch took 313.142943 s\n",
      "\n",
      "2021-11-28 04:42:32.868608: \n",
      "epoch:  38\n",
      "2021-11-28 04:47:24.182572: train loss : 0.1161\n",
      "2021-11-28 04:47:46.167481: validation loss: 0.1168\n",
      "2021-11-28 04:47:46.175700: Average global foreground Dice: [0.3292]\n",
      "2021-11-28 04:47:46.182697: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 04:47:46.765010: lr: 0.00256\n",
      "2021-11-28 04:47:46.790057: saving checkpoint...\n",
      "2021-11-28 04:47:47.416960: done, saving took 0.64 seconds\n",
      "2021-11-28 04:47:47.447199: This epoch took 314.570680 s\n",
      "\n",
      "2021-11-28 04:47:47.454227: \n",
      "epoch:  39\n",
      "2021-11-28 04:52:38.819761: train loss : 0.1051\n",
      "2021-11-28 04:53:00.886659: validation loss: 0.0853\n",
      "2021-11-28 04:53:00.894292: Average global foreground Dice: [0.3428]\n",
      "2021-11-28 04:53:00.901358: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 04:53:01.454153: lr: 0.002349\n",
      "2021-11-28 04:53:01.489353: saving checkpoint...\n",
      "2021-11-28 04:53:02.122530: done, saving took 0.66 seconds\n",
      "2021-11-28 04:53:02.150028: This epoch took 314.688812 s\n",
      "\n",
      "2021-11-28 04:53:02.157069: \n",
      "epoch:  40\n",
      "2021-11-28 04:57:52.206543: train loss : 0.0939\n",
      "2021-11-28 04:58:14.062843: validation loss: 0.0988\n",
      "2021-11-28 04:58:14.070842: Average global foreground Dice: [0.291]\n",
      "2021-11-28 04:58:14.078154: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 04:58:14.604094: lr: 0.002137\n",
      "2021-11-28 04:58:14.627705: saving checkpoint...\n",
      "2021-11-28 04:58:15.159771: done, saving took 0.55 seconds\n",
      "2021-11-28 04:58:15.185751: This epoch took 313.021136 s\n",
      "\n",
      "2021-11-28 04:58:15.193798: \n",
      "epoch:  41\n",
      "2021-11-28 05:03:22.903070: train loss : 0.0953\n",
      "2021-11-28 05:03:44.551244: validation loss: 0.1107\n",
      "2021-11-28 05:03:44.558833: Average global foreground Dice: [0.3582]\n",
      "2021-11-28 05:03:44.565985: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 05:03:45.106079: lr: 0.001922\n",
      "2021-11-28 05:03:45.129133: saving checkpoint...\n",
      "2021-11-28 05:03:45.652662: done, saving took 0.54 seconds\n",
      "2021-11-28 05:03:45.678482: This epoch took 330.476996 s\n",
      "\n",
      "2021-11-28 05:03:45.685577: \n",
      "epoch:  42\n",
      "2021-11-28 05:08:36.864964: train loss : 0.1074\n",
      "2021-11-28 05:08:58.194825: validation loss: 0.0542\n",
      "2021-11-28 05:08:58.203550: Average global foreground Dice: [0.3551]\n",
      "2021-11-28 05:08:58.212034: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 05:08:58.729774: lr: 0.001704\n",
      "2021-11-28 05:08:58.752150: saving checkpoint...\n",
      "2021-11-28 05:08:59.283205: done, saving took 0.55 seconds\n",
      "2021-11-28 05:08:59.306369: This epoch took 313.613321 s\n",
      "\n",
      "2021-11-28 05:08:59.313282: \n",
      "epoch:  43\n",
      "2021-11-28 05:13:51.776989: train loss : 0.0949\n",
      "2021-11-28 05:14:14.213981: validation loss: 0.0628\n",
      "2021-11-28 05:14:14.221469: Average global foreground Dice: [0.3755]\n",
      "2021-11-28 05:14:14.228373: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 05:14:14.749631: lr: 0.001483\n",
      "2021-11-28 05:14:14.772769: saving checkpoint...\n",
      "2021-11-28 05:14:15.396339: done, saving took 0.64 seconds\n",
      "2021-11-28 05:14:15.422400: This epoch took 316.101908 s\n",
      "\n",
      "2021-11-28 05:14:15.429723: \n",
      "epoch:  44\n",
      "2021-11-28 05:19:22.426311: train loss : 0.0912\n",
      "2021-11-28 05:19:43.874635: validation loss: 0.0867\n",
      "2021-11-28 05:19:43.882348: Average global foreground Dice: [0.3358]\n",
      "2021-11-28 05:19:43.889390: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 05:19:44.410222: lr: 0.001259\n",
      "2021-11-28 05:19:44.433136: saving checkpoint...\n",
      "2021-11-28 05:19:44.950534: done, saving took 0.53 seconds\n",
      "2021-11-28 05:19:44.975702: This epoch took 329.539011 s\n",
      "\n",
      "2021-11-28 05:19:44.983067: \n",
      "epoch:  45\n",
      "2021-11-28 05:24:36.639907: train loss : 0.0701\n",
      "2021-11-28 05:24:57.928032: validation loss: 0.0712\n",
      "2021-11-28 05:24:57.936528: Average global foreground Dice: [0.3958]\n",
      "2021-11-28 05:24:57.943912: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 05:24:58.469757: lr: 0.00103\n",
      "2021-11-28 05:24:58.492824: saving checkpoint...\n",
      "2021-11-28 05:24:59.049338: done, saving took 0.57 seconds\n",
      "2021-11-28 05:24:59.074129: This epoch took 314.083690 s\n",
      "\n",
      "2021-11-28 05:24:59.081515: \n",
      "epoch:  46\n",
      "2021-11-28 05:29:50.950385: train loss : 0.0895\n",
      "2021-11-28 05:30:12.296746: validation loss: 0.0946\n",
      "2021-11-28 05:30:12.304475: Average global foreground Dice: [0.3308]\n",
      "2021-11-28 05:30:12.311558: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 05:30:12.864240: lr: 0.000795\n",
      "2021-11-28 05:30:12.892518: saving checkpoint...\n",
      "2021-11-28 05:30:13.559635: done, saving took 0.69 seconds\n",
      "2021-11-28 05:30:13.590650: This epoch took 314.502357 s\n",
      "\n",
      "2021-11-28 05:30:13.597207: \n",
      "epoch:  47\n",
      "2021-11-28 05:35:05.029421: train loss : 0.0715\n",
      "2021-11-28 05:35:26.330730: validation loss: 0.0246\n",
      "2021-11-28 05:35:26.340541: Average global foreground Dice: [0.389]\n",
      "2021-11-28 05:35:26.348420: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 05:35:26.867080: lr: 0.000552\n",
      "2021-11-28 05:35:26.890471: saving checkpoint...\n",
      "2021-11-28 05:35:27.414902: done, saving took 0.54 seconds\n",
      "2021-11-28 05:35:27.440213: This epoch took 313.836037 s\n",
      "\n",
      "2021-11-28 05:35:27.448607: \n",
      "epoch:  48\n",
      "2021-11-28 05:40:18.193746: train loss : 0.0582\n",
      "2021-11-28 05:40:39.487626: validation loss: 0.0696\n",
      "2021-11-28 05:40:39.496692: Average global foreground Dice: [0.3649]\n",
      "2021-11-28 05:40:39.504304: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 05:40:40.040395: lr: 0.000296\n",
      "2021-11-28 05:40:40.062917: saving checkpoint...\n",
      "2021-11-28 05:40:40.658816: done, saving took 0.61 seconds\n",
      "2021-11-28 05:40:40.683537: This epoch took 313.228500 s\n",
      "\n",
      "2021-11-28 05:40:40.693676: \n",
      "epoch:  49\n",
      "2021-11-28 05:45:32.241792: train loss : 0.0853\n",
      "2021-11-28 05:45:53.576819: validation loss: 0.0382\n",
      "2021-11-28 05:45:53.584341: Average global foreground Dice: [0.3923]\n",
      "2021-11-28 05:45:53.591327: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-28 05:45:54.113549: lr: 0.0\n",
      "2021-11-28 05:45:54.122857: saving scheduled checkpoint file...\n",
      "2021-11-28 05:45:54.145931: saving checkpoint...\n",
      "2021-11-28 05:45:54.624405: done, saving took 0.49 seconds\n",
      "2021-11-28 05:45:54.643874: done\n",
      "2021-11-28 05:45:54.667288: saving checkpoint...\n",
      "2021-11-28 05:45:55.197786: done, saving took 0.55 seconds\n",
      "2021-11-28 05:45:55.222927: This epoch took 314.521402 s\n",
      "\n",
      "2021-11-28 05:45:55.246633: saving checkpoint...\n",
      "2021-11-28 05:45:55.705219: done, saving took 0.47 seconds\n",
      "GGHB_DC68_LJH0_BABA_0002 (2, 57, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 57, 512, 512)\n",
      "patch size: [ 40 256 240]\n",
      "steps (x, y, and z): [[0, 17], [0, 128, 256], [0, 91, 181, 272]]\n",
      "number of tiles: 24\n",
      "computing Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "GGHB_DC68_LJH0_BABA_0003 (2, 149, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 149, 512, 512)\n",
      "patch size: [ 40 256 240]\n",
      "steps (x, y, and z): [[0, 18, 36, 54, 73, 91, 109], [0, 128, 256], [0, 91, 181, 272]]\n",
      "number of tiles: 84\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RALP_0000 (2, 96, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 96, 512, 512)\n",
      "patch size: [ 40 256 240]\n",
      "steps (x, y, and z): [[0, 19, 37, 56], [0, 128, 256], [0, 91, 181, 272]]\n",
      "number of tiles: 48\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RALP_0001 (2, 145, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 145, 512, 512)\n",
      "patch size: [ 40 256 240]\n",
      "steps (x, y, and z): [[0, 18, 35, 52, 70, 88, 105], [0, 128, 256], [0, 91, 181, 272]]\n",
      "number of tiles: 84\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "SNUH_DC07_JCW0_RALP_0002 (2, 83, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 83, 512, 512)\n",
      "patch size: [ 40 256 240]\n",
      "steps (x, y, and z): [[0, 14, 29, 43], [0, 128, 256], [0, 91, 181, 272]]\n",
      "number of tiles: 48\n",
      "using precomputed Gaussian\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RALP_0011 (2, 111, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 111, 512, 512)\n",
      "patch size: [ 40 256 240]\n",
      "steps (x, y, and z): [[0, 18, 36, 53, 71], [0, 128, 256], [0, 91, 181, 272]]\n",
      "number of tiles: 60\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RALP_0020 (2, 213, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 213, 512, 512)\n",
      "patch size: [ 40 256 240]\n",
      "steps (x, y, and z): [[0, 19, 38, 58, 77, 96, 115, 135, 154, 173], [0, 128, 256], [0, 91, 181, 272]]\n",
      "number of tiles: 120\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "SNUH_DC07_JCW0_RALP_0021 (2, 67, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 67, 512, 512)\n",
      "patch size: [ 40 256 240]\n",
      "steps (x, y, and z): [[0, 14, 27], [0, 128, 256], [0, 91, 181, 272]]\n",
      "number of tiles: 36\n",
      "using precomputed Gaussian\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RALP_0031 (2, 150, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 150, 512, 512)\n",
      "patch size: [ 40 256 240]\n",
      "steps (x, y, and z): [[0, 18, 37, 55, 73, 92, 110], [0, 128, 256], [0, 91, 181, 272]]\n",
      "number of tiles: 84\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "SNUH_DC07_JCW0_RLPN_0002 (2, 90, 512, 512)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 90, 512, 512)\n",
      "patch size: [ 40 256 240]\n",
      "steps (x, y, and z): [[0, 17, 33, 50], [0, 128, 256], [0, 91, 181, 272]]\n",
      "number of tiles: 48\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RLPN_0003 (2, 123, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 123, 512, 512)\n",
      "patch size: [ 40 256 240]\n",
      "steps (x, y, and z): [[0, 17, 33, 50, 66, 83], [0, 128, 256], [0, 91, 181, 272]]\n",
      "number of tiles: 72\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RLPN_0008 (2, 86, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 86, 512, 512)\n",
      "patch size: [ 40 256 240]\n",
      "steps (x, y, and z): [[0, 15, 31, 46], [0, 128, 256], [0, 91, 181, 272]]\n",
      "number of tiles: 48\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "SNUH_DC07_JCW0_RLPN_0009 (2, 42, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 42, 512, 512)\n",
      "patch size: [ 40 256 240]\n",
      "steps (x, y, and z): [[0, 2], [0, 128, 256], [0, 91, 181, 272]]\n",
      "number of tiles: 24\n",
      "using precomputed Gaussian\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RLPN_0014 (2, 38, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 40, 512, 512)\n",
      "patch size: [ 40 256 240]\n",
      "steps (x, y, and z): [[0], [0, 128, 256], [0, 91, 181, 272]]\n",
      "number of tiles: 12\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC68_KSJ0_BABA_0001 (2, 38, 343, 502)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 40, 343, 502)\n",
      "patch size: [ 40 256 240]\n",
      "steps (x, y, and z): [[0], [0, 87], [0, 87, 175, 262]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC68_LKE0_BABA_0001 (2, 38, 342, 495)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 40, 342, 495)\n",
      "patch size: [ 40 256 240]\n",
      "steps (x, y, and z): [[0], [0, 86], [0, 85, 170, 255]]\n",
      "number of tiles: 8\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC68_LKE0_BABA_0002 (2, 96, 342, 488)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 96, 342, 488)\n",
      "patch size: [ 40 256 240]\n",
      "steps (x, y, and z): [[0, 19, 37, 56], [0, 86], [0, 83, 165, 248]]\n",
      "number of tiles: 32\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-28 06:07:30.014683: finished prediction\n",
      "2021-11-28 06:07:30.027983: evaluation of raw predictions\n",
      "2021-11-28 06:07:32.875173: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.24727816339091138\n",
      "after:  0.24903657464891343\n",
      "Removing all but the largest foreground region improved results!\n",
      "for_which_classes [1]\n",
      "min_valid_object_sizes None\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[[1]]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "!nnUNet_train 3d_fullres nnUNetTrainerV2 480 all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.loss_function.nnUNetTrainerV2_Loss_Dice.nnUNetTrainerV2_Loss_Dice'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'png'}\n",
      "use_mask_for_norm OrderedDict([(0, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 12, 'num_pool_per_axis': [7, 7], 'patch_size': array([512, 512]), 'median_patient_size_in_voxels': array([ 90, 512, 512]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /tf/temp/nnUNet/nnunet/preprocessed/Task480_GRSR/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-29 08:05:39.550918: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-29 08:05:45.932024: Unable to plot network architecture:\n",
      "2021-11-29 08:05:45.936962: No module named 'hiddenlayer'\n",
      "2021-11-29 08:05:45.942656: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-29 08:05:46.009026: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (1): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (2): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (3): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (4): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (5): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (6): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (4): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (5): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (6): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-29 08:05:46.019571: \n",
      "\n",
      "2021-11-29 08:05:46.025893: \n",
      "epoch:  0\n",
      "2021-11-29 08:09:00.493642: train loss : -0.1427\n",
      "2021-11-29 08:09:13.989003: validation loss: -0.1753\n",
      "2021-11-29 08:09:13.994690: Average global foreground Dice: [0.179]\n",
      "2021-11-29 08:09:13.999984: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 08:09:14.420053: lr: 0.00982\n",
      "2021-11-29 08:09:14.425086: This epoch took 208.393771 s\n",
      "\n",
      "2021-11-29 08:09:14.430207: \n",
      "epoch:  1\n",
      "2021-11-29 08:12:09.830275: train loss : -0.2154\n",
      "2021-11-29 08:12:23.516468: validation loss: -0.2547\n",
      "2021-11-29 08:12:23.521975: Average global foreground Dice: [0.2571]\n",
      "2021-11-29 08:12:23.528252: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 08:12:24.032240: lr: 0.009639\n",
      "2021-11-29 08:12:24.130402: saving checkpoint...\n",
      "2021-11-29 08:12:25.529063: done, saving took 1.49 seconds\n",
      "2021-11-29 08:12:25.555629: This epoch took 191.120707 s\n",
      "\n",
      "2021-11-29 08:12:25.561043: \n",
      "epoch:  2\n",
      "2021-11-29 08:15:27.414806: train loss : -0.2719\n",
      "2021-11-29 08:15:41.528474: validation loss: -0.3172\n",
      "2021-11-29 08:15:41.534554: Average global foreground Dice: [0.3191]\n",
      "2021-11-29 08:15:41.538817: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 08:15:42.167349: lr: 0.009458\n",
      "2021-11-29 08:15:42.228259: saving checkpoint...\n",
      "2021-11-29 08:15:43.831890: done, saving took 1.66 seconds\n",
      "2021-11-29 08:15:43.855217: This epoch took 198.289424 s\n",
      "\n",
      "2021-11-29 08:15:43.860908: \n",
      "epoch:  3\n",
      "2021-11-29 08:18:45.955136: train loss : -0.3133\n",
      "2021-11-29 08:18:59.554401: validation loss: -0.3672\n",
      "2021-11-29 08:18:59.559781: Average global foreground Dice: [0.3707]\n",
      "2021-11-29 08:18:59.567307: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 08:19:00.081870: lr: 0.009277\n",
      "2021-11-29 08:19:00.169598: saving checkpoint...\n",
      "2021-11-29 08:19:01.725146: done, saving took 1.64 seconds\n",
      "2021-11-29 08:19:01.748673: This epoch took 197.881994 s\n",
      "\n",
      "2021-11-29 08:19:01.753514: \n",
      "epoch:  4\n",
      "2021-11-29 08:21:57.504528: train loss : -0.3305\n",
      "2021-11-29 08:22:11.175342: validation loss: -0.3572\n",
      "2021-11-29 08:22:11.182056: Average global foreground Dice: [0.3611]\n",
      "2021-11-29 08:22:11.189308: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 08:22:11.686677: lr: 0.009095\n",
      "2021-11-29 08:22:11.763492: saving checkpoint...\n",
      "2021-11-29 08:22:13.184419: done, saving took 1.49 seconds\n",
      "2021-11-29 08:22:13.208835: This epoch took 191.450804 s\n",
      "\n",
      "2021-11-29 08:22:13.213321: \n",
      "epoch:  5\n",
      "2021-11-29 08:25:14.971883: train loss : -0.3505\n",
      "2021-11-29 08:25:29.163579: validation loss: -0.4036\n",
      "2021-11-29 08:25:29.170176: Average global foreground Dice: [0.407]\n",
      "2021-11-29 08:25:29.175419: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 08:25:29.675686: lr: 0.008913\n",
      "2021-11-29 08:25:29.754905: saving checkpoint...\n",
      "2021-11-29 08:25:31.455863: done, saving took 1.77 seconds\n",
      "2021-11-29 08:25:31.480557: This epoch took 198.262560 s\n",
      "\n",
      "2021-11-29 08:25:31.486472: \n",
      "epoch:  6\n",
      "2021-11-29 08:28:34.650951: train loss : -0.3533\n",
      "2021-11-29 08:28:48.282744: validation loss: -0.3894\n",
      "2021-11-29 08:28:48.289531: Average global foreground Dice: [0.3914]\n",
      "2021-11-29 08:28:48.295403: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 08:28:48.819851: lr: 0.008731\n",
      "2021-11-29 08:28:48.909495: saving checkpoint...\n",
      "2021-11-29 08:28:50.383987: done, saving took 1.56 seconds\n",
      "2021-11-29 08:28:50.408313: This epoch took 198.916435 s\n",
      "\n",
      "2021-11-29 08:28:50.413926: \n",
      "epoch:  7\n",
      "2021-11-29 08:31:45.610298: train loss : -0.3680\n",
      "2021-11-29 08:31:59.194397: validation loss: -0.4003\n",
      "2021-11-29 08:31:59.199971: Average global foreground Dice: [0.4035]\n",
      "2021-11-29 08:31:59.205398: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 08:31:59.702931: lr: 0.008548\n",
      "2021-11-29 08:31:59.792017: saving checkpoint...\n",
      "2021-11-29 08:32:02.407320: done, saving took 2.70 seconds\n",
      "2021-11-29 08:32:02.434301: This epoch took 192.015215 s\n",
      "\n",
      "2021-11-29 08:32:02.439631: \n",
      "epoch:  8\n",
      "2021-11-29 08:34:59.137644: train loss : -0.3771\n",
      "2021-11-29 08:35:12.663079: validation loss: -0.4382\n",
      "2021-11-29 08:35:12.668628: Average global foreground Dice: [0.4422]\n",
      "2021-11-29 08:35:12.674307: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 08:35:13.247939: lr: 0.008364\n",
      "2021-11-29 08:35:13.291176: saving checkpoint...\n",
      "2021-11-29 08:35:15.437932: done, saving took 2.18 seconds\n",
      "2021-11-29 08:35:15.460614: This epoch took 193.016016 s\n",
      "\n",
      "2021-11-29 08:35:15.466113: \n",
      "epoch:  9\n",
      "2021-11-29 08:38:12.486302: train loss : -0.3868\n",
      "2021-11-29 08:38:26.254321: validation loss: -0.4142\n",
      "2021-11-29 08:38:26.260049: Average global foreground Dice: [0.4181]\n",
      "2021-11-29 08:38:26.265782: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 08:38:26.772699: lr: 0.008181\n",
      "2021-11-29 08:38:26.822484: saving checkpoint...\n",
      "2021-11-29 08:38:28.336135: done, saving took 1.55 seconds\n",
      "2021-11-29 08:38:28.357361: This epoch took 192.886231 s\n",
      "\n",
      "2021-11-29 08:38:28.363802: \n",
      "epoch:  10\n",
      "2021-11-29 08:41:23.617646: train loss : -0.3875\n",
      "2021-11-29 08:41:37.189332: validation loss: -0.4207\n",
      "2021-11-29 08:41:37.194592: Average global foreground Dice: [0.4255]\n",
      "2021-11-29 08:41:37.200071: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 08:41:37.728199: lr: 0.007996\n",
      "2021-11-29 08:41:37.770897: saving checkpoint...\n",
      "2021-11-29 08:41:40.026380: done, saving took 2.29 seconds\n",
      "2021-11-29 08:41:40.047063: This epoch took 191.677823 s\n",
      "\n",
      "2021-11-29 08:41:40.053693: \n",
      "epoch:  11\n",
      "2021-11-29 08:44:40.273987: train loss : -0.3914\n",
      "2021-11-29 08:44:54.451697: validation loss: -0.4306\n",
      "2021-11-29 08:44:54.457786: Average global foreground Dice: [0.434]\n",
      "2021-11-29 08:44:54.462330: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 08:44:54.975088: lr: 0.007811\n",
      "2021-11-29 08:44:55.018348: saving checkpoint...\n",
      "2021-11-29 08:44:56.886040: done, saving took 1.91 seconds\n",
      "2021-11-29 08:44:56.907645: This epoch took 196.848925 s\n",
      "\n",
      "2021-11-29 08:44:56.912911: \n",
      "epoch:  12\n",
      "2021-11-29 08:48:00.931434: train loss : -0.4029\n",
      "2021-11-29 08:48:15.130708: validation loss: -0.4192\n",
      "2021-11-29 08:48:15.136095: Average global foreground Dice: [0.4238]\n",
      "2021-11-29 08:48:15.141068: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 08:48:15.653616: lr: 0.007626\n",
      "2021-11-29 08:48:15.696762: saving checkpoint...\n",
      "2021-11-29 08:48:17.829925: done, saving took 2.17 seconds\n",
      "2021-11-29 08:48:17.851142: This epoch took 200.932178 s\n",
      "\n",
      "2021-11-29 08:48:17.856610: \n",
      "epoch:  13\n",
      "2021-11-29 08:51:13.415128: train loss : -0.4045\n",
      "2021-11-29 08:51:26.940560: validation loss: -0.4227\n",
      "2021-11-29 08:51:26.946627: Average global foreground Dice: [0.4274]\n",
      "2021-11-29 08:51:26.952293: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 08:51:27.461329: lr: 0.00744\n",
      "2021-11-29 08:51:27.504571: saving checkpoint...\n",
      "2021-11-29 08:51:29.055928: done, saving took 1.59 seconds\n",
      "2021-11-29 08:51:29.081626: This epoch took 191.219542 s\n",
      "\n",
      "2021-11-29 08:51:29.086779: \n",
      "epoch:  14\n",
      "2021-11-29 08:54:28.960873: train loss : -0.3960\n",
      "2021-11-29 08:54:43.153784: validation loss: -0.4241\n",
      "2021-11-29 08:54:43.159362: Average global foreground Dice: [0.428]\n",
      "2021-11-29 08:54:43.170313: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 08:54:43.688634: lr: 0.007254\n",
      "2021-11-29 08:54:43.752261: saving checkpoint...\n",
      "2021-11-29 08:54:46.334191: done, saving took 2.64 seconds\n",
      "2021-11-29 08:54:46.366045: This epoch took 197.273997 s\n",
      "\n",
      "2021-11-29 08:54:46.371959: \n",
      "epoch:  15\n",
      "2021-11-29 08:57:49.637145: train loss : -0.4029\n",
      "2021-11-29 08:58:03.719030: validation loss: -0.4242\n",
      "2021-11-29 08:58:03.725214: Average global foreground Dice: [0.4277]\n",
      "2021-11-29 08:58:03.730852: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 08:58:04.244923: lr: 0.007067\n",
      "2021-11-29 08:58:04.291310: saving checkpoint...\n",
      "2021-11-29 08:58:07.916429: done, saving took 3.67 seconds\n",
      "2021-11-29 08:58:07.943829: This epoch took 201.566212 s\n",
      "\n",
      "2021-11-29 08:58:07.949196: \n",
      "epoch:  16\n",
      "2021-11-29 09:01:11.646306: train loss : -0.4193\n",
      "2021-11-29 09:01:25.839985: validation loss: -0.4419\n",
      "2021-11-29 09:01:25.846107: Average global foreground Dice: [0.4482]\n",
      "2021-11-29 09:01:25.851768: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 09:01:26.370649: lr: 0.00688\n",
      "2021-11-29 09:01:26.460236: saving checkpoint...\n",
      "2021-11-29 09:01:28.147140: done, saving took 1.77 seconds\n",
      "2021-11-29 09:01:28.173328: This epoch took 200.219003 s\n",
      "\n",
      "2021-11-29 09:01:28.179234: \n",
      "epoch:  17\n",
      "2021-11-29 09:04:28.877057: train loss : -0.4165\n",
      "2021-11-29 09:04:42.364801: validation loss: -0.4265\n",
      "2021-11-29 09:04:42.371594: Average global foreground Dice: [0.4311]\n",
      "2021-11-29 09:04:42.377636: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 09:04:42.897234: lr: 0.006692\n",
      "2021-11-29 09:04:43.002309: saving checkpoint...\n",
      "2021-11-29 09:04:44.466097: done, saving took 1.56 seconds\n",
      "2021-11-29 09:04:44.494051: This epoch took 196.309177 s\n",
      "\n",
      "2021-11-29 09:04:44.499145: \n",
      "epoch:  18\n",
      "2021-11-29 09:07:40.152287: train loss : -0.4011\n",
      "2021-11-29 09:07:53.860304: validation loss: -0.4265\n",
      "2021-11-29 09:07:53.866431: Average global foreground Dice: [0.4323]\n",
      "2021-11-29 09:07:53.871367: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 09:07:54.392272: lr: 0.006504\n",
      "2021-11-29 09:07:54.488443: saving checkpoint...\n",
      "2021-11-29 09:07:55.957384: done, saving took 1.56 seconds\n",
      "2021-11-29 09:07:55.987145: This epoch took 191.483624 s\n",
      "\n",
      "2021-11-29 09:07:55.992604: \n",
      "epoch:  19\n",
      "2021-11-29 09:10:58.727540: train loss : -0.4113\n",
      "2021-11-29 09:11:12.902847: validation loss: -0.4343\n",
      "2021-11-29 09:11:12.908638: Average global foreground Dice: [0.4363]\n",
      "2021-11-29 09:11:12.913218: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 09:11:13.432236: lr: 0.006314\n",
      "2021-11-29 09:11:13.527569: saving checkpoint...\n",
      "2021-11-29 09:11:15.004941: done, saving took 1.57 seconds\n",
      "2021-11-29 09:11:15.039348: This epoch took 199.041669 s\n",
      "\n",
      "2021-11-29 09:11:15.044582: \n",
      "epoch:  20\n",
      "2021-11-29 09:14:16.291523: train loss : -0.4170\n",
      "2021-11-29 09:14:29.779524: validation loss: -0.4334\n",
      "2021-11-29 09:14:29.790115: Average global foreground Dice: [0.4368]\n",
      "2021-11-29 09:14:29.795800: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 09:14:30.323316: lr: 0.006125\n",
      "2021-11-29 09:14:30.423622: saving checkpoint...\n",
      "2021-11-29 09:14:31.928252: done, saving took 1.60 seconds\n",
      "2021-11-29 09:14:31.952125: This epoch took 196.902182 s\n",
      "\n",
      "2021-11-29 09:14:31.956508: \n",
      "epoch:  21\n",
      "2021-11-29 09:17:27.933869: train loss : -0.4142\n",
      "2021-11-29 09:17:41.667477: validation loss: -0.4318\n",
      "2021-11-29 09:17:41.672841: Average global foreground Dice: [0.4383]\n",
      "2021-11-29 09:17:41.679477: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 09:17:42.195228: lr: 0.005934\n",
      "2021-11-29 09:17:42.237996: saving checkpoint...\n",
      "2021-11-29 09:17:43.750253: done, saving took 1.55 seconds\n",
      "2021-11-29 09:17:43.773465: This epoch took 191.811460 s\n",
      "\n",
      "2021-11-29 09:17:43.779725: \n",
      "epoch:  22\n",
      "2021-11-29 09:20:40.067037: train loss : -0.4077\n",
      "2021-11-29 09:20:53.577737: validation loss: -0.4484\n",
      "2021-11-29 09:20:53.592961: Average global foreground Dice: [0.4537]\n",
      "2021-11-29 09:20:53.598316: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 09:20:54.101381: lr: 0.005743\n",
      "2021-11-29 09:20:54.143634: saving checkpoint...\n",
      "2021-11-29 09:20:55.571335: done, saving took 1.47 seconds\n",
      "2021-11-29 09:20:55.592365: This epoch took 191.807326 s\n",
      "\n",
      "2021-11-29 09:20:55.597736: \n",
      "epoch:  23\n",
      "2021-11-29 09:23:52.625789: train loss : -0.4215\n",
      "2021-11-29 09:24:06.086376: validation loss: -0.4357\n",
      "2021-11-29 09:24:06.096636: Average global foreground Dice: [0.4376]\n",
      "2021-11-29 09:24:06.101957: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 09:24:06.617063: lr: 0.005551\n",
      "2021-11-29 09:24:06.661955: saving checkpoint...\n",
      "2021-11-29 09:24:08.120674: done, saving took 1.50 seconds\n",
      "2021-11-29 09:24:08.141121: This epoch took 192.538483 s\n",
      "\n",
      "2021-11-29 09:24:08.146471: \n",
      "epoch:  24\n",
      "2021-11-29 09:27:02.918301: train loss : -0.4276\n",
      "2021-11-29 09:27:16.522198: validation loss: -0.4622\n",
      "2021-11-29 09:27:16.528352: Average global foreground Dice: [0.4642]\n",
      "2021-11-29 09:27:16.539313: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 09:27:17.069050: lr: 0.005359\n",
      "2021-11-29 09:27:17.113174: saving checkpoint...\n",
      "2021-11-29 09:27:18.647035: done, saving took 1.57 seconds\n",
      "2021-11-29 09:27:18.674316: This epoch took 190.522952 s\n",
      "\n",
      "2021-11-29 09:27:18.680328: \n",
      "epoch:  25\n",
      "2021-11-29 09:30:19.791495: train loss : -0.4291\n",
      "2021-11-29 09:30:33.981237: validation loss: -0.4274\n",
      "2021-11-29 09:30:33.987443: Average global foreground Dice: [0.4306]\n",
      "2021-11-29 09:30:33.992898: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 09:30:34.514659: lr: 0.005166\n",
      "2021-11-29 09:30:34.557527: saving checkpoint...\n",
      "2021-11-29 09:30:36.144057: done, saving took 1.62 seconds\n",
      "2021-11-29 09:30:36.171967: This epoch took 197.485518 s\n",
      "\n",
      "2021-11-29 09:30:36.177913: \n",
      "epoch:  26\n",
      "2021-11-29 09:33:39.339904: train loss : -0.4269\n",
      "2021-11-29 09:33:52.930430: validation loss: -0.4390\n",
      "2021-11-29 09:33:52.938738: Average global foreground Dice: [0.4402]\n",
      "2021-11-29 09:33:52.943876: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 09:33:53.462616: lr: 0.004971\n",
      "2021-11-29 09:33:53.520760: saving checkpoint...\n",
      "2021-11-29 09:33:55.016418: done, saving took 1.55 seconds\n",
      "2021-11-29 09:33:55.042808: This epoch took 198.859199 s\n",
      "\n",
      "2021-11-29 09:33:55.048455: \n",
      "epoch:  27\n",
      "2021-11-29 09:36:49.936650: train loss : -0.4322\n",
      "2021-11-29 09:37:03.473530: validation loss: -0.4419\n",
      "2021-11-29 09:37:03.479289: Average global foreground Dice: [0.4466]\n",
      "2021-11-29 09:37:03.484718: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 09:37:04.023020: lr: 0.004776\n",
      "2021-11-29 09:37:04.097892: saving checkpoint...\n",
      "2021-11-29 09:37:05.573059: done, saving took 1.55 seconds\n",
      "2021-11-29 09:37:05.597384: This epoch took 190.543880 s\n",
      "\n",
      "2021-11-29 09:37:05.602075: \n",
      "epoch:  28\n",
      "2021-11-29 09:40:05.934269: train loss : -0.4292\n",
      "2021-11-29 09:40:20.100327: validation loss: -0.4411\n",
      "2021-11-29 09:40:20.111460: Average global foreground Dice: [0.4453]\n",
      "2021-11-29 09:40:20.117208: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 09:40:20.634921: lr: 0.004581\n",
      "2021-11-29 09:40:20.725523: saving checkpoint...\n",
      "2021-11-29 09:40:22.500843: done, saving took 1.86 seconds\n",
      "2021-11-29 09:40:22.531301: This epoch took 196.924440 s\n",
      "\n",
      "2021-11-29 09:40:22.537052: \n",
      "epoch:  29\n",
      "2021-11-29 09:43:25.975034: train loss : -0.4416\n",
      "2021-11-29 09:43:39.651941: validation loss: -0.4294\n",
      "2021-11-29 09:43:39.657706: Average global foreground Dice: [0.4325]\n",
      "2021-11-29 09:43:39.663432: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 09:43:40.185232: lr: 0.004384\n",
      "2021-11-29 09:43:40.276344: saving checkpoint...\n",
      "2021-11-29 09:43:41.996819: done, saving took 1.81 seconds\n",
      "2021-11-29 09:43:42.022436: This epoch took 199.480066 s\n",
      "\n",
      "2021-11-29 09:43:42.027454: \n",
      "epoch:  30\n",
      "2021-11-29 09:46:37.170815: train loss : -0.4277\n",
      "2021-11-29 09:46:50.755169: validation loss: -0.4498\n",
      "2021-11-29 09:46:50.763269: Average global foreground Dice: [0.4525]\n",
      "2021-11-29 09:46:50.768843: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 09:46:51.311670: lr: 0.004186\n",
      "2021-11-29 09:46:51.402910: saving checkpoint...\n",
      "2021-11-29 09:46:53.525426: done, saving took 2.21 seconds\n",
      "2021-11-29 09:46:53.548981: This epoch took 191.516081 s\n",
      "\n",
      "2021-11-29 09:46:53.554246: \n",
      "epoch:  31\n",
      "2021-11-29 09:49:50.090858: train loss : -0.4414\n",
      "2021-11-29 09:50:03.519318: validation loss: -0.4583\n",
      "2021-11-29 09:50:03.578909: Average global foreground Dice: [0.4608]\n",
      "2021-11-29 09:50:03.583930: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 09:50:04.107981: lr: 0.003987\n",
      "2021-11-29 09:50:04.187972: saving checkpoint...\n",
      "2021-11-29 09:50:06.126200: done, saving took 2.01 seconds\n",
      "2021-11-29 09:50:06.156634: This epoch took 192.596828 s\n",
      "\n",
      "2021-11-29 09:50:06.162279: \n",
      "epoch:  32\n",
      "2021-11-29 09:53:02.251054: train loss : -0.4416\n",
      "2021-11-29 09:53:16.045253: validation loss: -0.4541\n",
      "2021-11-29 09:53:16.050940: Average global foreground Dice: [0.459]\n",
      "2021-11-29 09:53:16.056272: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 09:53:16.573561: lr: 0.003787\n",
      "2021-11-29 09:53:16.653788: saving checkpoint...\n",
      "2021-11-29 09:53:18.131940: done, saving took 1.55 seconds\n",
      "2021-11-29 09:53:18.155700: This epoch took 191.987693 s\n",
      "\n",
      "2021-11-29 09:53:18.161209: \n",
      "epoch:  33\n",
      "2021-11-29 09:56:21.513445: train loss : -0.4354\n",
      "2021-11-29 09:56:35.653423: validation loss: -0.4593\n",
      "2021-11-29 09:56:35.659321: Average global foreground Dice: [0.4633]\n",
      "2021-11-29 09:56:35.665483: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 09:56:36.178278: lr: 0.003586\n",
      "2021-11-29 09:56:36.254534: saving checkpoint...\n",
      "2021-11-29 09:56:37.985285: done, saving took 1.80 seconds\n",
      "2021-11-29 09:56:38.010101: This epoch took 199.844152 s\n",
      "\n",
      "2021-11-29 09:56:38.015424: \n",
      "epoch:  34\n",
      "2021-11-29 09:59:41.759964: train loss : -0.4285\n",
      "2021-11-29 09:59:55.956391: validation loss: -0.4369\n",
      "2021-11-29 09:59:55.962605: Average global foreground Dice: [0.4401]\n",
      "2021-11-29 09:59:55.967515: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 09:59:56.483388: lr: 0.003384\n",
      "2021-11-29 09:59:56.572701: saving checkpoint...\n",
      "2021-11-29 09:59:58.160673: done, saving took 1.67 seconds\n",
      "2021-11-29 09:59:58.187299: This epoch took 200.165689 s\n",
      "\n",
      "2021-11-29 09:59:58.192402: \n",
      "epoch:  35\n",
      "2021-11-29 10:03:01.997165: train loss : -0.4462\n",
      "2021-11-29 10:03:16.133014: validation loss: -0.4548\n",
      "2021-11-29 10:03:16.139190: Average global foreground Dice: [0.4621]\n",
      "2021-11-29 10:03:16.144519: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 10:03:16.663995: lr: 0.00318\n",
      "2021-11-29 10:03:16.756562: saving checkpoint...\n",
      "2021-11-29 10:03:18.623354: done, saving took 1.95 seconds\n",
      "2021-11-29 10:03:18.651627: This epoch took 200.451557 s\n",
      "\n",
      "2021-11-29 10:03:18.658905: \n",
      "epoch:  36\n",
      "2021-11-29 10:06:14.436021: train loss : -0.4379\n",
      "2021-11-29 10:06:27.958446: validation loss: -0.4761\n",
      "2021-11-29 10:06:27.964816: Average global foreground Dice: [0.483]\n",
      "2021-11-29 10:06:27.970247: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 10:06:28.485231: lr: 0.002975\n",
      "2021-11-29 10:06:28.579325: saving checkpoint...\n",
      "2021-11-29 10:06:30.627581: done, saving took 2.14 seconds\n",
      "2021-11-29 10:06:30.655991: This epoch took 191.991693 s\n",
      "\n",
      "2021-11-29 10:06:30.661557: \n",
      "epoch:  37\n",
      "2021-11-29 10:09:30.498528: train loss : -0.4389\n",
      "2021-11-29 10:09:44.671225: validation loss: -0.4374\n",
      "2021-11-29 10:09:44.677243: Average global foreground Dice: [0.4435]\n",
      "2021-11-29 10:09:44.681648: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 10:09:45.239770: lr: 0.002768\n",
      "2021-11-29 10:09:45.337937: saving checkpoint...\n",
      "2021-11-29 10:09:46.951113: done, saving took 1.71 seconds\n",
      "2021-11-29 10:09:46.976733: This epoch took 196.310020 s\n",
      "\n",
      "2021-11-29 10:09:46.982715: \n",
      "epoch:  38\n",
      "2021-11-29 10:12:50.787985: train loss : -0.4334\n",
      "2021-11-29 10:13:04.850630: validation loss: -0.4426\n",
      "2021-11-29 10:13:04.856575: Average global foreground Dice: [0.4477]\n",
      "2021-11-29 10:13:04.861323: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 10:13:05.382021: lr: 0.00256\n",
      "2021-11-29 10:13:05.479997: saving checkpoint...\n",
      "2021-11-29 10:13:07.000186: done, saving took 1.61 seconds\n",
      "2021-11-29 10:13:07.028405: This epoch took 200.040876 s\n",
      "\n",
      "2021-11-29 10:13:07.033734: \n",
      "epoch:  39\n",
      "2021-11-29 10:16:03.303786: train loss : -0.4312\n",
      "2021-11-29 10:16:16.825929: validation loss: -0.4561\n",
      "2021-11-29 10:16:16.832007: Average global foreground Dice: [0.461]\n",
      "2021-11-29 10:16:16.838349: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 10:16:17.355772: lr: 0.002349\n",
      "2021-11-29 10:16:17.431046: saving checkpoint...\n",
      "2021-11-29 10:16:18.872957: done, saving took 1.51 seconds\n",
      "2021-11-29 10:16:18.901743: This epoch took 191.862491 s\n",
      "\n",
      "2021-11-29 10:16:18.906879: \n",
      "epoch:  40\n",
      "2021-11-29 10:19:16.012679: train loss : -0.4428\n",
      "2021-11-29 10:19:29.465955: validation loss: -0.4500\n",
      "2021-11-29 10:19:29.473639: Average global foreground Dice: [0.4556]\n",
      "2021-11-29 10:19:29.478702: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 10:19:30.003409: lr: 0.002137\n",
      "2021-11-29 10:19:30.092365: saving checkpoint...\n",
      "2021-11-29 10:19:31.627824: done, saving took 1.62 seconds\n",
      "2021-11-29 10:19:31.653541: This epoch took 192.740648 s\n",
      "\n",
      "2021-11-29 10:19:31.658821: \n",
      "epoch:  41\n",
      "2021-11-29 10:22:27.116416: train loss : -0.4449\n",
      "2021-11-29 10:22:40.797493: validation loss: -0.4612\n",
      "2021-11-29 10:22:40.803733: Average global foreground Dice: [0.4674]\n",
      "2021-11-29 10:22:40.809036: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 10:22:41.328864: lr: 0.001922\n",
      "2021-11-29 10:22:41.410205: saving checkpoint...\n",
      "2021-11-29 10:22:42.925851: done, saving took 1.59 seconds\n",
      "2021-11-29 10:22:42.951868: This epoch took 191.288136 s\n",
      "\n",
      "2021-11-29 10:22:42.957729: \n",
      "epoch:  42\n",
      "/tf/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-11-29 10:25:39.132339: train loss : -0.4398\n",
      "2021-11-29 10:25:52.619994: validation loss: -0.4492\n",
      "2021-11-29 10:25:52.625600: Average global foreground Dice: [0.4557]\n",
      "2021-11-29 10:25:52.631429: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 10:25:53.161820: lr: 0.001704\n",
      "2021-11-29 10:25:53.251521: saving checkpoint...\n",
      "2021-11-29 10:25:55.609766: done, saving took 2.44 seconds\n",
      "2021-11-29 10:25:55.638736: This epoch took 192.675313 s\n",
      "\n",
      "2021-11-29 10:25:55.644371: \n",
      "epoch:  43\n",
      "2021-11-29 10:28:52.713454: train loss : -0.4447\n",
      "2021-11-29 10:29:06.222011: validation loss: -0.4605\n",
      "2021-11-29 10:29:06.227947: Average global foreground Dice: [0.4653]\n",
      "2021-11-29 10:29:06.233275: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 10:29:06.743247: lr: 0.001483\n",
      "2021-11-29 10:29:06.811608: saving checkpoint...\n",
      "2021-11-29 10:29:08.133151: done, saving took 1.38 seconds\n",
      "2021-11-29 10:29:08.156747: This epoch took 192.507070 s\n",
      "\n",
      "2021-11-29 10:29:08.162020: \n",
      "epoch:  44\n",
      "2021-11-29 10:32:03.796498: train loss : -0.4517\n",
      "2021-11-29 10:32:17.457916: validation loss: -0.4766\n",
      "2021-11-29 10:32:17.464624: Average global foreground Dice: [0.4783]\n",
      "2021-11-29 10:32:17.469890: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 10:32:17.982361: lr: 0.001259\n",
      "2021-11-29 10:32:18.034946: saving checkpoint...\n",
      "2021-11-29 10:32:19.848630: done, saving took 1.86 seconds\n",
      "2021-11-29 10:32:19.874673: This epoch took 191.707836 s\n",
      "\n",
      "2021-11-29 10:32:19.879259: \n",
      "epoch:  45\n",
      "2021-11-29 10:35:16.590124: train loss : -0.4503\n",
      "2021-11-29 10:35:30.053410: validation loss: -0.4566\n",
      "2021-11-29 10:35:30.059912: Average global foreground Dice: [0.4591]\n",
      "2021-11-29 10:35:30.066444: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 10:35:30.606716: lr: 0.00103\n",
      "2021-11-29 10:35:30.682688: saving checkpoint...\n",
      "2021-11-29 10:35:32.661715: done, saving took 2.05 seconds\n",
      "2021-11-29 10:35:32.687752: This epoch took 192.802931 s\n",
      "\n",
      "2021-11-29 10:35:32.692900: \n",
      "epoch:  46\n",
      "2021-11-29 10:38:29.718826: train loss : -0.4512\n",
      "2021-11-29 10:38:43.272490: validation loss: -0.4554\n",
      "2021-11-29 10:38:43.278471: Average global foreground Dice: [0.457]\n",
      "2021-11-29 10:38:43.284796: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 10:38:43.803045: lr: 0.000795\n",
      "2021-11-29 10:38:43.894411: saving checkpoint...\n",
      "2021-11-29 10:38:45.746459: done, saving took 1.94 seconds\n",
      "2021-11-29 10:38:45.773200: This epoch took 193.074154 s\n",
      "\n",
      "2021-11-29 10:38:45.778490: \n",
      "epoch:  47\n",
      "2021-11-29 10:41:40.654066: train loss : -0.4396\n",
      "2021-11-29 10:41:54.213180: validation loss: -0.4413\n",
      "2021-11-29 10:41:54.221071: Average global foreground Dice: [0.4446]\n",
      "2021-11-29 10:41:54.225874: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 10:41:54.769301: lr: 0.000552\n",
      "2021-11-29 10:41:54.774662: This epoch took 188.990460 s\n",
      "\n",
      "2021-11-29 10:41:54.780092: \n",
      "epoch:  48\n",
      "2021-11-29 10:44:51.585685: train loss : -0.4432\n",
      "2021-11-29 10:45:05.060069: validation loss: -0.4471\n",
      "2021-11-29 10:45:05.065328: Average global foreground Dice: [0.4493]\n",
      "2021-11-29 10:45:05.073900: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 10:45:05.602119: lr: 0.000296\n",
      "2021-11-29 10:45:05.607472: This epoch took 190.822399 s\n",
      "\n",
      "2021-11-29 10:45:05.612738: \n",
      "epoch:  49\n",
      "2021-11-29 10:48:02.156891: train loss : -0.4477\n",
      "2021-11-29 10:48:15.977607: validation loss: -0.4521\n",
      "2021-11-29 10:48:15.983577: Average global foreground Dice: [0.4566]\n",
      "2021-11-29 10:48:15.988727: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 10:48:16.520142: lr: 0.0\n",
      "2021-11-29 10:48:16.525108: saving scheduled checkpoint file...\n",
      "2021-11-29 10:48:16.615360: saving checkpoint...\n",
      "2021-11-29 10:48:17.717124: done, saving took 1.19 seconds\n",
      "2021-11-29 10:48:17.738368: done\n",
      "2021-11-29 10:48:17.743771: This epoch took 192.126005 s\n",
      "\n",
      "2021-11-29 10:48:17.833841: saving checkpoint...\n",
      "2021-11-29 10:48:19.255938: done, saving took 1.51 seconds\n",
      "GGHB_DC68_LJH0_BABA_0002 (2, 57, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "GGHB_DC68_LJH0_BABA_0003 (2, 149, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RALP_0000 (2, 96, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RALP_0001 (2, 145, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "SNUH_DC07_JCW0_RALP_0002 (2, 83, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RALP_0011 (2, 111, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RALP_0020 (2, 213, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "SNUH_DC07_JCW0_RALP_0021 (2, 67, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RALP_0031 (2, 150, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RLPN_0002 (2, 90, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RLPN_0003 (2, 123, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RLPN_0008 (2, 86, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "SNUH_DC07_JCW0_RLPN_0009 (2, 42, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RLPN_0014 (2, 38, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC68_KSJ0_BABA_0001 (2, 38, 343, 502)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC68_LKE0_BABA_0001 (2, 38, 342, 495)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC68_LKE0_BABA_0002 (2, 96, 342, 488)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-29 10:52:19.221050: finished prediction\n",
      "2021-11-29 10:52:19.225858: evaluation of raw predictions\n",
      "2021-11-29 10:52:22.459309: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.41265380728080475\n",
      "after:  0.41265258951146655\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "!nnUNet_train 2d nnUNetTrainerV2_Loss_Dice 480 all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.loss_function.nnUNetTrainerV2_Loss_CE.nnUNetTrainerV2_Loss_CE'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'png'}\n",
      "use_mask_for_norm OrderedDict([(0, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 12, 'num_pool_per_axis': [7, 7], 'patch_size': array([512, 512]), 'median_patient_size_in_voxels': array([ 90, 512, 512]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /tf/temp/nnUNet/nnunet/preprocessed/Task480_GRSR/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-29 11:44:47.497618: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-29 11:44:55.213116: Unable to plot network architecture:\n",
      "2021-11-29 11:44:55.218592: No module named 'hiddenlayer'\n",
      "2021-11-29 11:44:55.224335: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-29 11:44:55.230992: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (1): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (2): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (3): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (4): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (5): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (6): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (4): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (5): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (6): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-29 11:44:55.311209: \n",
      "\n",
      "2021-11-29 11:44:55.316451: \n",
      "epoch:  0\n",
      "2021-11-29 11:47:56.968377: train loss : 0.3010\n",
      "2021-11-29 11:48:09.165048: validation loss: 0.2460\n",
      "2021-11-29 11:48:09.170520: Average global foreground Dice: [0.0]\n",
      "2021-11-29 11:48:09.176087: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 11:48:09.583123: lr: 0.00982\n",
      "2021-11-29 11:48:09.587867: This epoch took 194.265080 s\n",
      "\n",
      "2021-11-29 11:48:09.593459: \n",
      "epoch:  1\n",
      "2021-11-29 11:51:02.498190: train loss : 0.2374\n",
      "2021-11-29 11:51:15.011805: validation loss: 0.2332\n",
      "2021-11-29 11:51:15.017034: Average global foreground Dice: [0.0]\n",
      "2021-11-29 11:51:15.021859: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 11:51:15.522694: lr: 0.009639\n",
      "2021-11-29 11:51:15.528260: This epoch took 185.930463 s\n",
      "\n",
      "2021-11-29 11:51:15.533633: \n",
      "epoch:  2\n",
      "2021-11-29 11:54:08.994671: train loss : 0.2268\n",
      "2021-11-29 11:54:21.552298: validation loss: 0.2193\n",
      "2021-11-29 11:54:21.557749: Average global foreground Dice: [0.0]\n",
      "2021-11-29 11:54:21.566498: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 11:54:22.095963: lr: 0.009458\n",
      "2021-11-29 11:54:22.208358: saving checkpoint...\n",
      "2021-11-29 11:54:23.449971: done, saving took 1.35 seconds\n",
      "2021-11-29 11:54:23.469714: This epoch took 187.930964 s\n",
      "\n",
      "2021-11-29 11:54:23.474925: \n",
      "epoch:  3\n",
      "2021-11-29 11:57:17.170875: train loss : 0.2079\n",
      "2021-11-29 11:57:29.641778: validation loss: 0.1904\n",
      "2021-11-29 11:57:29.647046: Average global foreground Dice: [0.0002]\n",
      "2021-11-29 11:57:29.657072: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 11:57:30.163440: lr: 0.009277\n",
      "2021-11-29 11:57:30.255365: saving checkpoint...\n",
      "2021-11-29 11:57:31.758850: done, saving took 1.59 seconds\n",
      "2021-11-29 11:57:31.786386: This epoch took 188.306773 s\n",
      "\n",
      "2021-11-29 11:57:31.791093: \n",
      "epoch:  4\n",
      "2021-11-29 12:00:20.007218: train loss : 0.1928\n",
      "2021-11-29 12:00:31.857263: validation loss: 0.1858\n",
      "2021-11-29 12:00:31.870957: Average global foreground Dice: [0.0011]\n",
      "2021-11-29 12:00:31.876210: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 12:00:32.379704: lr: 0.009095\n",
      "2021-11-29 12:00:32.485857: saving checkpoint...\n",
      "2021-11-29 12:00:34.094934: done, saving took 1.71 seconds\n",
      "2021-11-29 12:00:34.116967: This epoch took 182.314968 s\n",
      "\n",
      "2021-11-29 12:00:34.121916: \n",
      "epoch:  5\n",
      "2021-11-29 12:03:21.277874: train loss : 0.1850\n",
      "2021-11-29 12:03:33.567546: validation loss: 0.1786\n",
      "2021-11-29 12:03:33.575319: Average global foreground Dice: [0.0311]\n",
      "2021-11-29 12:03:33.581073: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 12:03:34.096093: lr: 0.008913\n",
      "2021-11-29 12:03:34.139215: saving checkpoint...\n",
      "2021-11-29 12:03:35.545933: done, saving took 1.45 seconds\n",
      "2021-11-29 12:03:35.568727: This epoch took 181.442388 s\n",
      "\n",
      "2021-11-29 12:03:35.573562: \n",
      "epoch:  6\n",
      "2021-11-29 12:06:29.034003: train loss : 0.1793\n",
      "2021-11-29 12:06:41.534295: validation loss: 0.1767\n",
      "2021-11-29 12:06:41.540446: Average global foreground Dice: [0.1456]\n",
      "2021-11-29 12:06:41.545753: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 12:06:42.053158: lr: 0.008731\n",
      "2021-11-29 12:06:42.127417: saving checkpoint...\n",
      "2021-11-29 12:06:43.533819: done, saving took 1.48 seconds\n",
      "2021-11-29 12:06:43.559435: This epoch took 187.981098 s\n",
      "\n",
      "2021-11-29 12:06:43.564898: \n",
      "epoch:  7\n",
      "2021-11-29 12:09:37.235122: train loss : 0.1778\n",
      "2021-11-29 12:09:49.701056: validation loss: 0.1819\n",
      "2021-11-29 12:09:49.707145: Average global foreground Dice: [0.2425]\n",
      "2021-11-29 12:09:49.712614: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 12:09:50.215860: lr: 0.008548\n",
      "2021-11-29 12:09:50.305174: saving checkpoint...\n",
      "2021-11-29 12:09:51.811287: done, saving took 1.59 seconds\n",
      "2021-11-29 12:09:51.835756: This epoch took 188.266450 s\n",
      "\n",
      "2021-11-29 12:09:51.841037: \n",
      "epoch:  8\n",
      "2021-11-29 12:12:45.781757: train loss : 0.1750\n",
      "2021-11-29 12:12:58.241353: validation loss: 0.1627\n",
      "2021-11-29 12:12:58.247656: Average global foreground Dice: [0.1007]\n",
      "2021-11-29 12:12:58.253080: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 12:12:58.825345: lr: 0.008364\n",
      "2021-11-29 12:12:58.869660: saving checkpoint...\n",
      "2021-11-29 12:13:00.405452: done, saving took 1.57 seconds\n",
      "2021-11-29 12:13:00.427403: This epoch took 188.581404 s\n",
      "\n",
      "2021-11-29 12:13:00.432710: \n",
      "epoch:  9\n",
      "2021-11-29 12:15:47.157541: train loss : 0.1730\n",
      "2021-11-29 12:15:59.071365: validation loss: 0.1684\n",
      "2021-11-29 12:15:59.078753: Average global foreground Dice: [0.1953]\n",
      "2021-11-29 12:15:59.084515: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 12:15:59.594448: lr: 0.008181\n",
      "2021-11-29 12:15:59.637177: saving checkpoint...\n",
      "2021-11-29 12:16:01.104677: done, saving took 1.51 seconds\n",
      "2021-11-29 12:16:01.124826: This epoch took 180.686913 s\n",
      "\n",
      "2021-11-29 12:16:01.129562: \n",
      "epoch:  10\n",
      "2021-11-29 12:18:49.245167: train loss : 0.1699\n",
      "2021-11-29 12:19:01.175426: validation loss: 0.1727\n",
      "2021-11-29 12:19:01.181143: Average global foreground Dice: [0.1487]\n",
      "2021-11-29 12:19:01.186162: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 12:19:01.701152: lr: 0.007996\n",
      "2021-11-29 12:19:01.745616: saving checkpoint...\n",
      "2021-11-29 12:19:03.451619: done, saving took 1.74 seconds\n",
      "2021-11-29 12:19:03.481155: This epoch took 182.346501 s\n",
      "\n",
      "2021-11-29 12:19:03.486627: \n",
      "epoch:  11\n",
      "2021-11-29 12:21:49.181679: train loss : 0.1653\n",
      "2021-11-29 12:22:01.241063: validation loss: 0.1702\n",
      "2021-11-29 12:22:01.246548: Average global foreground Dice: [0.2436]\n",
      "2021-11-29 12:22:01.251972: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 12:22:01.751872: lr: 0.007811\n",
      "2021-11-29 12:22:01.829717: saving checkpoint...\n",
      "2021-11-29 12:22:03.308910: done, saving took 1.55 seconds\n",
      "2021-11-29 12:22:03.333275: This epoch took 179.841394 s\n",
      "\n",
      "2021-11-29 12:22:03.338485: \n",
      "epoch:  12\n",
      "2021-11-29 12:24:54.933559: train loss : 0.1698\n",
      "2021-11-29 12:25:07.516630: validation loss: 0.1688\n",
      "2021-11-29 12:25:07.522717: Average global foreground Dice: [0.2367]\n",
      "2021-11-29 12:25:07.528389: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 12:25:08.064403: lr: 0.007626\n",
      "2021-11-29 12:25:08.151641: saving checkpoint...\n",
      "2021-11-29 12:25:10.046023: done, saving took 1.97 seconds\n",
      "2021-11-29 12:25:10.071367: This epoch took 186.727676 s\n",
      "\n",
      "2021-11-29 12:25:10.077582: \n",
      "epoch:  13\n",
      "2021-11-29 12:28:03.863506: train loss : 0.1654\n",
      "2021-11-29 12:28:16.433880: validation loss: 0.1643\n",
      "2021-11-29 12:28:16.439609: Average global foreground Dice: [0.2628]\n",
      "2021-11-29 12:28:16.444957: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 12:28:16.974102: lr: 0.00744\n",
      "2021-11-29 12:28:17.060555: saving checkpoint...\n",
      "2021-11-29 12:28:18.542287: done, saving took 1.56 seconds\n",
      "2021-11-29 12:28:18.569976: This epoch took 188.486972 s\n",
      "\n",
      "2021-11-29 12:28:18.575729: \n",
      "epoch:  14\n",
      "2021-11-29 12:31:04.850510: train loss : 0.1689\n",
      "2021-11-29 12:31:16.779658: validation loss: 0.1637\n",
      "2021-11-29 12:31:16.785967: Average global foreground Dice: [0.1968]\n",
      "2021-11-29 12:31:16.790613: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 12:31:17.344015: lr: 0.007254\n",
      "2021-11-29 12:31:17.389123: saving checkpoint...\n",
      "2021-11-29 12:31:19.056667: done, saving took 1.71 seconds\n",
      "2021-11-29 12:31:19.079566: This epoch took 180.498527 s\n",
      "\n",
      "2021-11-29 12:31:19.084627: \n",
      "epoch:  15\n",
      "2021-11-29 12:34:06.449747: train loss : 0.1659\n",
      "2021-11-29 12:34:18.317919: validation loss: 0.1710\n",
      "2021-11-29 12:34:18.323984: Average global foreground Dice: [0.3189]\n",
      "2021-11-29 12:34:18.328847: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 12:34:18.848066: lr: 0.007067\n",
      "2021-11-29 12:34:18.893650: saving checkpoint...\n",
      "2021-11-29 12:34:20.365700: done, saving took 1.51 seconds\n",
      "2021-11-29 12:34:20.385238: This epoch took 181.295154 s\n",
      "\n",
      "2021-11-29 12:34:20.390497: \n",
      "epoch:  16\n",
      "2021-11-29 12:37:06.007523: train loss : 0.1641\n",
      "2021-11-29 12:37:18.035967: validation loss: 0.1636\n",
      "2021-11-29 12:37:18.041440: Average global foreground Dice: [0.2441]\n",
      "2021-11-29 12:37:18.046926: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 12:37:18.570810: lr: 0.00688\n",
      "2021-11-29 12:37:18.620383: saving checkpoint...\n",
      "2021-11-29 12:37:20.073850: done, saving took 1.50 seconds\n",
      "2021-11-29 12:37:20.098032: This epoch took 179.701728 s\n",
      "\n",
      "2021-11-29 12:37:20.103553: \n",
      "epoch:  17\n",
      "2021-11-29 12:40:07.128313: train loss : 0.1616\n",
      "2021-11-29 12:40:19.009706: validation loss: 0.1566\n",
      "2021-11-29 12:40:19.015463: Average global foreground Dice: [0.2524]\n",
      "2021-11-29 12:40:19.020887: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 12:40:19.554284: lr: 0.006692\n",
      "2021-11-29 12:40:19.630972: saving checkpoint...\n",
      "2021-11-29 12:40:21.079768: done, saving took 1.52 seconds\n",
      "2021-11-29 12:40:21.105295: This epoch took 180.996026 s\n",
      "\n",
      "2021-11-29 12:40:21.110718: \n",
      "epoch:  18\n",
      "2021-11-29 12:43:08.088936: train loss : 0.1622\n",
      "2021-11-29 12:43:20.289295: validation loss: 0.1598\n",
      "2021-11-29 12:43:20.294831: Average global foreground Dice: [0.255]\n",
      "2021-11-29 12:43:20.300382: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 12:43:20.826414: lr: 0.006504\n",
      "2021-11-29 12:43:20.903194: saving checkpoint...\n",
      "2021-11-29 12:43:22.196728: done, saving took 1.37 seconds\n",
      "2021-11-29 12:43:22.219121: This epoch took 181.103403 s\n",
      "\n",
      "2021-11-29 12:43:22.225015: \n",
      "epoch:  19\n",
      "2021-11-29 12:46:08.072470: train loss : 0.1624\n",
      "2021-11-29 12:46:20.006697: validation loss: 0.1709\n",
      "2021-11-29 12:46:20.014519: Average global foreground Dice: [0.2657]\n",
      "2021-11-29 12:46:20.020194: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 12:46:20.611573: lr: 0.006314\n",
      "2021-11-29 12:46:20.655325: saving checkpoint...\n",
      "2021-11-29 12:46:22.045240: done, saving took 1.43 seconds\n",
      "2021-11-29 12:46:22.064185: This epoch took 179.833629 s\n",
      "\n",
      "2021-11-29 12:46:22.069860: \n",
      "epoch:  20\n",
      "2021-11-29 12:49:10.053576: train loss : 0.1642\n",
      "2021-11-29 12:49:21.952773: validation loss: 0.1562\n",
      "2021-11-29 12:49:21.958754: Average global foreground Dice: [0.2655]\n",
      "2021-11-29 12:49:21.964118: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 12:49:22.500982: lr: 0.006125\n",
      "2021-11-29 12:49:22.544674: saving checkpoint...\n",
      "2021-11-29 12:49:24.033536: done, saving took 1.53 seconds\n",
      "2021-11-29 12:49:24.054550: This epoch took 181.978774 s\n",
      "\n",
      "2021-11-29 12:49:24.060212: \n",
      "epoch:  21\n",
      "2021-11-29 12:52:09.881586: train loss : 0.1619\n",
      "2021-11-29 12:52:21.935467: validation loss: 0.1575\n",
      "2021-11-29 12:52:21.942613: Average global foreground Dice: [0.2875]\n",
      "2021-11-29 12:52:21.948034: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 12:52:22.482039: lr: 0.005934\n",
      "2021-11-29 12:52:22.525437: saving checkpoint...\n",
      "2021-11-29 12:52:24.016186: done, saving took 1.53 seconds\n",
      "2021-11-29 12:52:24.037468: This epoch took 179.972503 s\n",
      "\n",
      "2021-11-29 12:52:24.042545: \n",
      "epoch:  22\n",
      "2021-11-29 12:55:10.532620: train loss : 0.1625\n",
      "2021-11-29 12:55:22.376159: validation loss: 0.1561\n",
      "2021-11-29 12:55:22.381679: Average global foreground Dice: [0.319]\n",
      "2021-11-29 12:55:22.387194: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 12:55:22.917314: lr: 0.005743\n",
      "2021-11-29 12:55:22.960904: saving checkpoint...\n",
      "2021-11-29 12:55:24.520844: done, saving took 1.60 seconds\n",
      "2021-11-29 12:55:24.545408: This epoch took 180.497509 s\n",
      "\n",
      "2021-11-29 12:55:24.552818: \n",
      "epoch:  23\n",
      "2021-11-29 12:58:11.032754: train loss : 0.1584\n",
      "2021-11-29 12:58:23.174993: validation loss: 0.1636\n",
      "2021-11-29 12:58:23.181830: Average global foreground Dice: [0.3021]\n",
      "2021-11-29 12:58:23.187776: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 12:58:23.706935: lr: 0.005551\n",
      "2021-11-29 12:58:23.780431: saving checkpoint...\n",
      "2021-11-29 12:58:25.246506: done, saving took 1.53 seconds\n",
      "2021-11-29 12:58:25.271433: This epoch took 180.713541 s\n",
      "\n",
      "2021-11-29 12:58:25.277082: \n",
      "epoch:  24\n",
      "2021-11-29 13:01:10.825214: train loss : 0.1585\n",
      "2021-11-29 13:01:22.727545: validation loss: 0.1645\n",
      "2021-11-29 13:01:22.733549: Average global foreground Dice: [0.2565]\n",
      "2021-11-29 13:01:22.737996: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 13:01:23.256496: lr: 0.005359\n",
      "2021-11-29 13:01:23.350008: saving checkpoint...\n",
      "2021-11-29 13:01:24.896008: done, saving took 1.63 seconds\n",
      "2021-11-29 13:01:24.922771: This epoch took 179.640408 s\n",
      "\n",
      "2021-11-29 13:01:24.928096: \n",
      "epoch:  25\n",
      "2021-11-29 13:04:12.421197: train loss : 0.1601\n",
      "2021-11-29 13:04:24.287945: validation loss: 0.1621\n",
      "2021-11-29 13:04:24.295404: Average global foreground Dice: [0.2892]\n",
      "2021-11-29 13:04:24.301011: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 13:04:24.818343: lr: 0.005166\n",
      "2021-11-29 13:04:24.861849: saving checkpoint...\n",
      "2021-11-29 13:04:26.385549: done, saving took 1.56 seconds\n",
      "2021-11-29 13:04:26.408751: This epoch took 181.475146 s\n",
      "\n",
      "2021-11-29 13:04:26.413873: \n",
      "epoch:  26\n",
      "2021-11-29 13:07:12.221007: train loss : 0.1608\n",
      "2021-11-29 13:07:24.230213: validation loss: 0.1633\n",
      "2021-11-29 13:07:24.236952: Average global foreground Dice: [0.2753]\n",
      "2021-11-29 13:07:24.243143: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 13:07:24.799407: lr: 0.004971\n",
      "2021-11-29 13:07:24.843071: saving checkpoint...\n",
      "2021-11-29 13:07:27.523784: done, saving took 2.72 seconds\n",
      "2021-11-29 13:07:27.545693: This epoch took 181.125383 s\n",
      "\n",
      "2021-11-29 13:07:27.551903: \n",
      "epoch:  27\n",
      "2021-11-29 13:10:13.864703: train loss : 0.1606\n",
      "2021-11-29 13:10:25.724864: validation loss: 0.1623\n",
      "2021-11-29 13:10:25.733422: Average global foreground Dice: [0.2821]\n",
      "2021-11-29 13:10:25.739080: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 13:10:26.256626: lr: 0.004776\n",
      "2021-11-29 13:10:26.300218: saving checkpoint...\n",
      "2021-11-29 13:10:27.658350: done, saving took 1.40 seconds\n",
      "2021-11-29 13:10:27.686224: This epoch took 180.129232 s\n",
      "\n",
      "2021-11-29 13:10:27.692912: \n",
      "epoch:  28\n",
      "2021-11-29 13:13:14.700557: train loss : 0.1632\n",
      "2021-11-29 13:13:26.839791: validation loss: 0.1622\n",
      "2021-11-29 13:13:26.846358: Average global foreground Dice: [0.2874]\n",
      "2021-11-29 13:13:26.851784: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 13:13:27.369261: lr: 0.004581\n",
      "2021-11-29 13:13:27.444861: saving checkpoint...\n",
      "2021-11-29 13:13:28.913012: done, saving took 1.54 seconds\n",
      "2021-11-29 13:13:28.938858: This epoch took 181.239851 s\n",
      "\n",
      "2021-11-29 13:13:28.944804: \n",
      "epoch:  29\n",
      "2021-11-29 13:16:14.395012: train loss : 0.1602\n",
      "2021-11-29 13:16:26.320347: validation loss: 0.1618\n",
      "2021-11-29 13:16:26.327436: Average global foreground Dice: [0.2242]\n",
      "2021-11-29 13:16:26.332957: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 13:16:26.855216: lr: 0.004384\n",
      "2021-11-29 13:16:26.860712: This epoch took 177.910871 s\n",
      "\n",
      "2021-11-29 13:16:26.866075: \n",
      "epoch:  30\n",
      "2021-11-29 13:19:14.669221: train loss : 0.1617\n",
      "2021-11-29 13:19:26.515851: validation loss: 0.1600\n",
      "2021-11-29 13:19:26.522399: Average global foreground Dice: [0.2785]\n",
      "2021-11-29 13:19:26.527725: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 13:19:27.064312: lr: 0.004186\n",
      "2021-11-29 13:19:27.157604: saving checkpoint...\n",
      "2021-11-29 13:19:28.734896: done, saving took 1.66 seconds\n",
      "2021-11-29 13:19:28.760355: This epoch took 181.889438 s\n",
      "\n",
      "2021-11-29 13:19:28.766468: \n",
      "epoch:  31\n",
      "2021-11-29 13:22:14.477074: train loss : 0.1587\n",
      "2021-11-29 13:22:26.563527: validation loss: 0.1588\n",
      "2021-11-29 13:22:26.570977: Average global foreground Dice: [0.2984]\n",
      "2021-11-29 13:22:26.576314: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 13:22:27.122793: lr: 0.003987\n",
      "2021-11-29 13:22:27.165810: saving checkpoint...\n",
      "2021-11-29 13:22:28.779099: done, saving took 1.65 seconds\n",
      "2021-11-29 13:22:28.801568: This epoch took 180.029438 s\n",
      "\n",
      "2021-11-29 13:22:28.807371: \n",
      "epoch:  32\n",
      "2021-11-29 13:25:21.101785: train loss : 0.1598\n",
      "2021-11-29 13:25:33.644480: validation loss: 0.1591\n",
      "2021-11-29 13:25:33.649822: Average global foreground Dice: [0.348]\n",
      "2021-11-29 13:25:33.655374: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 13:25:34.186247: lr: 0.003787\n",
      "2021-11-29 13:25:34.233575: saving checkpoint...\n",
      "2021-11-29 13:25:35.666816: done, saving took 1.47 seconds\n",
      "2021-11-29 13:25:35.693906: This epoch took 186.881883 s\n",
      "\n",
      "2021-11-29 13:25:35.701029: \n",
      "epoch:  33\n",
      "2021-11-29 13:28:30.114862: train loss : 0.1620\n",
      "2021-11-29 13:28:42.716217: validation loss: 0.1594\n",
      "2021-11-29 13:28:42.722191: Average global foreground Dice: [0.2781]\n",
      "2021-11-29 13:28:42.728725: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 13:28:43.273853: lr: 0.003586\n",
      "2021-11-29 13:28:43.338996: saving checkpoint...\n",
      "2021-11-29 13:28:45.018924: done, saving took 1.74 seconds\n",
      "2021-11-29 13:28:45.050508: This epoch took 189.343739 s\n",
      "\n",
      "2021-11-29 13:28:45.056885: \n",
      "epoch:  34\n",
      "2021-11-29 13:31:39.536558: train loss : 0.1561\n",
      "2021-11-29 13:31:51.997638: validation loss: 0.1634\n",
      "2021-11-29 13:31:52.003316: Average global foreground Dice: [0.3124]\n",
      "2021-11-29 13:31:52.009584: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 13:31:52.540158: lr: 0.003384\n",
      "2021-11-29 13:31:52.622097: saving checkpoint...\n",
      "2021-11-29 13:31:54.061946: done, saving took 1.52 seconds\n",
      "2021-11-29 13:31:54.088564: This epoch took 189.026455 s\n",
      "\n",
      "2021-11-29 13:31:54.093480: \n",
      "epoch:  35\n",
      "2021-11-29 13:34:44.502416: train loss : 0.1579\n",
      "2021-11-29 13:34:56.400884: validation loss: 0.1576\n",
      "2021-11-29 13:34:56.406837: Average global foreground Dice: [0.3348]\n",
      "2021-11-29 13:34:56.411931: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 13:34:56.945897: lr: 0.00318\n",
      "2021-11-29 13:34:57.028546: saving checkpoint...\n",
      "2021-11-29 13:34:58.611563: done, saving took 1.66 seconds\n",
      "2021-11-29 13:34:58.638994: This epoch took 184.539717 s\n",
      "\n",
      "2021-11-29 13:34:58.646929: \n",
      "epoch:  36\n",
      "2021-11-29 13:37:45.197613: train loss : 0.1552\n",
      "2021-11-29 13:37:57.372031: validation loss: 0.1573\n",
      "2021-11-29 13:37:57.379642: Average global foreground Dice: [0.3128]\n",
      "2021-11-29 13:37:57.385337: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 13:37:58.025880: lr: 0.002975\n",
      "2021-11-29 13:37:58.070808: saving checkpoint...\n",
      "2021-11-29 13:38:00.105035: done, saving took 2.07 seconds\n",
      "2021-11-29 13:38:00.127549: This epoch took 181.475340 s\n",
      "\n",
      "2021-11-29 13:38:00.133228: \n",
      "epoch:  37\n",
      "2021-11-29 13:40:46.928913: train loss : 0.1573\n",
      "2021-11-29 13:40:58.846431: validation loss: 0.1573\n",
      "2021-11-29 13:40:58.852250: Average global foreground Dice: [0.3178]\n",
      "2021-11-29 13:40:58.857287: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 13:40:59.379728: lr: 0.002768\n",
      "2021-11-29 13:40:59.423223: saving checkpoint...\n",
      "2021-11-29 13:41:01.839060: done, saving took 2.45 seconds\n",
      "2021-11-29 13:41:01.859610: This epoch took 181.720138 s\n",
      "\n",
      "2021-11-29 13:41:01.865264: \n",
      "epoch:  38\n",
      "2021-11-29 13:43:50.343879: train loss : 0.1556\n",
      "2021-11-29 13:44:02.227609: validation loss: 0.1623\n",
      "2021-11-29 13:44:02.235040: Average global foreground Dice: [0.3191]\n",
      "2021-11-29 13:44:02.240415: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 13:44:02.773217: lr: 0.00256\n",
      "2021-11-29 13:44:02.817040: saving checkpoint...\n",
      "2021-11-29 13:44:04.404966: done, saving took 1.63 seconds\n",
      "2021-11-29 13:44:04.426789: This epoch took 182.556020 s\n",
      "\n",
      "2021-11-29 13:44:04.431945: \n",
      "epoch:  39\n",
      "2021-11-29 13:46:50.368685: train loss : 0.1596\n",
      "2021-11-29 13:47:02.355270: validation loss: 0.1562\n",
      "2021-11-29 13:47:02.361551: Average global foreground Dice: [0.3278]\n",
      "2021-11-29 13:47:02.367487: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 13:47:02.917670: lr: 0.002349\n",
      "2021-11-29 13:47:02.961212: saving checkpoint...\n",
      "2021-11-29 13:47:04.455106: done, saving took 1.53 seconds\n",
      "2021-11-29 13:47:04.474957: This epoch took 180.036849 s\n",
      "\n",
      "2021-11-29 13:47:04.480866: \n",
      "epoch:  40\n",
      "2021-11-29 13:49:52.129427: train loss : 0.1580\n",
      "2021-11-29 13:50:03.988182: validation loss: 0.1554\n",
      "2021-11-29 13:50:03.994331: Average global foreground Dice: [0.3038]\n",
      "2021-11-29 13:50:04.000643: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 13:50:04.540832: lr: 0.002137\n",
      "2021-11-29 13:50:04.622381: saving checkpoint...\n",
      "2021-11-29 13:50:06.298095: done, saving took 1.75 seconds\n",
      "2021-11-29 13:50:06.324337: This epoch took 181.837943 s\n",
      "\n",
      "2021-11-29 13:50:06.329048: \n",
      "epoch:  41\n",
      "2021-11-29 13:52:53.573140: train loss : 0.1597\n",
      "2021-11-29 13:53:05.757168: validation loss: 0.1523\n",
      "2021-11-29 13:53:05.765610: Average global foreground Dice: [0.309]\n",
      "2021-11-29 13:53:05.771412: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 13:53:06.309589: lr: 0.001922\n",
      "2021-11-29 13:53:06.389564: saving checkpoint...\n",
      "2021-11-29 13:53:08.040704: done, saving took 1.73 seconds\n",
      "2021-11-29 13:53:08.068567: This epoch took 181.734073 s\n",
      "\n",
      "2021-11-29 13:53:08.073593: \n",
      "epoch:  42\n",
      "2021-11-29 13:55:54.300937: train loss : 0.1522\n",
      "2021-11-29 13:56:06.203212: validation loss: 0.1569\n",
      "2021-11-29 13:56:06.209017: Average global foreground Dice: [0.3179]\n",
      "2021-11-29 13:56:06.214224: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 13:56:06.731433: lr: 0.001704\n",
      "2021-11-29 13:56:06.775187: saving checkpoint...\n",
      "2021-11-29 13:56:08.129074: done, saving took 1.39 seconds\n",
      "2021-11-29 13:56:08.150886: This epoch took 180.072332 s\n",
      "\n",
      "2021-11-29 13:56:08.156366: \n",
      "epoch:  43\n",
      "2021-11-29 13:58:56.024892: train loss : 0.1535\n",
      "2021-11-29 13:59:07.921532: validation loss: 0.1536\n",
      "2021-11-29 13:59:07.927423: Average global foreground Dice: [0.289]\n",
      "2021-11-29 13:59:07.933789: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 13:59:08.457174: lr: 0.001483\n",
      "2021-11-29 13:59:08.462862: This epoch took 180.297139 s\n",
      "\n",
      "2021-11-29 13:59:08.470881: \n",
      "epoch:  44\n",
      "2021-11-29 14:01:54.531893: train loss : 0.1563\n",
      "2021-11-29 14:02:06.549788: validation loss: 0.1576\n",
      "2021-11-29 14:02:06.555747: Average global foreground Dice: [0.304]\n",
      "2021-11-29 14:02:06.561068: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 14:02:07.091498: lr: 0.001259\n",
      "2021-11-29 14:02:07.144555: saving checkpoint...\n",
      "2021-11-29 14:02:08.643137: done, saving took 1.55 seconds\n",
      "2021-11-29 14:02:08.666167: This epoch took 180.189543 s\n",
      "\n",
      "2021-11-29 14:02:08.671446: \n",
      "epoch:  45\n",
      "2021-11-29 14:05:00.799785: train loss : 0.1547\n",
      "2021-11-29 14:05:13.264380: validation loss: 0.1554\n",
      "2021-11-29 14:05:13.272541: Average global foreground Dice: [0.3125]\n",
      "2021-11-29 14:05:13.278134: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 14:05:13.787487: lr: 0.00103\n",
      "2021-11-29 14:05:13.863724: saving checkpoint...\n",
      "2021-11-29 14:05:15.308554: done, saving took 1.52 seconds\n",
      "2021-11-29 14:05:15.331104: This epoch took 186.653995 s\n",
      "\n",
      "2021-11-29 14:05:15.336299: \n",
      "epoch:  46\n",
      "2021-11-29 14:08:10.127799: train loss : 0.1553\n",
      "2021-11-29 14:08:22.565144: validation loss: 0.1533\n",
      "2021-11-29 14:08:22.571201: Average global foreground Dice: [0.2688]\n",
      "2021-11-29 14:08:22.576992: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 14:08:23.101438: lr: 0.000795\n",
      "2021-11-29 14:08:23.107036: This epoch took 187.765985 s\n",
      "\n",
      "2021-11-29 14:08:23.112719: \n",
      "epoch:  47\n",
      "2021-11-29 14:11:10.194947: train loss : 0.1556\n",
      "2021-11-29 14:11:22.181146: validation loss: 0.1571\n",
      "2021-11-29 14:11:22.187356: Average global foreground Dice: [0.3234]\n",
      "2021-11-29 14:11:22.193153: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 14:11:22.715743: lr: 0.000552\n",
      "2021-11-29 14:11:22.720786: This epoch took 179.602765 s\n",
      "\n",
      "2021-11-29 14:11:22.726404: \n",
      "epoch:  48\n",
      "2021-11-29 14:14:11.194510: train loss : 0.1553\n",
      "2021-11-29 14:14:23.090060: validation loss: 0.1564\n",
      "2021-11-29 14:14:23.097512: Average global foreground Dice: [0.3316]\n",
      "2021-11-29 14:14:23.103897: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 14:14:23.646648: lr: 0.000296\n",
      "2021-11-29 14:14:23.690624: saving checkpoint...\n",
      "2021-11-29 14:14:25.160544: done, saving took 1.51 seconds\n",
      "2021-11-29 14:14:25.187711: This epoch took 182.455840 s\n",
      "\n",
      "2021-11-29 14:14:25.192935: \n",
      "epoch:  49\n",
      "2021-11-29 14:17:11.793804: train loss : 0.1564\n",
      "2021-11-29 14:17:23.893286: validation loss: 0.1544\n",
      "2021-11-29 14:17:23.898901: Average global foreground Dice: [0.3056]\n",
      "2021-11-29 14:17:23.904241: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 14:17:24.416803: lr: 0.0\n",
      "2021-11-29 14:17:24.422355: saving scheduled checkpoint file...\n",
      "2021-11-29 14:17:24.467847: saving checkpoint...\n",
      "2021-11-29 14:17:25.650410: done, saving took 1.22 seconds\n",
      "2021-11-29 14:17:25.664664: done\n",
      "2021-11-29 14:17:25.708614: saving checkpoint...\n",
      "2021-11-29 14:17:27.233848: done, saving took 1.56 seconds\n",
      "2021-11-29 14:17:27.258222: This epoch took 182.059556 s\n",
      "\n",
      "2021-11-29 14:17:27.302302: saving checkpoint...\n",
      "2021-11-29 14:17:28.441772: done, saving took 1.18 seconds\n",
      "GGHB_DC68_LJH0_BABA_0002 (2, 57, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "GGHB_DC68_LJH0_BABA_0003 (2, 149, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RALP_0000 (2, 96, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RALP_0001 (2, 145, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "SNUH_DC07_JCW0_RALP_0002 (2, 83, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RALP_0011 (2, 111, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RALP_0020 (2, 213, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "SNUH_DC07_JCW0_RALP_0021 (2, 67, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RALP_0031 (2, 150, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RLPN_0002 (2, 90, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RLPN_0003 (2, 123, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RLPN_0008 (2, 86, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "SNUH_DC07_JCW0_RLPN_0009 (2, 42, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RLPN_0014 (2, 38, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC68_KSJ0_BABA_0001 (2, 38, 343, 502)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC68_LKE0_BABA_0001 (2, 38, 342, 495)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC68_LKE0_BABA_0002 (2, 96, 342, 488)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-29 14:21:30.922595: finished prediction\n",
      "2021-11-29 14:21:30.928438: evaluation of raw predictions\n",
      "2021-11-29 14:21:34.082760: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.18432314036412223\n",
      "after:  0.1837087865404039\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "!nnUNet_train 2d nnUNetTrainerV2_Loss_CE 480 all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.loss_function.nnUNetTrainerV2_Loss_DiceTopK10.nnUNetTrainerV2_Loss_DiceTopK10'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'png'}\n",
      "use_mask_for_norm OrderedDict([(0, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 12, 'num_pool_per_axis': [7, 7], 'patch_size': array([512, 512]), 'median_patient_size_in_voxels': array([ 90, 512, 512]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /tf/temp/nnUNet/nnunet/preprocessed/Task480_GRSR/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "/usr/local/lib/python3.8/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "loading dataset\n",
      "loading all case properties\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-29 14:44:34.609557: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-29 14:44:40.134558: Unable to plot network architecture:\n",
      "2021-11-29 14:44:40.139333: No module named 'hiddenlayer'\n",
      "2021-11-29 14:44:40.217448: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-29 14:44:40.225880: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (1): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (2): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (3): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (4): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (5): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (6): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (4): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (5): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (6): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-29 14:44:40.241517: \n",
      "\n",
      "2021-11-29 14:44:40.314086: \n",
      "epoch:  0\n",
      "2021-11-29 14:48:12.960386: train loss : 0.6494\n",
      "2021-11-29 14:48:30.237618: validation loss: 0.5804\n",
      "2021-11-29 14:48:30.244617: Average global foreground Dice: [0.0055]\n",
      "2021-11-29 14:48:30.250704: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 14:48:30.668302: lr: 0.00982\n",
      "2021-11-29 14:48:30.673073: This epoch took 230.353973 s\n",
      "\n",
      "2021-11-29 14:48:30.678264: \n",
      "epoch:  1\n",
      "2021-11-29 14:51:41.746239: train loss : 0.5802\n",
      "2021-11-29 14:51:58.663528: validation loss: 0.5800\n",
      "2021-11-29 14:51:58.669054: Average global foreground Dice: [0.0106]\n",
      "2021-11-29 14:51:58.673841: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 14:51:59.174830: lr: 0.009639\n",
      "2021-11-29 14:51:59.265813: saving checkpoint...\n",
      "2021-11-29 14:52:01.428743: done, saving took 2.25 seconds\n",
      "2021-11-29 14:52:01.444133: This epoch took 210.759470 s\n",
      "\n",
      "2021-11-29 14:52:01.450607: \n",
      "epoch:  2\n",
      "2021-11-29 14:55:17.923953: train loss : 0.5775\n",
      "2021-11-29 14:55:35.538464: validation loss: 0.5719\n",
      "2021-11-29 14:55:35.544233: Average global foreground Dice: [0.1337]\n",
      "2021-11-29 14:55:35.549284: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 14:55:36.155710: lr: 0.009458\n",
      "2021-11-29 14:55:36.220872: saving checkpoint...\n",
      "2021-11-29 14:55:37.692016: done, saving took 1.53 seconds\n",
      "2021-11-29 14:55:37.717861: This epoch took 216.261661 s\n",
      "\n",
      "2021-11-29 14:55:37.723380: \n",
      "epoch:  3\n",
      "2021-11-29 14:58:55.572226: train loss : 0.5793\n",
      "2021-11-29 14:59:12.433873: validation loss: 0.5696\n",
      "2021-11-29 14:59:12.439022: Average global foreground Dice: [0.0208]\n",
      "2021-11-29 14:59:12.444013: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 14:59:12.948287: lr: 0.009277\n",
      "2021-11-29 14:59:13.028693: saving checkpoint...\n",
      "2021-11-29 14:59:14.514868: done, saving took 1.56 seconds\n",
      "2021-11-29 14:59:14.540935: This epoch took 216.812496 s\n",
      "\n",
      "2021-11-29 14:59:14.545919: \n",
      "epoch:  4\n",
      "2021-11-29 15:02:25.653316: train loss : 0.5805\n",
      "2021-11-29 15:02:42.659574: validation loss: 0.5810\n",
      "2021-11-29 15:02:42.665562: Average global foreground Dice: [0.0033]\n",
      "2021-11-29 15:02:42.670439: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 15:02:43.194885: lr: 0.009095\n",
      "2021-11-29 15:02:43.199385: This epoch took 208.648344 s\n",
      "\n",
      "2021-11-29 15:02:43.203531: \n",
      "epoch:  5\n",
      "2021-11-29 15:06:00.815110: train loss : 0.5790\n",
      "2021-11-29 15:06:18.361659: validation loss: 0.5767\n",
      "2021-11-29 15:06:18.369146: Average global foreground Dice: [0.0298]\n",
      "2021-11-29 15:06:18.375032: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 15:06:18.894470: lr: 0.008913\n",
      "2021-11-29 15:06:18.899786: This epoch took 215.691442 s\n",
      "\n",
      "2021-11-29 15:06:18.906722: \n",
      "epoch:  6\n",
      "2021-11-29 15:09:34.499154: train loss : 0.5753\n",
      "2021-11-29 15:09:51.286977: validation loss: 0.5723\n",
      "2021-11-29 15:09:51.292638: Average global foreground Dice: [0.0469]\n",
      "2021-11-29 15:09:51.297108: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 15:09:51.822664: lr: 0.008731\n",
      "2021-11-29 15:09:51.916607: saving checkpoint...\n",
      "2021-11-29 15:09:54.104861: done, saving took 2.28 seconds\n",
      "2021-11-29 15:09:54.130154: This epoch took 215.218199 s\n",
      "\n",
      "2021-11-29 15:09:54.135807: \n",
      "epoch:  7\n",
      "2021-11-29 15:13:05.554073: train loss : 0.5770\n",
      "2021-11-29 15:13:22.805898: validation loss: 0.5754\n",
      "2021-11-29 15:13:22.811897: Average global foreground Dice: [0.0169]\n",
      "2021-11-29 15:13:22.816926: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 15:13:23.342197: lr: 0.008548\n",
      "2021-11-29 15:13:23.347208: This epoch took 209.205925 s\n",
      "\n",
      "2021-11-29 15:13:23.353902: \n",
      "epoch:  8\n",
      "2021-11-29 15:16:42.220427: train loss : 0.5766\n",
      "2021-11-29 15:16:59.793273: validation loss: 0.5759\n",
      "2021-11-29 15:16:59.799180: Average global foreground Dice: [0.03]\n",
      "2021-11-29 15:16:59.804659: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 15:17:00.313637: lr: 0.008364\n",
      "2021-11-29 15:17:00.404131: saving checkpoint...\n",
      "2021-11-29 15:17:01.902068: done, saving took 1.58 seconds\n",
      "2021-11-29 15:17:01.924656: This epoch took 218.565182 s\n",
      "\n",
      "2021-11-29 15:17:01.930107: \n",
      "epoch:  9\n",
      "2021-11-29 15:20:16.509316: train loss : 0.5781\n",
      "2021-11-29 15:20:33.343873: validation loss: 0.5733\n",
      "2021-11-29 15:20:33.349991: Average global foreground Dice: [0.0187]\n",
      "2021-11-29 15:20:33.355274: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 15:20:33.873766: lr: 0.008181\n",
      "2021-11-29 15:20:33.879049: This epoch took 211.943625 s\n",
      "\n",
      "2021-11-29 15:20:33.884509: \n",
      "epoch:  10\n",
      "2021-11-29 15:23:46.915886: train loss : 0.5770\n",
      "2021-11-29 15:24:04.306201: validation loss: 0.5748\n",
      "2021-11-29 15:24:04.312570: Average global foreground Dice: [0.0015]\n",
      "2021-11-29 15:24:04.321233: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 15:24:04.844623: lr: 0.007996\n",
      "2021-11-29 15:24:04.850051: This epoch took 210.960695 s\n",
      "\n",
      "2021-11-29 15:24:04.855278: \n",
      "epoch:  11\n",
      "2021-11-29 15:27:24.399079: train loss : 0.5777\n",
      "2021-11-29 15:27:42.064568: validation loss: 0.5745\n",
      "2021-11-29 15:27:42.070320: Average global foreground Dice: [0.082]\n",
      "2021-11-29 15:27:42.076834: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 15:27:42.607546: lr: 0.007811\n",
      "2021-11-29 15:27:42.713266: saving checkpoint...\n",
      "2021-11-29 15:27:44.267545: done, saving took 1.65 seconds\n",
      "2021-11-29 15:27:44.291212: This epoch took 219.430917 s\n",
      "\n",
      "2021-11-29 15:27:44.298267: \n",
      "epoch:  12\n",
      "2021-11-29 15:30:57.069967: train loss : 0.5748\n",
      "2021-11-29 15:31:13.997278: validation loss: 0.5761\n",
      "2021-11-29 15:31:14.003187: Average global foreground Dice: [0.0037]\n",
      "2021-11-29 15:31:14.010091: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 15:31:14.563985: lr: 0.007626\n",
      "2021-11-29 15:31:14.569990: This epoch took 210.266098 s\n",
      "\n",
      "2021-11-29 15:31:14.575385: \n",
      "epoch:  13\n",
      "2021-11-29 15:34:26.891355: train loss : 0.5766\n",
      "2021-11-29 15:34:43.655648: validation loss: 0.5713\n",
      "2021-11-29 15:34:43.661406: Average global foreground Dice: [0.0065]\n",
      "2021-11-29 15:34:43.666368: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 15:34:44.256172: lr: 0.00744\n",
      "2021-11-29 15:34:44.261308: This epoch took 209.680569 s\n",
      "\n",
      "2021-11-29 15:34:44.266474: \n",
      "epoch:  14\n",
      "2021-11-29 15:37:55.446891: train loss : 0.5766\n",
      "2021-11-29 15:38:12.595864: validation loss: 0.5755\n",
      "2021-11-29 15:38:12.601949: Average global foreground Dice: [0.0011]\n",
      "2021-11-29 15:38:12.608070: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 15:38:13.134529: lr: 0.007254\n",
      "2021-11-29 15:38:13.140059: This epoch took 208.867419 s\n",
      "\n",
      "2021-11-29 15:38:13.147013: \n",
      "epoch:  15\n",
      "2021-11-29 15:41:23.769001: train loss : 0.5789\n",
      "2021-11-29 15:41:40.701495: validation loss: 0.5763\n",
      "2021-11-29 15:41:40.707441: Average global foreground Dice: [0.0011]\n",
      "2021-11-29 15:41:40.712501: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 15:41:41.246571: lr: 0.007067\n",
      "2021-11-29 15:41:41.252324: This epoch took 208.099880 s\n",
      "\n",
      "2021-11-29 15:41:41.257513: \n",
      "epoch:  16\n",
      "2021-11-29 15:44:53.570356: train loss : 0.5747\n",
      "2021-11-29 15:45:10.387774: validation loss: 0.5684\n",
      "2021-11-29 15:45:10.394114: Average global foreground Dice: [0.005]\n",
      "2021-11-29 15:45:10.399344: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 15:45:10.932553: lr: 0.00688\n",
      "2021-11-29 15:45:10.938373: This epoch took 209.675422 s\n",
      "\n",
      "2021-11-29 15:45:10.944974: \n",
      "epoch:  17\n",
      "2021-11-29 15:48:24.047136: train loss : 0.5764\n",
      "2021-11-29 15:48:41.320699: validation loss: 0.5715\n",
      "2021-11-29 15:48:41.326643: Average global foreground Dice: [0.0003]\n",
      "2021-11-29 15:48:41.331740: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 15:48:41.863185: lr: 0.006692\n",
      "2021-11-29 15:48:41.869320: This epoch took 210.918584 s\n",
      "\n",
      "2021-11-29 15:48:41.874273: \n",
      "epoch:  18\n",
      "2021-11-29 15:52:01.192541: train loss : 0.5777\n",
      "2021-11-29 15:52:18.654454: validation loss: 0.5755\n",
      "2021-11-29 15:52:18.660721: Average global foreground Dice: [0.0001]\n",
      "2021-11-29 15:52:18.666496: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 15:52:19.200418: lr: 0.006504\n",
      "2021-11-29 15:52:19.211051: This epoch took 217.331393 s\n",
      "\n",
      "2021-11-29 15:52:19.218968: \n",
      "epoch:  19\n",
      "2021-11-29 15:55:33.010558: train loss : 0.5779\n",
      "2021-11-29 15:55:49.778220: validation loss: 0.5744\n",
      "2021-11-29 15:55:49.784603: Average global foreground Dice: [0.0004]\n",
      "2021-11-29 15:55:49.790032: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 15:55:50.320860: lr: 0.006314\n",
      "2021-11-29 15:55:50.325815: This epoch took 211.100984 s\n",
      "\n",
      "2021-11-29 15:55:50.331782: \n",
      "epoch:  20\n",
      "2021-11-29 15:59:03.847605: train loss : 0.5765\n",
      "2021-11-29 15:59:21.368741: validation loss: 0.5761\n",
      "2021-11-29 15:59:21.374962: Average global foreground Dice: [0.0003]\n",
      "2021-11-29 15:59:21.380086: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 15:59:21.913899: lr: 0.006125\n",
      "2021-11-29 15:59:21.919433: This epoch took 211.582436 s\n",
      "\n",
      "2021-11-29 15:59:21.925291: \n",
      "epoch:  21\n",
      "2021-11-29 16:02:41.491490: train loss : 0.5773\n",
      "2021-11-29 16:02:59.033713: validation loss: 0.5724\n",
      "2021-11-29 16:02:59.042100: Average global foreground Dice: [0.0074]\n",
      "2021-11-29 16:02:59.047555: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 16:02:59.572677: lr: 0.005934\n",
      "2021-11-29 16:02:59.578574: This epoch took 217.647905 s\n",
      "\n",
      "2021-11-29 16:02:59.584541: \n",
      "epoch:  22\n",
      "2021-11-29 16:06:19.353791: train loss : 0.5752\n",
      "2021-11-29 16:06:36.891469: validation loss: 0.5778\n",
      "2021-11-29 16:06:36.897527: Average global foreground Dice: [0.0121]\n",
      "2021-11-29 16:06:36.905149: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 16:06:37.445866: lr: 0.005743\n",
      "2021-11-29 16:06:37.453020: This epoch took 217.862406 s\n",
      "\n",
      "2021-11-29 16:06:37.459958: \n",
      "epoch:  23\n",
      "2021-11-29 16:09:53.666767: train loss : 0.5768\n",
      "2021-11-29 16:10:10.548511: validation loss: 0.5689\n",
      "2021-11-29 16:10:10.554413: Average global foreground Dice: [0.0]\n",
      "2021-11-29 16:10:10.559917: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 16:10:11.065849: lr: 0.005551\n",
      "2021-11-29 16:10:11.071702: This epoch took 213.605354 s\n",
      "\n",
      "2021-11-29 16:10:11.077537: \n",
      "epoch:  24\n",
      "2021-11-29 16:13:25.038007: train loss : 0.5779\n",
      "2021-11-29 16:13:42.132343: validation loss: 0.5708\n",
      "2021-11-29 16:13:42.139653: Average global foreground Dice: [0.0099]\n",
      "2021-11-29 16:13:42.144519: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 16:13:42.674557: lr: 0.005359\n",
      "2021-11-29 16:13:42.679940: This epoch took 211.597140 s\n",
      "\n",
      "2021-11-29 16:13:42.684762: \n",
      "epoch:  25\n",
      "2021-11-29 16:16:54.738471: train loss : 0.5775\n",
      "2021-11-29 16:17:11.902734: validation loss: 0.5722\n",
      "2021-11-29 16:17:11.908921: Average global foreground Dice: [0.0]\n",
      "2021-11-29 16:17:11.914582: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 16:17:12.455611: lr: 0.005166\n",
      "2021-11-29 16:17:12.461122: This epoch took 209.771178 s\n",
      "\n",
      "2021-11-29 16:17:12.467090: \n",
      "epoch:  26\n",
      "2021-11-29 16:20:30.837003: train loss : 0.5780\n",
      "2021-11-29 16:20:48.303319: validation loss: 0.5749\n",
      "2021-11-29 16:20:48.309120: Average global foreground Dice: [0.0007]\n",
      "2021-11-29 16:20:48.313778: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 16:20:48.845211: lr: 0.004971\n",
      "2021-11-29 16:20:48.850712: This epoch took 216.377816 s\n",
      "\n",
      "2021-11-29 16:20:48.855714: \n",
      "epoch:  27\n",
      "2021-11-29 16:24:08.724515: train loss : 0.5776\n",
      "2021-11-29 16:24:26.254010: validation loss: 0.5714\n",
      "2021-11-29 16:24:26.260387: Average global foreground Dice: [0.0005]\n",
      "2021-11-29 16:24:26.265655: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 16:24:26.794209: lr: 0.004776\n",
      "2021-11-29 16:24:26.799700: This epoch took 217.938278 s\n",
      "\n",
      "2021-11-29 16:24:26.805029: \n",
      "epoch:  28\n",
      "2021-11-29 16:27:46.308738: train loss : 0.5787\n",
      "2021-11-29 16:28:03.938981: validation loss: 0.5705\n",
      "2021-11-29 16:28:03.944469: Average global foreground Dice: [0.0]\n",
      "2021-11-29 16:28:03.949700: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 16:28:04.484461: lr: 0.004581\n",
      "2021-11-29 16:28:04.489996: This epoch took 217.679601 s\n",
      "\n",
      "2021-11-29 16:28:04.495317: \n",
      "epoch:  29\n",
      "2021-11-29 16:31:17.317277: train loss : 0.5768\n",
      "2021-11-29 16:31:34.217296: validation loss: 0.5742\n",
      "2021-11-29 16:31:34.222643: Average global foreground Dice: [0.0001]\n",
      "2021-11-29 16:31:34.227574: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 16:31:34.754146: lr: 0.004384\n",
      "2021-11-29 16:31:34.760817: This epoch took 210.259999 s\n",
      "\n",
      "2021-11-29 16:31:34.766691: \n",
      "epoch:  30\n",
      "2021-11-29 16:34:47.849331: train loss : 0.5744\n",
      "2021-11-29 16:35:04.703905: validation loss: 0.5733\n",
      "2021-11-29 16:35:04.710299: Average global foreground Dice: [0.0002]\n",
      "2021-11-29 16:35:04.715817: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 16:35:05.242823: lr: 0.004186\n",
      "2021-11-29 16:35:05.248482: This epoch took 210.476390 s\n",
      "\n",
      "2021-11-29 16:35:05.254236: \n",
      "epoch:  31\n",
      "2021-11-29 16:38:18.270358: train loss : 0.5767\n",
      "2021-11-29 16:38:35.307922: validation loss: 0.5743\n",
      "2021-11-29 16:38:35.314348: Average global foreground Dice: [0.0]\n",
      "2021-11-29 16:38:35.320152: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 16:38:35.860925: lr: 0.003987\n",
      "2021-11-29 16:38:35.867513: This epoch took 210.607795 s\n",
      "\n",
      "2021-11-29 16:38:35.873177: \n",
      "epoch:  32\n",
      "/tf/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-11-29 16:41:47.171584: train loss : 0.5793\n",
      "2021-11-29 16:42:04.109328: validation loss: 0.5735\n",
      "2021-11-29 16:42:04.116844: Average global foreground Dice: [0.0003]\n",
      "2021-11-29 16:42:04.121458: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 16:42:04.650637: lr: 0.003787\n",
      "2021-11-29 16:42:04.655490: This epoch took 208.777564 s\n",
      "\n",
      "2021-11-29 16:42:04.661176: \n",
      "epoch:  33\n",
      "2021-11-29 16:45:17.851197: train loss : 0.5762\n",
      "2021-11-29 16:45:34.793496: validation loss: 0.5724\n",
      "2021-11-29 16:45:34.800312: Average global foreground Dice: [0.0002]\n",
      "2021-11-29 16:45:34.805652: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 16:45:35.338130: lr: 0.003586\n",
      "2021-11-29 16:45:35.343656: This epoch took 210.676277 s\n",
      "\n",
      "2021-11-29 16:45:35.348981: \n",
      "epoch:  34\n",
      "2021-11-29 16:48:49.762092: train loss : 0.5762\n",
      "2021-11-29 16:49:07.213044: validation loss: 0.5735\n",
      "2021-11-29 16:49:07.218489: Average global foreground Dice: [0.0]\n",
      "2021-11-29 16:49:07.223995: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 16:49:07.759300: lr: 0.003384\n",
      "2021-11-29 16:49:07.765710: This epoch took 212.410935 s\n",
      "\n",
      "2021-11-29 16:49:07.771359: \n",
      "epoch:  35\n",
      "2021-11-29 16:52:27.809130: train loss : 0.5793\n",
      "2021-11-29 16:52:45.330345: validation loss: 0.5725\n",
      "2021-11-29 16:52:45.336723: Average global foreground Dice: [0.0]\n",
      "2021-11-29 16:52:45.342654: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 16:52:45.873368: lr: 0.00318\n",
      "2021-11-29 16:52:45.878981: This epoch took 218.102459 s\n",
      "\n",
      "2021-11-29 16:52:45.884765: \n",
      "epoch:  36\n",
      "2021-11-29 16:55:58.755829: train loss : 0.5789\n",
      "2021-11-29 16:56:15.631516: validation loss: 0.5710\n",
      "2021-11-29 16:56:15.637513: Average global foreground Dice: [0.0012]\n",
      "2021-11-29 16:56:15.642705: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 16:56:16.175496: lr: 0.002975\n",
      "2021-11-29 16:56:16.181638: This epoch took 210.290546 s\n",
      "\n",
      "2021-11-29 16:56:16.187230: \n",
      "epoch:  37\n",
      "2021-11-29 16:59:31.482419: train loss : 0.5775\n",
      "2021-11-29 16:59:49.135166: validation loss: 0.5732\n",
      "2021-11-29 16:59:49.141002: Average global foreground Dice: [0.0]\n",
      "2021-11-29 16:59:49.147545: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 16:59:49.682289: lr: 0.002768\n",
      "2021-11-29 16:59:49.689822: This epoch took 213.497424 s\n",
      "\n",
      "2021-11-29 16:59:49.695553: \n",
      "epoch:  38\n",
      "2021-11-29 17:03:09.332285: train loss : 0.5772\n",
      "2021-11-29 17:03:26.736622: validation loss: 0.5782\n",
      "2021-11-29 17:03:26.742806: Average global foreground Dice: [0.0]\n",
      "2021-11-29 17:03:26.747623: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 17:03:27.262711: lr: 0.00256\n",
      "2021-11-29 17:03:27.268162: This epoch took 217.567105 s\n",
      "\n",
      "2021-11-29 17:03:27.274377: \n",
      "epoch:  39\n",
      "2021-11-29 17:06:39.383712: train loss : 0.5776\n",
      "2021-11-29 17:06:56.452409: validation loss: 0.5733\n",
      "2021-11-29 17:06:56.458033: Average global foreground Dice: [0.0001]\n",
      "2021-11-29 17:06:56.463127: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 17:06:56.993139: lr: 0.002349\n",
      "2021-11-29 17:06:56.999327: This epoch took 209.719557 s\n",
      "\n",
      "2021-11-29 17:06:57.012026: \n",
      "epoch:  40\n",
      "2021-11-29 17:10:10.305224: train loss : 0.5766\n",
      "2021-11-29 17:10:27.232705: validation loss: 0.5727\n",
      "2021-11-29 17:10:27.239290: Average global foreground Dice: [0.0021]\n",
      "2021-11-29 17:10:27.245339: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 17:10:27.775661: lr: 0.002137\n",
      "2021-11-29 17:10:27.781458: This epoch took 210.764193 s\n",
      "\n",
      "2021-11-29 17:10:27.787140: \n",
      "epoch:  41\n",
      "2021-11-29 17:13:41.640184: train loss : 0.5764\n",
      "2021-11-29 17:13:58.558131: validation loss: 0.5713\n",
      "2021-11-29 17:13:58.564443: Average global foreground Dice: [0.0]\n",
      "2021-11-29 17:13:58.569567: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 17:13:59.093697: lr: 0.001922\n",
      "2021-11-29 17:13:59.100457: This epoch took 211.307950 s\n",
      "\n",
      "2021-11-29 17:13:59.106007: \n",
      "epoch:  42\n",
      "2021-11-29 17:17:10.879253: train loss : 0.5784\n",
      "2021-11-29 17:17:28.074395: validation loss: 0.5751\n",
      "2021-11-29 17:17:28.079742: Average global foreground Dice: [0.0001]\n",
      "2021-11-29 17:17:28.087355: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 17:17:28.610639: lr: 0.001704\n",
      "2021-11-29 17:17:28.617148: This epoch took 209.505627 s\n",
      "\n",
      "2021-11-29 17:17:28.623196: \n",
      "epoch:  43\n",
      "2021-11-29 17:20:41.415274: train loss : 0.5755\n",
      "2021-11-29 17:20:58.274059: validation loss: 0.5737\n",
      "2021-11-29 17:20:58.280083: Average global foreground Dice: [0.0]\n",
      "2021-11-29 17:20:58.285124: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 17:20:58.816366: lr: 0.001483\n",
      "2021-11-29 17:20:58.822876: This epoch took 210.192565 s\n",
      "\n",
      "2021-11-29 17:20:58.827652: \n",
      "epoch:  44\n",
      "2021-11-29 17:24:14.047669: train loss : 0.5760\n",
      "2021-11-29 17:24:31.819731: validation loss: 0.5703\n",
      "2021-11-29 17:24:31.826220: Average global foreground Dice: [0.0]\n",
      "2021-11-29 17:24:31.831760: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 17:24:32.358873: lr: 0.001259\n",
      "2021-11-29 17:24:32.364769: This epoch took 213.530900 s\n",
      "\n",
      "2021-11-29 17:24:32.369957: \n",
      "epoch:  45\n",
      "2021-11-29 17:27:52.002545: train loss : 0.5770\n",
      "2021-11-29 17:28:09.596209: validation loss: 0.5711\n",
      "2021-11-29 17:28:09.602831: Average global foreground Dice: [0.0001]\n",
      "2021-11-29 17:28:09.608514: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 17:28:10.133295: lr: 0.00103\n",
      "2021-11-29 17:28:10.138930: This epoch took 217.763220 s\n",
      "\n",
      "2021-11-29 17:28:10.144275: \n",
      "epoch:  46\n",
      "2021-11-29 17:31:21.987854: train loss : 0.5780\n",
      "2021-11-29 17:31:38.978740: validation loss: 0.5721\n",
      "2021-11-29 17:31:38.985096: Average global foreground Dice: [0.0]\n",
      "2021-11-29 17:31:38.991406: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 17:31:39.513533: lr: 0.000795\n",
      "2021-11-29 17:31:39.519421: This epoch took 209.368502 s\n",
      "\n",
      "2021-11-29 17:31:39.526335: \n",
      "epoch:  47\n",
      "2021-11-29 17:34:56.307679: train loss : 0.5770\n",
      "2021-11-29 17:35:14.014655: validation loss: 0.5741\n",
      "2021-11-29 17:35:14.019666: Average global foreground Dice: [0.0]\n",
      "2021-11-29 17:35:14.025342: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 17:35:14.549999: lr: 0.000552\n",
      "2021-11-29 17:35:14.555464: This epoch took 215.023574 s\n",
      "\n",
      "2021-11-29 17:35:14.560772: \n",
      "epoch:  48\n",
      "2021-11-29 17:38:34.180425: train loss : 0.5762\n",
      "2021-11-29 17:38:51.928127: validation loss: 0.5713\n",
      "2021-11-29 17:38:51.935596: Average global foreground Dice: [0.0001]\n",
      "2021-11-29 17:38:51.941340: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 17:38:52.528867: lr: 0.000296\n",
      "2021-11-29 17:38:52.534282: This epoch took 217.968044 s\n",
      "\n",
      "2021-11-29 17:38:52.540364: \n",
      "epoch:  49\n",
      "2021-11-29 17:42:12.575685: train loss : 0.5776\n",
      "2021-11-29 17:42:30.285263: validation loss: 0.5705\n",
      "2021-11-29 17:42:30.290798: Average global foreground Dice: [0.0001]\n",
      "2021-11-29 17:42:30.297042: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 17:42:30.829032: lr: 0.0\n",
      "2021-11-29 17:42:30.834142: saving scheduled checkpoint file...\n",
      "2021-11-29 17:42:30.877262: saving checkpoint...\n",
      "2021-11-29 17:42:31.992063: done, saving took 1.15 seconds\n",
      "2021-11-29 17:42:32.009626: done\n",
      "2021-11-29 17:42:32.015491: This epoch took 219.469486 s\n",
      "\n",
      "2021-11-29 17:42:32.059565: saving checkpoint...\n",
      "2021-11-29 17:42:33.147853: done, saving took 1.13 seconds\n",
      "GGHB_DC68_LJH0_BABA_0002 (2, 57, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "GGHB_DC68_LJH0_BABA_0003 (2, 149, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RALP_0000 (2, 96, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RALP_0001 (2, 145, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "SNUH_DC07_JCW0_RALP_0002 (2, 83, 512, 512)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RALP_0011 (2, 111, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RALP_0020 (2, 213, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "SNUH_DC07_JCW0_RALP_0021 (2, 67, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RALP_0031 (2, 150, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RLPN_0002 (2, 90, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RLPN_0003 (2, 123, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RLPN_0008 (2, 86, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "SNUH_DC07_JCW0_RLPN_0009 (2, 42, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RLPN_0014 (2, 38, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC68_KSJ0_BABA_0001 (2, 38, 343, 502)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC68_LKE0_BABA_0001 (2, 38, 342, 495)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC68_LKE0_BABA_0002 (2, 96, 342, 488)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-29 17:46:38.187996: finished prediction\n",
      "2021-11-29 17:46:38.193190: evaluation of raw predictions\n",
      "2021-11-29 17:46:41.286440: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.003699787469078019\n",
      "after:  0.00045329167535791085\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "!nnUNet_train 2d nnUNetTrainerV2_Loss_DiceTopK10 480 all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  None\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'png'}\n",
      "use_mask_for_norm OrderedDict([(0, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 12, 'num_pool_per_axis': [7, 7], 'patch_size': array([512, 512]), 'median_patient_size_in_voxels': array([ 90, 512, 512]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /tf/temp/nnUNet/nnunet/preprocessed/Task480_GRSR/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/nnUNet_train\", line 33, in <module>\n",
      "    sys.exit(load_entry_point('nnunet', 'console_scripts', 'nnUNet_train')())\n",
      "  File \"/tf/backup/nnUNet/nnunet/run/run_training.py\", line 140, in main\n",
      "    raise RuntimeError(\"Could not find trainer class in nnunet.training.network_training\")\n",
      "RuntimeError: Could not find trainer class in nnunet.training.network_training\n"
     ]
    }
   ],
   "source": [
    "!nnUNet_train 2d nnUNetTrainerV2_focalLoss 480 all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.loss_function.nnUNetTrainerV2_Loss_MCC.nnUNetTrainerV2_Loss_MCC'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'png'}\n",
      "use_mask_for_norm OrderedDict([(0, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 12, 'num_pool_per_axis': [7, 7], 'patch_size': array([512, 512]), 'median_patient_size_in_voxels': array([ 90, 512, 512]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /tf/temp/nnUNet/nnunet/preprocessed/Task480_GRSR/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-29 17:47:27.913282: lr: 0.001\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-29 17:47:34.440106: Unable to plot network architecture:\n",
      "2021-11-29 17:47:34.513606: No module named 'hiddenlayer'\n",
      "2021-11-29 17:47:34.609133: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-29 17:47:34.615172: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (1): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (2): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (3): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (4): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (5): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (6): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (4): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (5): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (6): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-29 17:47:34.625837: \n",
      "\n",
      "2021-11-29 17:47:34.636103: \n",
      "epoch:  0\n",
      "2021-11-29 17:50:46.030600: train loss : -0.0227\n",
      "2021-11-29 17:50:59.043600: validation loss: -0.0495\n",
      "2021-11-29 17:50:59.048844: Average global foreground Dice: [0.142]\n",
      "2021-11-29 17:50:59.053879: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 17:50:59.478290: lr: 0.000982\n",
      "2021-11-29 17:50:59.483768: This epoch took 204.774849 s\n",
      "\n",
      "2021-11-29 17:50:59.488680: \n",
      "epoch:  1\n",
      "2021-11-29 17:53:54.822048: train loss : -0.0785\n",
      "2021-11-29 17:54:07.818853: validation loss: -0.1006\n",
      "2021-11-29 17:54:07.826572: Average global foreground Dice: [0.1651]\n",
      "2021-11-29 17:54:07.832596: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 17:54:08.348480: lr: 0.000964\n",
      "2021-11-29 17:54:08.459793: saving checkpoint...\n",
      "2021-11-29 17:54:09.600626: done, saving took 1.25 seconds\n",
      "2021-11-29 17:54:09.619388: This epoch took 190.125643 s\n",
      "\n",
      "2021-11-29 17:54:09.624809: \n",
      "epoch:  2\n",
      "2021-11-29 17:57:02.568758: train loss : -0.1177\n",
      "2021-11-29 17:57:15.754831: validation loss: -0.1393\n",
      "2021-11-29 17:57:15.762629: Average global foreground Dice: [0.1839]\n",
      "2021-11-29 17:57:15.767328: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 17:57:16.388449: lr: 0.000946\n",
      "2021-11-29 17:57:16.486856: saving checkpoint...\n",
      "2021-11-29 17:57:17.952444: done, saving took 1.56 seconds\n",
      "2021-11-29 17:57:17.979827: This epoch took 188.350290 s\n",
      "\n",
      "2021-11-29 17:57:17.984817: \n",
      "epoch:  3\n",
      "2021-11-29 18:00:16.955901: train loss : -0.1625\n",
      "2021-11-29 18:00:30.573543: validation loss: -0.2057\n",
      "2021-11-29 18:00:30.579560: Average global foreground Dice: [0.2243]\n",
      "2021-11-29 18:00:30.585030: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 18:00:31.090788: lr: 0.000928\n",
      "2021-11-29 18:00:31.164837: saving checkpoint...\n",
      "2021-11-29 18:00:32.728746: done, saving took 1.63 seconds\n",
      "2021-11-29 18:00:32.754846: This epoch took 194.765529 s\n",
      "\n",
      "2021-11-29 18:00:32.760334: \n",
      "epoch:  4\n",
      "2021-11-29 18:03:33.346115: train loss : -0.2322\n",
      "2021-11-29 18:03:46.540996: validation loss: -0.2912\n",
      "2021-11-29 18:03:46.547069: Average global foreground Dice: [0.3192]\n",
      "2021-11-29 18:03:46.552836: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 18:03:47.071888: lr: 0.00091\n",
      "2021-11-29 18:03:47.159376: saving checkpoint...\n",
      "2021-11-29 18:03:48.645061: done, saving took 1.57 seconds\n",
      "2021-11-29 18:03:48.672197: This epoch took 195.907420 s\n",
      "\n",
      "2021-11-29 18:03:48.679141: \n",
      "epoch:  5\n",
      "2021-11-29 18:06:41.770325: train loss : -0.2787\n",
      "2021-11-29 18:06:54.917582: validation loss: -0.3406\n",
      "2021-11-29 18:06:54.923857: Average global foreground Dice: [0.3574]\n",
      "2021-11-29 18:06:54.928469: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 18:06:55.445848: lr: 0.000891\n",
      "2021-11-29 18:06:55.532871: saving checkpoint...\n",
      "2021-11-29 18:06:56.999273: done, saving took 1.55 seconds\n",
      "2021-11-29 18:06:57.024691: This epoch took 188.340260 s\n",
      "\n",
      "2021-11-29 18:06:57.030085: \n",
      "epoch:  6\n",
      "2021-11-29 18:09:51.557558: train loss : -0.3045\n",
      "2021-11-29 18:10:04.472993: validation loss: -0.3327\n",
      "2021-11-29 18:10:04.479145: Average global foreground Dice: [0.3568]\n",
      "2021-11-29 18:10:04.485290: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 18:10:05.023841: lr: 0.000873\n",
      "2021-11-29 18:10:05.109303: saving checkpoint...\n",
      "2021-11-29 18:10:07.134765: done, saving took 2.11 seconds\n",
      "2021-11-29 18:10:07.163327: This epoch took 190.128041 s\n",
      "\n",
      "2021-11-29 18:10:07.168168: \n",
      "epoch:  7\n",
      "2021-11-29 18:13:01.297567: train loss : -0.3233\n",
      "2021-11-29 18:13:14.640955: validation loss: -0.3698\n",
      "2021-11-29 18:13:14.647024: Average global foreground Dice: [0.3979]\n",
      "2021-11-29 18:13:14.652868: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 18:13:15.160710: lr: 0.000855\n",
      "2021-11-29 18:13:15.235297: saving checkpoint...\n",
      "2021-11-29 18:13:16.700168: done, saving took 1.53 seconds\n",
      "2021-11-29 18:13:16.725275: This epoch took 189.551110 s\n",
      "\n",
      "2021-11-29 18:13:16.730745: \n",
      "epoch:  8\n",
      "2021-11-29 18:16:09.933138: train loss : -0.3361\n",
      "2021-11-29 18:16:23.057391: validation loss: -0.3742\n",
      "2021-11-29 18:16:23.063331: Average global foreground Dice: [0.3966]\n",
      "2021-11-29 18:16:23.068775: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 18:16:23.577211: lr: 0.000836\n",
      "2021-11-29 18:16:23.652234: saving checkpoint...\n",
      "2021-11-29 18:16:25.305442: done, saving took 1.72 seconds\n",
      "2021-11-29 18:16:25.331587: This epoch took 188.596258 s\n",
      "\n",
      "2021-11-29 18:16:25.336456: \n",
      "epoch:  9\n",
      "2021-11-29 18:19:20.652676: train loss : -0.3521\n",
      "2021-11-29 18:19:33.655110: validation loss: -0.3700\n",
      "2021-11-29 18:19:33.662094: Average global foreground Dice: [0.3936]\n",
      "2021-11-29 18:19:33.668741: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 18:19:34.174059: lr: 0.000818\n",
      "2021-11-29 18:19:34.263422: saving checkpoint...\n",
      "2021-11-29 18:19:35.749323: done, saving took 1.57 seconds\n",
      "2021-11-29 18:19:35.777478: This epoch took 190.436677 s\n",
      "\n",
      "2021-11-29 18:19:35.782982: \n",
      "epoch:  10\n",
      "2021-11-29 18:22:29.527541: train loss : -0.3661\n",
      "2021-11-29 18:22:42.725101: validation loss: -0.3899\n",
      "2021-11-29 18:22:42.731267: Average global foreground Dice: [0.4199]\n",
      "2021-11-29 18:22:42.736863: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 18:22:43.235355: lr: 0.0008\n",
      "2021-11-29 18:22:43.326283: saving checkpoint...\n",
      "2021-11-29 18:22:44.686794: done, saving took 1.45 seconds\n",
      "2021-11-29 18:22:44.713371: This epoch took 188.924128 s\n",
      "\n",
      "2021-11-29 18:22:44.719406: \n",
      "epoch:  11\n",
      "2021-11-29 18:25:45.033818: train loss : -0.3610\n",
      "2021-11-29 18:25:58.584191: validation loss: -0.3851\n",
      "2021-11-29 18:25:58.590146: Average global foreground Dice: [0.4161]\n",
      "2021-11-29 18:25:58.595646: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 18:25:59.100678: lr: 0.000781\n",
      "2021-11-29 18:25:59.193318: saving checkpoint...\n",
      "2021-11-29 18:26:00.525266: done, saving took 1.42 seconds\n",
      "2021-11-29 18:26:00.553375: This epoch took 195.827658 s\n",
      "\n",
      "2021-11-29 18:26:00.559200: \n",
      "epoch:  12\n",
      "2021-11-29 18:28:59.519822: train loss : -0.3711\n",
      "2021-11-29 18:29:12.553881: validation loss: -0.3949\n",
      "2021-11-29 18:29:12.561667: Average global foreground Dice: [0.4186]\n",
      "2021-11-29 18:29:12.567546: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 18:29:13.097483: lr: 0.000763\n",
      "2021-11-29 18:29:13.188231: saving checkpoint...\n",
      "2021-11-29 18:29:14.870134: done, saving took 1.77 seconds\n",
      "2021-11-29 18:29:14.893273: This epoch took 194.328589 s\n",
      "\n",
      "2021-11-29 18:29:14.897971: \n",
      "epoch:  13\n",
      "2021-11-29 18:32:08.297866: train loss : -0.3780\n",
      "2021-11-29 18:32:21.504837: validation loss: -0.3774\n",
      "2021-11-29 18:32:21.510363: Average global foreground Dice: [0.4108]\n",
      "2021-11-29 18:32:21.516119: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 18:32:22.030948: lr: 0.000744\n",
      "2021-11-29 18:32:22.106295: saving checkpoint...\n",
      "2021-11-29 18:32:23.530276: done, saving took 1.49 seconds\n",
      "2021-11-29 18:32:23.556508: This epoch took 188.652730 s\n",
      "\n",
      "2021-11-29 18:32:23.562288: \n",
      "epoch:  14\n",
      "2021-11-29 18:35:17.836573: train loss : -0.3796\n",
      "2021-11-29 18:35:30.839540: validation loss: -0.3890\n",
      "2021-11-29 18:35:30.846237: Average global foreground Dice: [0.4209]\n",
      "2021-11-29 18:35:30.851798: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 18:35:31.425294: lr: 0.000725\n",
      "2021-11-29 18:35:31.468403: saving checkpoint...\n",
      "2021-11-29 18:35:32.955346: done, saving took 1.52 seconds\n",
      "2021-11-29 18:35:32.974829: This epoch took 189.407892 s\n",
      "\n",
      "2021-11-29 18:35:32.980006: \n",
      "epoch:  15\n",
      "2021-11-29 18:38:27.427420: train loss : -0.3802\n",
      "2021-11-29 18:38:40.561267: validation loss: -0.3970\n",
      "2021-11-29 18:38:40.567114: Average global foreground Dice: [0.4243]\n",
      "2021-11-29 18:38:40.571960: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 18:38:41.075361: lr: 0.000707\n",
      "2021-11-29 18:38:41.119012: saving checkpoint...\n",
      "2021-11-29 18:38:42.451153: done, saving took 1.37 seconds\n",
      "2021-11-29 18:38:42.469804: This epoch took 189.484852 s\n",
      "\n",
      "2021-11-29 18:38:42.475177: \n",
      "epoch:  16\n",
      "2021-11-29 18:41:35.361729: train loss : -0.3852\n",
      "2021-11-29 18:41:48.500672: validation loss: -0.4018\n",
      "2021-11-29 18:41:48.506381: Average global foreground Dice: [0.4324]\n",
      "2021-11-29 18:41:48.511766: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 18:41:49.008509: lr: 0.000688\n",
      "2021-11-29 18:41:49.052093: saving checkpoint...\n",
      "2021-11-29 18:41:50.488348: done, saving took 1.47 seconds\n",
      "2021-11-29 18:41:50.509702: This epoch took 188.028811 s\n",
      "\n",
      "2021-11-29 18:41:50.515106: \n",
      "epoch:  17\n",
      "2021-11-29 18:44:45.435150: train loss : -0.3855\n",
      "2021-11-29 18:44:58.463600: validation loss: -0.4051\n",
      "2021-11-29 18:44:58.471431: Average global foreground Dice: [0.4336]\n",
      "2021-11-29 18:44:58.476784: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 18:44:58.990178: lr: 0.000669\n",
      "2021-11-29 18:44:59.033957: saving checkpoint...\n",
      "2021-11-29 18:45:00.546046: done, saving took 1.55 seconds\n",
      "2021-11-29 18:45:00.570529: This epoch took 190.049717 s\n",
      "\n",
      "2021-11-29 18:45:00.576067: \n",
      "epoch:  18\n",
      "2021-11-29 18:47:55.155652: train loss : -0.3908\n",
      "2021-11-29 18:48:08.499841: validation loss: -0.4033\n",
      "2021-11-29 18:48:08.505691: Average global foreground Dice: [0.434]\n",
      "2021-11-29 18:48:08.510969: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 18:48:09.008655: lr: 0.00065\n",
      "2021-11-29 18:48:09.077975: saving checkpoint...\n",
      "2021-11-29 18:48:10.429235: done, saving took 1.42 seconds\n",
      "2021-11-29 18:48:10.451078: This epoch took 189.870053 s\n",
      "\n",
      "2021-11-29 18:48:10.456576: \n",
      "epoch:  19\n",
      "2021-11-29 18:51:03.812282: train loss : -0.3883\n",
      "2021-11-29 18:51:16.916807: validation loss: -0.4028\n",
      "2021-11-29 18:51:16.923288: Average global foreground Dice: [0.4304]\n",
      "2021-11-29 18:51:16.928710: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 18:51:17.460286: lr: 0.000631\n",
      "2021-11-29 18:51:17.541584: saving checkpoint...\n",
      "2021-11-29 18:51:19.152458: done, saving took 1.69 seconds\n",
      "2021-11-29 18:51:19.174119: This epoch took 188.712713 s\n",
      "\n",
      "2021-11-29 18:51:19.178995: \n",
      "epoch:  20\n",
      "2021-11-29 18:54:14.540763: train loss : -0.3993\n",
      "2021-11-29 18:54:27.545048: validation loss: -0.3947\n",
      "2021-11-29 18:54:27.550877: Average global foreground Dice: [0.4251]\n",
      "2021-11-29 18:54:27.557103: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 18:54:28.065474: lr: 0.000612\n",
      "2021-11-29 18:54:28.109391: saving checkpoint...\n",
      "2021-11-29 18:54:29.521472: done, saving took 1.45 seconds\n",
      "2021-11-29 18:54:29.542198: This epoch took 190.358425 s\n",
      "\n",
      "2021-11-29 18:54:29.547037: \n",
      "epoch:  21\n",
      "2021-11-29 18:57:22.370559: train loss : -0.3965\n",
      "2021-11-29 18:57:35.551497: validation loss: -0.4134\n",
      "2021-11-29 18:57:35.557441: Average global foreground Dice: [0.4337]\n",
      "2021-11-29 18:57:35.562913: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 18:57:36.054431: lr: 0.000593\n",
      "2021-11-29 18:57:36.097630: saving checkpoint...\n",
      "2021-11-29 18:57:37.591756: done, saving took 1.53 seconds\n",
      "2021-11-29 18:57:37.615477: This epoch took 188.063539 s\n",
      "\n",
      "2021-11-29 18:57:37.620537: \n",
      "epoch:  22\n",
      "2021-11-29 19:00:31.222623: train loss : -0.3982\n",
      "2021-11-29 19:00:44.248721: validation loss: -0.4137\n",
      "2021-11-29 19:00:44.255042: Average global foreground Dice: [0.4412]\n",
      "2021-11-29 19:00:44.259925: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 19:00:44.746610: lr: 0.000574\n",
      "2021-11-29 19:00:44.790421: saving checkpoint...\n",
      "2021-11-29 19:00:46.093774: done, saving took 1.34 seconds\n",
      "2021-11-29 19:00:46.114103: This epoch took 188.488598 s\n",
      "\n",
      "2021-11-29 19:00:46.118960: \n",
      "epoch:  23\n",
      "2021-11-29 19:03:40.907564: train loss : -0.4010\n",
      "2021-11-29 19:03:53.952932: validation loss: -0.4011\n",
      "2021-11-29 19:03:53.958627: Average global foreground Dice: [0.4285]\n",
      "2021-11-29 19:03:53.964132: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 19:03:54.456015: lr: 0.000555\n",
      "2021-11-29 19:03:54.499896: saving checkpoint...\n",
      "2021-11-29 19:03:55.858315: done, saving took 1.40 seconds\n",
      "2021-11-29 19:03:55.878017: This epoch took 189.753176 s\n",
      "\n",
      "2021-11-29 19:03:55.883019: \n",
      "epoch:  24\n",
      "/tf/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-11-29 19:06:48.610724: train loss : -0.4111\n",
      "2021-11-29 19:07:01.805353: validation loss: -0.4052\n",
      "2021-11-29 19:07:01.811299: Average global foreground Dice: [0.4338]\n",
      "2021-11-29 19:07:01.816559: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 19:07:02.313499: lr: 0.000536\n",
      "2021-11-29 19:07:02.358030: saving checkpoint...\n",
      "2021-11-29 19:07:03.688993: done, saving took 1.37 seconds\n",
      "2021-11-29 19:07:03.709976: This epoch took 187.821969 s\n",
      "\n",
      "2021-11-29 19:07:03.715376: \n",
      "epoch:  25\n",
      "2021-11-29 19:09:58.651568: train loss : -0.3993\n",
      "2021-11-29 19:10:11.664690: validation loss: -0.4109\n",
      "2021-11-29 19:10:11.670200: Average global foreground Dice: [0.4363]\n",
      "2021-11-29 19:10:11.675183: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 19:10:12.233421: lr: 0.000517\n",
      "2021-11-29 19:10:12.275915: saving checkpoint...\n",
      "2021-11-29 19:10:13.639201: done, saving took 1.40 seconds\n",
      "2021-11-29 19:10:13.658319: This epoch took 189.937838 s\n",
      "\n",
      "2021-11-29 19:10:13.663444: \n",
      "epoch:  26\n",
      "2021-11-29 19:13:08.217871: train loss : -0.3920\n",
      "2021-11-29 19:13:21.575255: validation loss: -0.4087\n",
      "2021-11-29 19:13:21.580900: Average global foreground Dice: [0.4367]\n",
      "2021-11-29 19:13:21.586602: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 19:13:22.083164: lr: 0.000497\n",
      "2021-11-29 19:13:22.126814: saving checkpoint...\n",
      "2021-11-29 19:13:23.405667: done, saving took 1.32 seconds\n",
      "2021-11-29 19:13:23.424930: This epoch took 189.756050 s\n",
      "\n",
      "2021-11-29 19:13:23.430267: \n",
      "epoch:  27\n",
      "2021-11-29 19:16:24.702842: train loss : -0.3964\n",
      "2021-11-29 19:16:38.280795: validation loss: -0.4190\n",
      "2021-11-29 19:16:38.286369: Average global foreground Dice: [0.4475]\n",
      "2021-11-29 19:16:38.292065: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 19:16:38.808508: lr: 0.000478\n",
      "2021-11-29 19:16:38.852871: saving checkpoint...\n",
      "2021-11-29 19:16:40.198230: done, saving took 1.38 seconds\n",
      "2021-11-29 19:16:40.218931: This epoch took 196.783832 s\n",
      "\n",
      "2021-11-29 19:16:40.224085: \n",
      "epoch:  28\n",
      "2021-11-29 19:19:38.432405: train loss : -0.4060\n",
      "2021-11-29 19:19:51.461851: validation loss: -0.3942\n",
      "2021-11-29 19:19:51.467481: Average global foreground Dice: [0.4199]\n",
      "2021-11-29 19:19:51.472417: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 19:19:51.965729: lr: 0.000458\n",
      "2021-11-29 19:19:52.009794: saving checkpoint...\n",
      "2021-11-29 19:19:53.596848: done, saving took 1.63 seconds\n",
      "2021-11-29 19:19:53.616677: This epoch took 193.387647 s\n",
      "\n",
      "2021-11-29 19:19:53.622067: \n",
      "epoch:  29\n",
      "2021-11-29 19:22:47.645434: train loss : -0.4053\n",
      "2021-11-29 19:23:00.885630: validation loss: -0.4097\n",
      "2021-11-29 19:23:00.891745: Average global foreground Dice: [0.441]\n",
      "2021-11-29 19:23:00.896172: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 19:23:01.395125: lr: 0.000438\n",
      "2021-11-29 19:23:01.438851: saving checkpoint...\n",
      "2021-11-29 19:23:02.827654: done, saving took 1.43 seconds\n",
      "2021-11-29 19:23:02.847387: This epoch took 189.220754 s\n",
      "\n",
      "2021-11-29 19:23:02.852256: \n",
      "epoch:  30\n",
      "2021-11-29 19:26:03.767137: train loss : -0.4034\n",
      "2021-11-29 19:26:17.376623: validation loss: -0.4278\n",
      "2021-11-29 19:26:17.382763: Average global foreground Dice: [0.4513]\n",
      "2021-11-29 19:26:17.388723: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 19:26:17.888122: lr: 0.000419\n",
      "2021-11-29 19:26:17.931207: saving checkpoint...\n",
      "2021-11-29 19:26:19.454766: done, saving took 1.56 seconds\n",
      "2021-11-29 19:26:19.476731: This epoch took 196.619871 s\n",
      "\n",
      "2021-11-29 19:26:19.481848: \n",
      "epoch:  31\n",
      "2021-11-29 19:29:20.829774: train loss : -0.4063\n",
      "2021-11-29 19:29:34.494543: validation loss: -0.3969\n",
      "2021-11-29 19:29:34.499649: Average global foreground Dice: [0.4225]\n",
      "2021-11-29 19:29:34.504354: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 19:29:34.998153: lr: 0.000399\n",
      "2021-11-29 19:29:35.041884: saving checkpoint...\n",
      "2021-11-29 19:29:36.465209: done, saving took 1.46 seconds\n",
      "2021-11-29 19:29:36.483947: This epoch took 196.997289 s\n",
      "\n",
      "2021-11-29 19:29:36.489739: \n",
      "epoch:  32\n",
      "2021-11-29 19:32:38.765980: train loss : -0.4061\n",
      "2021-11-29 19:32:52.355062: validation loss: -0.4242\n",
      "2021-11-29 19:32:52.360560: Average global foreground Dice: [0.4533]\n",
      "2021-11-29 19:32:52.366158: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 19:32:52.868761: lr: 0.000379\n",
      "2021-11-29 19:32:52.912445: saving checkpoint...\n",
      "2021-11-29 19:32:54.371875: done, saving took 1.50 seconds\n",
      "2021-11-29 19:32:54.390380: This epoch took 197.895341 s\n",
      "\n",
      "2021-11-29 19:32:54.395716: \n",
      "epoch:  33\n",
      "2021-11-29 19:35:48.967440: train loss : -0.4043\n",
      "2021-11-29 19:36:02.030445: validation loss: -0.4065\n",
      "2021-11-29 19:36:02.035928: Average global foreground Dice: [0.4345]\n",
      "2021-11-29 19:36:02.042025: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 19:36:02.545198: lr: 0.000359\n",
      "2021-11-29 19:36:02.588979: saving checkpoint...\n",
      "2021-11-29 19:36:03.958590: done, saving took 1.41 seconds\n",
      "2021-11-29 19:36:03.977763: This epoch took 189.576954 s\n",
      "\n",
      "2021-11-29 19:36:03.982612: \n",
      "epoch:  34\n",
      "2021-11-29 19:39:00.391680: train loss : -0.4094\n",
      "2021-11-29 19:39:13.921977: validation loss: -0.4155\n",
      "2021-11-29 19:39:13.927494: Average global foreground Dice: [0.4469]\n",
      "2021-11-29 19:39:13.932079: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 19:39:14.433005: lr: 0.000338\n",
      "2021-11-29 19:39:14.476664: saving checkpoint...\n",
      "2021-11-29 19:39:16.046326: done, saving took 1.61 seconds\n",
      "2021-11-29 19:39:16.064339: This epoch took 192.076288 s\n",
      "\n",
      "2021-11-29 19:39:16.069713: \n",
      "epoch:  35\n",
      "2021-11-29 19:42:17.296680: train loss : -0.4106\n",
      "2021-11-29 19:42:30.819581: validation loss: -0.4198\n",
      "2021-11-29 19:42:30.825739: Average global foreground Dice: [0.4482]\n",
      "2021-11-29 19:42:30.831042: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 19:42:31.331487: lr: 0.000318\n",
      "2021-11-29 19:42:31.374108: saving checkpoint...\n",
      "2021-11-29 19:42:32.676375: done, saving took 1.34 seconds\n",
      "2021-11-29 19:42:32.695276: This epoch took 196.619385 s\n",
      "\n",
      "2021-11-29 19:42:32.700891: \n",
      "epoch:  36\n",
      "2021-11-29 19:45:34.027143: train loss : -0.4151\n",
      "2021-11-29 19:45:47.665163: validation loss: -0.4210\n",
      "2021-11-29 19:45:47.672846: Average global foreground Dice: [0.4509]\n",
      "2021-11-29 19:45:47.677192: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 19:45:48.248915: lr: 0.000297\n",
      "2021-11-29 19:45:48.292656: saving checkpoint...\n",
      "2021-11-29 19:45:49.667463: done, saving took 1.41 seconds\n",
      "2021-11-29 19:45:49.688869: This epoch took 196.982405 s\n",
      "\n",
      "2021-11-29 19:45:49.693852: \n",
      "epoch:  37\n",
      "2021-11-29 19:48:50.078193: train loss : -0.4127\n",
      "2021-11-29 19:49:03.168363: validation loss: -0.4333\n",
      "2021-11-29 19:49:03.174878: Average global foreground Dice: [0.4604]\n",
      "2021-11-29 19:49:03.180401: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 19:49:03.670119: lr: 0.000277\n",
      "2021-11-29 19:49:03.713262: saving checkpoint...\n",
      "2021-11-29 19:49:05.062237: done, saving took 1.39 seconds\n",
      "2021-11-29 19:49:05.082194: This epoch took 195.382845 s\n",
      "\n",
      "2021-11-29 19:49:05.087831: \n",
      "epoch:  38\n",
      "2021-11-29 19:51:58.193128: train loss : -0.4150\n",
      "2021-11-29 19:52:11.386408: validation loss: -0.4145\n",
      "2021-11-29 19:52:11.392016: Average global foreground Dice: [0.4442]\n",
      "2021-11-29 19:52:11.397150: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 19:52:11.897699: lr: 0.000256\n",
      "2021-11-29 19:52:11.941946: saving checkpoint...\n",
      "2021-11-29 19:52:13.685456: done, saving took 1.78 seconds\n",
      "2021-11-29 19:52:13.705937: This epoch took 188.613457 s\n",
      "\n",
      "2021-11-29 19:52:13.711987: \n",
      "epoch:  39\n",
      "2021-11-29 19:55:13.127569: train loss : -0.4148\n",
      "2021-11-29 19:55:26.726309: validation loss: -0.4118\n",
      "2021-11-29 19:55:26.732103: Average global foreground Dice: [0.4408]\n",
      "2021-11-29 19:55:26.737535: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 19:55:27.234507: lr: 0.000235\n",
      "2021-11-29 19:55:27.278713: saving checkpoint...\n",
      "2021-11-29 19:55:28.646200: done, saving took 1.41 seconds\n",
      "2021-11-29 19:55:28.665915: This epoch took 194.948570 s\n",
      "\n",
      "2021-11-29 19:55:28.671387: \n",
      "epoch:  40\n",
      "2021-11-29 19:58:30.068857: train loss : -0.4126\n",
      "2021-11-29 19:58:43.676513: validation loss: -0.4229\n",
      "2021-11-29 19:58:43.682587: Average global foreground Dice: [0.4527]\n",
      "2021-11-29 19:58:43.688678: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 19:58:44.200773: lr: 0.000214\n",
      "2021-11-29 19:58:44.245115: saving checkpoint...\n",
      "2021-11-29 19:58:46.083488: done, saving took 1.88 seconds\n",
      "2021-11-29 19:58:46.101874: This epoch took 197.422532 s\n",
      "\n",
      "2021-11-29 19:58:46.106900: \n",
      "epoch:  41\n",
      "2021-11-29 20:01:47.101220: train loss : -0.4092\n",
      "2021-11-29 20:02:00.648885: validation loss: -0.4011\n",
      "2021-11-29 20:02:00.655370: Average global foreground Dice: [0.4341]\n",
      "2021-11-29 20:02:00.661019: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 20:02:01.166295: lr: 0.000192\n",
      "2021-11-29 20:02:01.171998: This epoch took 195.059223 s\n",
      "\n",
      "2021-11-29 20:02:01.179087: \n",
      "epoch:  42\n",
      "2021-11-29 20:05:02.388980: train loss : -0.4048\n",
      "2021-11-29 20:05:15.967847: validation loss: -0.4240\n",
      "2021-11-29 20:05:15.973156: Average global foreground Dice: [0.453]\n",
      "2021-11-29 20:05:15.978766: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 20:05:16.483579: lr: 0.00017\n",
      "2021-11-29 20:05:16.538100: saving checkpoint...\n",
      "2021-11-29 20:05:18.200527: done, saving took 1.71 seconds\n",
      "2021-11-29 20:05:18.224681: This epoch took 197.040513 s\n",
      "\n",
      "2021-11-29 20:05:18.230662: \n",
      "epoch:  43\n",
      "2021-11-29 20:08:19.399652: train loss : -0.4144\n",
      "2021-11-29 20:08:33.033604: validation loss: -0.4061\n",
      "2021-11-29 20:08:33.039269: Average global foreground Dice: [0.4353]\n",
      "2021-11-29 20:08:33.045233: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 20:08:33.552256: lr: 0.000148\n",
      "2021-11-29 20:08:33.559654: This epoch took 195.323577 s\n",
      "\n",
      "2021-11-29 20:08:33.565021: \n",
      "epoch:  44\n",
      "2021-11-29 20:11:34.421123: train loss : -0.4113\n",
      "2021-11-29 20:11:48.061320: validation loss: -0.4359\n",
      "2021-11-29 20:11:48.068249: Average global foreground Dice: [0.4653]\n",
      "2021-11-29 20:11:48.073966: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 20:11:48.770516: lr: 0.000126\n",
      "2021-11-29 20:11:48.815048: saving checkpoint...\n",
      "2021-11-29 20:11:50.321102: done, saving took 1.54 seconds\n",
      "2021-11-29 20:11:50.341515: This epoch took 196.770676 s\n",
      "\n",
      "2021-11-29 20:11:50.346550: \n",
      "epoch:  45\n",
      "2021-11-29 20:14:51.941424: train loss : -0.4166\n",
      "2021-11-29 20:15:05.569545: validation loss: -0.4384\n",
      "2021-11-29 20:15:05.576339: Average global foreground Dice: [0.4667]\n",
      "2021-11-29 20:15:05.581793: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 20:15:06.088717: lr: 0.000103\n",
      "2021-11-29 20:15:06.132228: saving checkpoint...\n",
      "2021-11-29 20:15:07.710224: done, saving took 1.62 seconds\n",
      "2021-11-29 20:15:07.732431: This epoch took 197.380420 s\n",
      "\n",
      "2021-11-29 20:15:07.737319: \n",
      "epoch:  46\n",
      "2021-11-29 20:18:08.422886: train loss : -0.4173\n",
      "2021-11-29 20:18:21.976282: validation loss: -0.4280\n",
      "2021-11-29 20:18:21.983303: Average global foreground Dice: [0.4553]\n",
      "2021-11-29 20:18:21.988319: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 20:18:22.518286: lr: 7.9e-05\n",
      "2021-11-29 20:18:22.561537: saving checkpoint...\n",
      "2021-11-29 20:18:24.043131: done, saving took 1.52 seconds\n",
      "2021-11-29 20:18:24.064602: This epoch took 196.321771 s\n",
      "\n",
      "2021-11-29 20:18:24.070799: \n",
      "epoch:  47\n",
      "2021-11-29 20:21:25.198086: train loss : -0.4056\n",
      "2021-11-29 20:21:38.805779: validation loss: -0.4170\n",
      "2021-11-29 20:21:38.811730: Average global foreground Dice: [0.4426]\n",
      "2021-11-29 20:21:38.817518: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 20:21:39.316071: lr: 5.5e-05\n",
      "2021-11-29 20:21:39.321064: This epoch took 195.244637 s\n",
      "\n",
      "2021-11-29 20:21:39.326283: \n",
      "epoch:  48\n",
      "2021-11-29 20:24:37.378399: train loss : -0.4166\n",
      "2021-11-29 20:24:50.336739: validation loss: -0.4229\n",
      "2021-11-29 20:24:50.343352: Average global foreground Dice: [0.4495]\n",
      "2021-11-29 20:24:50.348738: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 20:24:50.872665: lr: 3e-05\n",
      "2021-11-29 20:24:50.930231: saving checkpoint...\n",
      "2021-11-29 20:24:52.493666: done, saving took 1.61 seconds\n",
      "2021-11-29 20:24:52.517900: This epoch took 193.186032 s\n",
      "\n",
      "2021-11-29 20:24:52.523279: \n",
      "epoch:  49\n",
      "2021-11-29 20:27:45.787820: train loss : -0.4183\n",
      "2021-11-29 20:27:58.989759: validation loss: -0.4119\n",
      "2021-11-29 20:27:58.995438: Average global foreground Dice: [0.4441]\n",
      "2021-11-29 20:27:59.000518: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 20:27:59.555249: lr: 0.0\n",
      "2021-11-29 20:27:59.560922: saving scheduled checkpoint file...\n",
      "2021-11-29 20:27:59.604357: saving checkpoint...\n",
      "2021-11-29 20:28:00.786266: done, saving took 1.22 seconds\n",
      "2021-11-29 20:28:00.800353: done\n",
      "2021-11-29 20:28:00.806395: This epoch took 188.278123 s\n",
      "\n",
      "2021-11-29 20:28:00.849319: saving checkpoint...\n",
      "2021-11-29 20:28:02.054342: done, saving took 1.24 seconds\n",
      "GGHB_DC68_LJH0_BABA_0002 (2, 57, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "GGHB_DC68_LJH0_BABA_0003 (2, 149, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RALP_0000 (2, 96, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RALP_0001 (2, 145, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "SNUH_DC07_JCW0_RALP_0002 (2, 83, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RALP_0011 (2, 111, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RALP_0020 (2, 213, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "SNUH_DC07_JCW0_RALP_0021 (2, 67, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RALP_0031 (2, 150, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RLPN_0002 (2, 90, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RLPN_0003 (2, 123, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RLPN_0008 (2, 86, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RLPN_0009 (2, 42, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RLPN_0014 (2, 38, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC68_KSJ0_BABA_0001 (2, 38, 343, 502)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC68_LKE0_BABA_0001 (2, 38, 342, 495)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC68_LKE0_BABA_0002 (2, 96, 342, 488)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-29 20:32:05.515146: finished prediction\n",
      "2021-11-29 20:32:05.520844: evaluation of raw predictions\n",
      "2021-11-29 20:32:08.531221: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.41382801914221606\n",
      "after:  0.4138155428341493\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "!nnUNet_train 2d nnUNetTrainerV2_Loss_MCC 480 all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.loss_function.nnUNetTrainerV2_Loss_TopK10.nnUNetTrainerV2_Loss_TopK10'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  1\n",
      "modalities:  {0: 'png'}\n",
      "use_mask_for_norm OrderedDict([(0, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 12, 'num_pool_per_axis': [7, 7], 'patch_size': array([512, 512]), 'median_patient_size_in_voxels': array([ 90, 512, 512]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /tf/temp/nnUNet/nnunet/preprocessed/Task480_GRSR/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "/usr/local/lib/python3.8/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "loading dataset\n",
      "loading all case properties\n",
      "unpacking dataset\n",
      "done\n",
      "2021-11-29 20:32:26.367990: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2021-11-29 20:32:33.034520: Unable to plot network architecture:\n",
      "2021-11-29 20:32:33.039526: No module named 'hiddenlayer'\n",
      "2021-11-29 20:32:33.111586: \n",
      "printing the network instead:\n",
      "\n",
      "2021-11-29 20:32:33.117239: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (1): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (2): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (3): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (4): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (5): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (6): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(480, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (4): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (5): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (6): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2021-11-29 20:32:33.127992: \n",
      "\n",
      "2021-11-29 20:32:33.133252: \n",
      "epoch:  0\n",
      "2021-11-29 20:35:46.909097: train loss : 0.8089\n",
      "2021-11-29 20:36:01.152099: validation loss: 0.6982\n",
      "2021-11-29 20:36:01.157121: Average global foreground Dice: [0.0187]\n",
      "2021-11-29 20:36:01.162545: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 20:36:01.586162: lr: 0.00982\n",
      "2021-11-29 20:36:01.591566: This epoch took 208.453185 s\n",
      "\n",
      "2021-11-29 20:36:01.596298: \n",
      "epoch:  1\n",
      "2021-11-29 20:38:59.766531: train loss : 0.6977\n",
      "2021-11-29 20:39:13.969555: validation loss: 0.6961\n",
      "2021-11-29 20:39:13.974477: Average global foreground Dice: [0.0011]\n",
      "2021-11-29 20:39:13.979223: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 20:39:14.507915: lr: 0.009639\n",
      "2021-11-29 20:39:14.512460: This epoch took 192.910073 s\n",
      "\n",
      "2021-11-29 20:39:14.517507: \n",
      "epoch:  2\n",
      "2021-11-29 20:42:11.009559: train loss : 0.6955\n",
      "2021-11-29 20:42:25.489664: validation loss: 0.6962\n",
      "2021-11-29 20:42:25.495675: Average global foreground Dice: [0.0141]\n",
      "2021-11-29 20:42:25.501274: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 20:42:26.011301: lr: 0.009458\n",
      "2021-11-29 20:42:26.015746: This epoch took 191.493041 s\n",
      "\n",
      "2021-11-29 20:42:26.020412: \n",
      "epoch:  3\n",
      "2021-11-29 20:45:23.108815: train loss : 0.6953\n",
      "2021-11-29 20:45:37.312402: validation loss: 0.6942\n",
      "2021-11-29 20:45:37.321185: Average global foreground Dice: [0.0023]\n",
      "2021-11-29 20:45:37.326744: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 20:45:37.814697: lr: 0.009277\n",
      "2021-11-29 20:45:37.819684: This epoch took 191.794503 s\n",
      "\n",
      "2021-11-29 20:45:37.828290: \n",
      "epoch:  4\n",
      "2021-11-29 20:48:35.341473: train loss : 0.6949\n",
      "2021-11-29 20:48:49.568884: validation loss: 0.6938\n",
      "2021-11-29 20:48:49.574496: Average global foreground Dice: [0.0041]\n",
      "2021-11-29 20:48:49.579833: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 20:48:50.075069: lr: 0.009095\n",
      "2021-11-29 20:48:50.081126: This epoch took 192.242709 s\n",
      "\n",
      "2021-11-29 20:48:50.085983: \n",
      "epoch:  5\n",
      "2021-11-29 20:51:45.863143: train loss : 0.6954\n",
      "2021-11-29 20:52:00.249303: validation loss: 0.6937\n",
      "2021-11-29 20:52:00.255474: Average global foreground Dice: [0.0022]\n",
      "2021-11-29 20:52:00.259951: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 20:52:00.758637: lr: 0.008913\n",
      "2021-11-29 20:52:00.766613: This epoch took 190.675399 s\n",
      "\n",
      "2021-11-29 20:52:00.772146: \n",
      "epoch:  6\n",
      "2021-11-29 20:54:57.518707: train loss : 0.6949\n",
      "2021-11-29 20:55:11.747701: validation loss: 0.6945\n",
      "2021-11-29 20:55:11.754348: Average global foreground Dice: [0.0057]\n",
      "2021-11-29 20:55:11.760061: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 20:55:12.267454: lr: 0.008731\n",
      "2021-11-29 20:55:12.272511: This epoch took 191.494675 s\n",
      "\n",
      "2021-11-29 20:55:12.277856: \n",
      "epoch:  7\n",
      "2021-11-29 20:58:08.729310: train loss : 0.6943\n",
      "2021-11-29 20:58:23.428971: validation loss: 0.6937\n",
      "2021-11-29 20:58:23.435200: Average global foreground Dice: [0.0304]\n",
      "2021-11-29 20:58:23.440128: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 20:58:23.949925: lr: 0.008548\n",
      "2021-11-29 20:58:23.955855: This epoch took 191.672098 s\n",
      "\n",
      "2021-11-29 20:58:23.960786: \n",
      "epoch:  8\n",
      "2021-11-29 21:01:27.397835: train loss : 0.6943\n",
      "2021-11-29 21:01:42.520800: validation loss: 0.6935\n",
      "2021-11-29 21:01:42.526905: Average global foreground Dice: [0.0001]\n",
      "2021-11-29 21:01:42.532088: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 21:01:43.049306: lr: 0.008364\n",
      "2021-11-29 21:01:43.054551: This epoch took 199.088373 s\n",
      "\n",
      "2021-11-29 21:01:43.060705: \n",
      "epoch:  9\n",
      "2021-11-29 21:04:43.726452: train loss : 0.6937\n",
      "2021-11-29 21:04:57.940217: validation loss: 0.6934\n",
      "2021-11-29 21:04:57.945998: Average global foreground Dice: [0.0098]\n",
      "2021-11-29 21:04:57.951172: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 21:04:58.468549: lr: 0.008181\n",
      "2021-11-29 21:04:58.474220: This epoch took 195.407444 s\n",
      "\n",
      "2021-11-29 21:04:58.478976: \n",
      "epoch:  10\n",
      "2021-11-29 21:07:54.969123: train loss : 0.6948\n",
      "2021-11-29 21:08:09.716101: validation loss: 0.6936\n",
      "2021-11-29 21:08:09.722251: Average global foreground Dice: [0.0001]\n",
      "2021-11-29 21:08:09.727672: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 21:08:10.245164: lr: 0.007996\n",
      "2021-11-29 21:08:10.251329: This epoch took 191.767385 s\n",
      "\n",
      "2021-11-29 21:08:10.256769: \n",
      "epoch:  11\n",
      "2021-11-29 21:11:05.862476: train loss : 0.6938\n",
      "2021-11-29 21:11:20.131078: validation loss: 0.6935\n",
      "2021-11-29 21:11:20.137193: Average global foreground Dice: [0.0]\n",
      "2021-11-29 21:11:20.141750: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 21:11:20.643546: lr: 0.007811\n",
      "2021-11-29 21:11:20.650129: This epoch took 190.388241 s\n",
      "\n",
      "2021-11-29 21:11:20.655361: \n",
      "epoch:  12\n",
      "2021-11-29 21:14:18.308825: train loss : 0.6937\n",
      "2021-11-29 21:14:32.595559: validation loss: 0.6935\n",
      "2021-11-29 21:14:32.602287: Average global foreground Dice: [0.0]\n",
      "2021-11-29 21:14:32.607250: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 21:14:33.110885: lr: 0.007626\n",
      "2021-11-29 21:14:33.116129: This epoch took 192.455322 s\n",
      "\n",
      "2021-11-29 21:14:33.121352: \n",
      "epoch:  13\n",
      "2021-11-29 21:17:29.430378: train loss : 0.6938\n",
      "2021-11-29 21:17:44.134617: validation loss: 0.6935\n",
      "2021-11-29 21:17:44.140171: Average global foreground Dice: [0.0001]\n",
      "2021-11-29 21:17:44.145487: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 21:17:44.656950: lr: 0.00744\n",
      "2021-11-29 21:17:44.662573: This epoch took 191.535532 s\n",
      "\n",
      "2021-11-29 21:17:44.667296: \n",
      "epoch:  14\n",
      "2021-11-29 21:20:41.795429: train loss : 0.6942\n",
      "2021-11-29 21:20:56.057510: validation loss: 0.6937\n",
      "2021-11-29 21:20:56.063998: Average global foreground Dice: [0.0461]\n",
      "2021-11-29 21:20:56.069376: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 21:20:56.567279: lr: 0.007254\n",
      "2021-11-29 21:20:56.572062: This epoch took 191.899853 s\n",
      "\n",
      "2021-11-29 21:20:56.577381: \n",
      "epoch:  15\n",
      "2021-11-29 21:23:55.721868: train loss : 0.6937\n",
      "2021-11-29 21:24:10.942786: validation loss: 0.6937\n",
      "2021-11-29 21:24:10.948072: Average global foreground Dice: [0.0]\n",
      "2021-11-29 21:24:10.953797: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 21:24:11.469834: lr: 0.007067\n",
      "2021-11-29 21:24:11.475391: This epoch took 194.892509 s\n",
      "\n",
      "2021-11-29 21:24:11.480066: \n",
      "epoch:  16\n",
      "2021-11-29 21:27:15.944985: train loss : 0.6937\n",
      "2021-11-29 21:27:31.155998: validation loss: 0.6934\n",
      "2021-11-29 21:27:31.161944: Average global foreground Dice: [0.0]\n",
      "2021-11-29 21:27:31.166965: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 21:27:31.674332: lr: 0.00688\n",
      "2021-11-29 21:27:31.680818: This epoch took 200.195297 s\n",
      "\n",
      "2021-11-29 21:27:31.686307: \n",
      "epoch:  17\n",
      "2021-11-29 21:30:30.250711: train loss : 0.6935\n",
      "2021-11-29 21:30:44.555418: validation loss: 0.6935\n",
      "2021-11-29 21:30:44.562476: Average global foreground Dice: [0.0]\n",
      "2021-11-29 21:30:44.568019: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 21:30:45.084994: lr: 0.006692\n",
      "2021-11-29 21:30:45.089754: This epoch took 193.398270 s\n",
      "\n",
      "2021-11-29 21:30:45.095023: \n",
      "epoch:  18\n",
      "2021-11-29 21:33:42.894786: train loss : 0.6936\n",
      "2021-11-29 21:33:57.281381: validation loss: 0.6934\n",
      "2021-11-29 21:33:57.286984: Average global foreground Dice: [0.0001]\n",
      "2021-11-29 21:33:57.291882: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 21:33:57.815108: lr: 0.006504\n",
      "2021-11-29 21:33:57.820461: This epoch took 192.720892 s\n",
      "\n",
      "2021-11-29 21:33:57.825466: \n",
      "epoch:  19\n",
      "2021-11-29 21:36:53.518293: train loss : 0.6934\n",
      "2021-11-29 21:37:07.907761: validation loss: 0.6934\n",
      "2021-11-29 21:37:07.913788: Average global foreground Dice: [0.0]\n",
      "2021-11-29 21:37:07.920751: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 21:37:08.428643: lr: 0.006314\n",
      "2021-11-29 21:37:08.434678: This epoch took 190.603714 s\n",
      "\n",
      "2021-11-29 21:37:08.440838: \n",
      "epoch:  20\n",
      "2021-11-29 21:40:10.398926: train loss : 0.6936\n",
      "2021-11-29 21:40:25.559885: validation loss: 0.6934\n",
      "2021-11-29 21:40:25.566598: Average global foreground Dice: [0.0001]\n",
      "2021-11-29 21:40:25.571707: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 21:40:26.073481: lr: 0.006125\n",
      "2021-11-29 21:40:26.079165: This epoch took 197.632632 s\n",
      "\n",
      "2021-11-29 21:40:26.084675: \n",
      "epoch:  21\n",
      "2021-11-29 21:43:29.794545: train loss : 0.6936\n",
      "2021-11-29 21:43:44.935273: validation loss: 0.6933\n",
      "2021-11-29 21:43:44.942962: Average global foreground Dice: [0.0001]\n",
      "2021-11-29 21:43:44.948982: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 21:43:45.453676: lr: 0.005934\n",
      "2021-11-29 21:43:45.458592: This epoch took 199.368612 s\n",
      "\n",
      "2021-11-29 21:43:45.463794: \n",
      "epoch:  22\n",
      "2021-11-29 21:46:50.055437: train loss : 0.6938\n",
      "2021-11-29 21:47:05.279343: validation loss: 0.6934\n",
      "2021-11-29 21:47:05.287504: Average global foreground Dice: [0.0]\n",
      "2021-11-29 21:47:05.293699: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 21:47:05.794437: lr: 0.005743\n",
      "2021-11-29 21:47:05.799914: This epoch took 200.331409 s\n",
      "\n",
      "2021-11-29 21:47:05.804416: \n",
      "epoch:  23\n",
      "2021-11-29 21:50:05.705715: train loss : 0.6936\n",
      "2021-11-29 21:50:19.935766: validation loss: 0.6935\n",
      "2021-11-29 21:50:19.941822: Average global foreground Dice: [0.0005]\n",
      "2021-11-29 21:50:19.947790: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 21:50:20.439854: lr: 0.005551\n",
      "2021-11-29 21:50:20.445458: This epoch took 194.635134 s\n",
      "\n",
      "2021-11-29 21:50:20.450760: \n",
      "epoch:  24\n",
      "2021-11-29 21:53:17.990056: train loss : 0.6938\n",
      "2021-11-29 21:53:32.594653: validation loss: 0.6938\n",
      "2021-11-29 21:53:32.600788: Average global foreground Dice: [0.0]\n",
      "2021-11-29 21:53:32.606901: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 21:53:33.099091: lr: 0.005359\n",
      "2021-11-29 21:53:33.104742: This epoch took 192.648069 s\n",
      "\n",
      "2021-11-29 21:53:33.110807: \n",
      "epoch:  25\n",
      "2021-11-29 21:56:29.130962: train loss : 0.6937\n",
      "2021-11-29 21:56:43.568929: validation loss: 0.6934\n",
      "2021-11-29 21:56:43.574990: Average global foreground Dice: [0.0]\n",
      "2021-11-29 21:56:43.580958: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 21:56:44.102472: lr: 0.005166\n",
      "2021-11-29 21:56:44.107517: This epoch took 190.991517 s\n",
      "\n",
      "2021-11-29 21:56:44.113177: \n",
      "epoch:  26\n",
      "2021-11-29 21:59:41.558513: train loss : 0.6934\n",
      "2021-11-29 21:59:55.784568: validation loss: 0.6934\n",
      "2021-11-29 21:59:55.795641: Average global foreground Dice: [0.0]\n",
      "2021-11-29 21:59:55.800886: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 21:59:56.289096: lr: 0.004971\n",
      "2021-11-29 21:59:56.294948: This epoch took 192.175963 s\n",
      "\n",
      "2021-11-29 21:59:56.299809: \n",
      "epoch:  27\n",
      "2021-11-29 22:02:53.389211: train loss : 0.6935\n",
      "2021-11-29 22:03:08.170679: validation loss: 0.6934\n",
      "2021-11-29 22:03:08.176731: Average global foreground Dice: [0.0]\n",
      "2021-11-29 22:03:08.181987: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 22:03:08.703682: lr: 0.004776\n",
      "2021-11-29 22:03:08.709443: This epoch took 192.404906 s\n",
      "\n",
      "2021-11-29 22:03:08.714869: \n",
      "epoch:  28\n",
      "2021-11-29 22:06:05.459805: train loss : 0.6937\n",
      "2021-11-29 22:06:19.715231: validation loss: 0.6935\n",
      "2021-11-29 22:06:19.721429: Average global foreground Dice: [0.0]\n",
      "2021-11-29 22:06:19.726947: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 22:06:20.210740: lr: 0.004581\n",
      "2021-11-29 22:06:20.216555: This epoch took 191.495885 s\n",
      "\n",
      "2021-11-29 22:06:20.221416: \n",
      "epoch:  29\n",
      "2021-11-29 22:09:18.162357: train loss : 0.6936\n",
      "2021-11-29 22:09:32.431963: validation loss: 0.6935\n",
      "2021-11-29 22:09:32.437624: Average global foreground Dice: [0.0]\n",
      "2021-11-29 22:09:32.443389: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 22:09:32.929918: lr: 0.004384\n",
      "2021-11-29 22:09:32.934970: This epoch took 192.707983 s\n",
      "\n",
      "2021-11-29 22:09:32.939983: \n",
      "epoch:  30\n",
      "2021-11-29 22:12:29.824918: train loss : 0.6934\n",
      "2021-11-29 22:12:44.438938: validation loss: 0.6933\n",
      "2021-11-29 22:12:44.445964: Average global foreground Dice: [0.0]\n",
      "2021-11-29 22:12:44.451618: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 22:12:44.944762: lr: 0.004186\n",
      "2021-11-29 22:12:44.950082: This epoch took 192.004555 s\n",
      "\n",
      "2021-11-29 22:12:44.955145: \n",
      "epoch:  31\n",
      "2021-11-29 22:15:42.178700: train loss : 0.6934\n",
      "2021-11-29 22:15:56.401734: validation loss: 0.6933\n",
      "2021-11-29 22:15:56.408237: Average global foreground Dice: [0.0]\n",
      "2021-11-29 22:15:56.414006: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 22:15:56.908451: lr: 0.003987\n",
      "2021-11-29 22:15:56.914785: This epoch took 191.953376 s\n",
      "\n",
      "2021-11-29 22:15:56.920990: \n",
      "epoch:  32\n",
      "/tf/backup/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py:254: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
      "2021-11-29 22:18:56.581573: train loss : 0.6934\n",
      "2021-11-29 22:19:11.796405: validation loss: 0.6935\n",
      "2021-11-29 22:19:11.802219: Average global foreground Dice: [0.0]\n",
      "2021-11-29 22:19:11.808029: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 22:19:12.294471: lr: 0.003787\n",
      "2021-11-29 22:19:12.299892: This epoch took 195.373268 s\n",
      "\n",
      "2021-11-29 22:19:12.305545: \n",
      "epoch:  33\n",
      "2021-11-29 22:22:16.746583: train loss : 0.6935\n",
      "2021-11-29 22:22:31.891521: validation loss: 0.6933\n",
      "2021-11-29 22:22:31.897132: Average global foreground Dice: [0.0]\n",
      "2021-11-29 22:22:31.903113: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 22:22:32.413193: lr: 0.003586\n",
      "2021-11-29 22:22:32.418499: This epoch took 200.107481 s\n",
      "\n",
      "2021-11-29 22:22:32.423761: \n",
      "epoch:  34\n",
      "2021-11-29 22:25:36.865236: train loss : 0.6934\n",
      "2021-11-29 22:25:52.056048: validation loss: 0.6934\n",
      "2021-11-29 22:25:52.062539: Average global foreground Dice: [0.0]\n",
      "2021-11-29 22:25:52.068339: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 22:25:52.569297: lr: 0.003384\n",
      "2021-11-29 22:25:52.575214: This epoch took 200.146119 s\n",
      "\n",
      "2021-11-29 22:25:52.580981: \n",
      "epoch:  35\n",
      "2021-11-29 22:28:56.896343: train loss : 0.6934\n",
      "2021-11-29 22:29:12.118196: validation loss: 0.6934\n",
      "2021-11-29 22:29:12.124393: Average global foreground Dice: [0.0]\n",
      "2021-11-29 22:29:12.129281: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 22:29:12.635507: lr: 0.00318\n",
      "2021-11-29 22:29:12.640991: This epoch took 200.054468 s\n",
      "\n",
      "2021-11-29 22:29:12.645996: \n",
      "epoch:  36\n",
      "2021-11-29 22:32:16.599375: train loss : 0.6934\n",
      "2021-11-29 22:32:31.790622: validation loss: 0.6933\n",
      "2021-11-29 22:32:31.795937: Average global foreground Dice: [0.0]\n",
      "2021-11-29 22:32:31.800771: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 22:32:32.289417: lr: 0.002975\n",
      "2021-11-29 22:32:32.294867: This epoch took 199.643449 s\n",
      "\n",
      "2021-11-29 22:32:32.299874: \n",
      "epoch:  37\n",
      "2021-11-29 22:35:31.096430: train loss : 0.6934\n",
      "2021-11-29 22:35:45.367727: validation loss: 0.6934\n",
      "2021-11-29 22:35:45.373674: Average global foreground Dice: [0.0]\n",
      "2021-11-29 22:35:45.378160: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 22:35:45.879885: lr: 0.002768\n",
      "2021-11-29 22:35:45.885383: This epoch took 193.580536 s\n",
      "\n",
      "2021-11-29 22:35:45.890669: \n",
      "epoch:  38\n",
      "2021-11-29 22:38:43.836108: train loss : 0.6934\n",
      "2021-11-29 22:38:58.264756: validation loss: 0.6934\n",
      "2021-11-29 22:38:58.270442: Average global foreground Dice: [0.0]\n",
      "2021-11-29 22:38:58.275879: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 22:38:58.797171: lr: 0.00256\n",
      "2021-11-29 22:38:58.802993: This epoch took 192.906921 s\n",
      "\n",
      "2021-11-29 22:38:58.808263: \n",
      "epoch:  39\n",
      "2021-11-29 22:41:54.906160: train loss : 0.6934\n",
      "2021-11-29 22:42:09.454190: validation loss: 0.6934\n",
      "2021-11-29 22:42:09.460876: Average global foreground Dice: [0.0]\n",
      "2021-11-29 22:42:09.466147: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 22:42:09.961108: lr: 0.002349\n",
      "2021-11-29 22:42:09.966011: This epoch took 191.152459 s\n",
      "\n",
      "2021-11-29 22:42:09.971469: \n",
      "epoch:  40\n",
      "2021-11-29 22:45:07.965895: train loss : 0.6934\n",
      "2021-11-29 22:45:22.360900: validation loss: 0.6934\n",
      "2021-11-29 22:45:22.367137: Average global foreground Dice: [0.0]\n",
      "2021-11-29 22:45:22.372035: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 22:45:22.885487: lr: 0.002137\n",
      "2021-11-29 22:45:22.891350: This epoch took 192.914213 s\n",
      "\n",
      "2021-11-29 22:45:22.896903: \n",
      "epoch:  41\n",
      "2021-11-29 22:48:21.184534: train loss : 0.6934\n",
      "2021-11-29 22:48:35.761012: validation loss: 0.6933\n",
      "2021-11-29 22:48:35.767151: Average global foreground Dice: [0.0]\n",
      "2021-11-29 22:48:35.772398: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 22:48:36.258446: lr: 0.001922\n",
      "2021-11-29 22:48:36.264112: This epoch took 193.361614 s\n",
      "\n",
      "2021-11-29 22:48:36.269101: \n",
      "epoch:  42\n",
      "2021-11-29 22:51:33.001132: train loss : 0.6934\n",
      "2021-11-29 22:51:47.503331: validation loss: 0.6933\n",
      "2021-11-29 22:51:47.508979: Average global foreground Dice: [0.0]\n",
      "2021-11-29 22:51:47.513971: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 22:51:48.013698: lr: 0.001704\n",
      "2021-11-29 22:51:48.018730: This epoch took 191.744747 s\n",
      "\n",
      "2021-11-29 22:51:48.024291: \n",
      "epoch:  43\n",
      "2021-11-29 22:54:49.707274: train loss : 0.6934\n",
      "2021-11-29 22:55:04.949076: validation loss: 0.6934\n",
      "2021-11-29 22:55:04.954501: Average global foreground Dice: [0.0]\n",
      "2021-11-29 22:55:04.959523: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 22:55:05.461551: lr: 0.001483\n",
      "2021-11-29 22:55:05.466305: This epoch took 197.436168 s\n",
      "\n",
      "2021-11-29 22:55:05.471648: \n",
      "epoch:  44\n",
      "2021-11-29 22:58:09.347638: train loss : 0.6934\n",
      "2021-11-29 22:58:24.594930: validation loss: 0.6934\n",
      "2021-11-29 22:58:24.600550: Average global foreground Dice: [0.0]\n",
      "2021-11-29 22:58:24.605010: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 22:58:25.096567: lr: 0.001259\n",
      "2021-11-29 22:58:25.102058: This epoch took 199.624706 s\n",
      "\n",
      "2021-11-29 22:58:25.106906: \n",
      "epoch:  45\n",
      "2021-11-29 23:01:29.183079: train loss : 0.6934\n",
      "2021-11-29 23:01:44.418351: validation loss: 0.6933\n",
      "2021-11-29 23:01:44.424670: Average global foreground Dice: [0.0]\n",
      "2021-11-29 23:01:44.430146: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 23:01:44.922035: lr: 0.00103\n",
      "2021-11-29 23:01:44.927867: This epoch took 199.815686 s\n",
      "\n",
      "2021-11-29 23:01:44.933202: \n",
      "epoch:  46\n",
      "2021-11-29 23:04:49.283876: train loss : 0.6934\n",
      "2021-11-29 23:05:04.468985: validation loss: 0.6933\n",
      "2021-11-29 23:05:04.474785: Average global foreground Dice: [0.0]\n",
      "2021-11-29 23:05:04.479713: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 23:05:04.961207: lr: 0.000795\n",
      "2021-11-29 23:05:04.966927: This epoch took 200.028031 s\n",
      "\n",
      "2021-11-29 23:05:04.972531: \n",
      "epoch:  47\n",
      "2021-11-29 23:08:09.312929: train loss : 0.6934\n",
      "2021-11-29 23:08:24.382762: validation loss: 0.6934\n",
      "2021-11-29 23:08:24.389008: Average global foreground Dice: [0.0]\n",
      "2021-11-29 23:08:24.394592: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 23:08:24.877571: lr: 0.000552\n",
      "2021-11-29 23:08:24.883332: This epoch took 199.904520 s\n",
      "\n",
      "2021-11-29 23:08:24.888364: \n",
      "epoch:  48\n",
      "2021-11-29 23:11:21.728408: train loss : 0.6934\n",
      "2021-11-29 23:11:36.278368: validation loss: 0.6933\n",
      "2021-11-29 23:11:36.285970: Average global foreground Dice: [0.0]\n",
      "2021-11-29 23:11:36.290906: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 23:11:36.799428: lr: 0.000296\n",
      "2021-11-29 23:11:36.805264: This epoch took 191.911729 s\n",
      "\n",
      "2021-11-29 23:11:36.810202: \n",
      "epoch:  49\n",
      "2021-11-29 23:14:37.478547: train loss : 0.6934\n",
      "2021-11-29 23:14:52.694924: validation loss: 0.6934\n",
      "2021-11-29 23:14:52.701106: Average global foreground Dice: [0.0]\n",
      "2021-11-29 23:14:52.707080: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2021-11-29 23:14:53.192302: lr: 0.0\n",
      "2021-11-29 23:14:53.198092: saving scheduled checkpoint file...\n",
      "2021-11-29 23:14:53.295816: saving checkpoint...\n",
      "2021-11-29 23:14:54.559314: done, saving took 1.36 seconds\n",
      "2021-11-29 23:14:54.576267: done\n",
      "2021-11-29 23:14:54.582302: This epoch took 197.762407 s\n",
      "\n",
      "2021-11-29 23:14:54.625952: saving checkpoint...\n",
      "2021-11-29 23:14:55.808898: done, saving took 1.22 seconds\n",
      "GGHB_DC68_LJH0_BABA_0002 (2, 57, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "GGHB_DC68_LJH0_BABA_0003 (2, 149, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RALP_0000 (2, 96, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RALP_0001 (2, 145, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "SNUH_DC07_JCW0_RALP_0002 (2, 83, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RALP_0011 (2, 111, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RALP_0020 (2, 213, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "SNUH_DC07_JCW0_RALP_0021 (2, 67, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RALP_0031 (2, 150, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RLPN_0002 (2, 90, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RLPN_0003 (2, 123, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RLPN_0008 (2, 86, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "SNUH_DC07_JCW0_RLPN_0009 (2, 42, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC07_JCW0_RLPN_0014 (2, 38, 512, 512)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC68_KSJ0_BABA_0001 (2, 38, 343, 502)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC68_LKE0_BABA_0001 (2, 38, 342, 495)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "SNUH_DC68_LKE0_BABA_0002 (2, 96, 342, 488)\n",
      "debug: mirroring True mirror_axes (0, 1)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2021-11-29 23:18:59.577062: finished prediction\n",
      "2021-11-29 23:18:59.582592: evaluation of raw predictions\n",
      "2021-11-29 23:19:02.741288: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 2.7974971944659436e-06\n",
      "after:  1.8926840772816061e-06\n",
      "Only one class present, no need to do each class separately as this is covered in fg vs bg\n",
      "done\n",
      "for which classes:\n",
      "[]\n",
      "min_object_sizes\n",
      "None\n",
      "done\r\n"
     ]
    }
   ],
   "source": [
    "!nnUNet_train 2d nnUNetTrainerV2_Loss_TopK10 480 all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/nnUNet_train\", line 33, in <module>\n",
      "    sys.exit(load_entry_point('nnunet', 'console_scripts', 'nnUNet_train')())\n",
      "  File \"/tf/backup/nnUNet/nnunet/run/run_training.py\", line 137, in main\n",
      "    trainer_class = get_default_configuration(network, task, network_trainer, plans_identifier)\n",
      "  File \"/tf/backup/nnUNet/nnunet/run/default_configuration.py\", line 47, in get_default_configuration\n",
      "    plans = load_pickle(plans_file)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/batchgenerators/utilities/file_and_folder_operations.py\", line 57, in load_pickle\n",
      "    with open(file, mode) as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/tf/temp/nnUNet/nnunet/preprocessed/Task480_SUR/nnUNetPlansv2.1_plans_2D.pkl'\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/nnUNet_train\", line 33, in <module>\n",
      "    sys.exit(load_entry_point('nnunet', 'console_scripts', 'nnUNet_train')())\n",
      "  File \"/tf/backup/nnUNet/nnunet/run/run_training.py\", line 137, in main\n",
      "    trainer_class = get_default_configuration(network, task, network_trainer, plans_identifier)\n",
      "  File \"/tf/backup/nnUNet/nnunet/run/default_configuration.py\", line 47, in get_default_configuration\n",
      "    plans = load_pickle(plans_file)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/batchgenerators/utilities/file_and_folder_operations.py\", line 57, in load_pickle\n",
      "    with open(file, mode) as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/tf/temp/nnUNet/nnunet/preprocessed/Task480_SUR/nnUNetPlansv2.1_plans_2D.pkl'\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/nnUNet_train\", line 33, in <module>\n",
      "    sys.exit(load_entry_point('nnunet', 'console_scripts', 'nnUNet_train')())\n",
      "  File \"/tf/backup/nnUNet/nnunet/run/run_training.py\", line 137, in main\n",
      "    trainer_class = get_default_configuration(network, task, network_trainer, plans_identifier)\n",
      "  File \"/tf/backup/nnUNet/nnunet/run/default_configuration.py\", line 47, in get_default_configuration\n",
      "    plans = load_pickle(plans_file)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/batchgenerators/utilities/file_and_folder_operations.py\", line 57, in load_pickle\n",
      "    with open(file, mode) as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/tf/temp/nnUNet/nnunet/preprocessed/Task480_SUR/nnUNetPlansv2.1_plans_2D.pkl'\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/nnUNet_train\", line 33, in <module>\n",
      "    sys.exit(load_entry_point('nnunet', 'console_scripts', 'nnUNet_train')())\n",
      "  File \"/tf/backup/nnUNet/nnunet/run/run_training.py\", line 137, in main\n",
      "    trainer_class = get_default_configuration(network, task, network_trainer, plans_identifier)\n",
      "  File \"/tf/backup/nnUNet/nnunet/run/default_configuration.py\", line 47, in get_default_configuration\n",
      "    plans = load_pickle(plans_file)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/batchgenerators/utilities/file_and_folder_operations.py\", line 57, in load_pickle\n",
      "    with open(file, mode) as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/tf/temp/nnUNet/nnunet/preprocessed/Task480_SUR/nnUNetPlansv2.1_plans_2D.pkl'\n",
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/nnUNet_train\", line 33, in <module>\n",
      "    sys.exit(load_entry_point('nnunet', 'console_scripts', 'nnUNet_train')())\n",
      "  File \"/tf/backup/nnUNet/nnunet/run/run_training.py\", line 137, in main\n",
      "    trainer_class = get_default_configuration(network, task, network_trainer, plans_identifier)\n",
      "  File \"/tf/backup/nnUNet/nnunet/run/default_configuration.py\", line 47, in get_default_configuration\n",
      "    plans = load_pickle(plans_file)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/batchgenerators/utilities/file_and_folder_operations.py\", line 57, in load_pickle\n",
      "    with open(file, mode) as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/tf/temp/nnUNet/nnunet/preprocessed/Task480_SUR/nnUNetPlansv2.1_plans_2D.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Model 1 (epoch 50)\n",
    "\n",
    "!nnUNet_train 2d nnUNetTrainerV2 480 0\n",
    "!nnUNet_train 2d nnUNetTrainerV2 480 1\n",
    "!nnUNet_train 2d nnUNetTrainerV2 480 2\n",
    "!nnUNet_train 2d nnUNetTrainerV2 480 3\n",
    "!nnUNet_train 2d nnUNetTrainerV2 480 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
